#~~
Copyright (c) 2024 Randy Hollines
~~#	

use Web.HTTP, Collection, System.IO.Filesystem, Data.JSON, Data.JSON.Scheme;

#~
Support for OpenAI audio APIs (-lib openai)
~#
bundle API.OpenAI.Audio {
	#~
	Transcribes audio into the given output format.
	~#
	class Transcription from EndPoint {
		#~
		Transcribes audio into the input language.
		@param name transcription name
		@param content byte stream to translate
		@param model ID of the model to use
		@param token API token
		@return translated text, Nil if unsuccessful
		~#
		function : Translate(name : String, content : Byte[], model : String, token : String) ~ String {
			return Translate(name, content, model, Nil, Nil, -1.0, token)
		}

		#~
		Transcribes audio into the input language.
		@param name transcription name
		@param content byte stream to translate
		@param model ID of the model to use
		@param prompt text to guide the model's style or continue a previous audio segment
		@param response_format format of the transcript output, options: 'json', 'text', 'srt', 'verbose_json', or 'vtt'
		@param temperature sampling temperature, between 0 and 1, higher values make the output more random
		@param token API token
		@return translated text, Nil if unsuccessful
		~#
		function : Translate(name : String, content : Byte[], model : String, prompt : String, response_format : String, temperature : Float, token : String) ~ String {
			encoder := Web.HTTP.Server.MultipartEncoder->New();

			model_headers := Map->New()<String, String>;
			model_headers->Insert("Content-Disposition", "form-data; name=\"model\"");
			model_content := Web.HTTP.Server.MultipartContent->New(model_headers, model->ToByteArray());
			encoder->Add(model_content);

			content_headers := Map->New()<String, String>;
			content_headers->Insert("Content-Disposition", "form-data; name=\"file\"; filename=\"{$name}\"");
			content_headers->Insert("Content-Type", "application/octet-stream");
			multi_content := Web.HTTP.Server.MultipartContent->New(content_headers, content);
			encoder->Add(multi_content);

			if(prompt <> Nil) {
				prompt_headers := Map->New()<String, String>;
				prompt_headers->Insert("Content-Disposition", "form-data; name=\"prompt\"");
				prompt_content := Web.HTTP.Server.MultipartContent->New(prompt_headers, prompt->ToByteArray());
				encoder->Add(prompt_content);
			};

			if(response_format <> Nil) {
				response_format_headers := Map->New()<String, String>;
				response_format_headers->Insert("Content-Disposition", "form-data; name=\"response_format\"");
				response_format_content := Web.HTTP.Server.MultipartContent->New(response_format_headers, response_format->ToByteArray());
				encoder->Add(response_format_content);
			};

			if(temperature >= 0.0 & temperature <= 1.0) {
				temperature_headers := Map->New()<String, String>;
				temperature_headers->Insert("Content-Disposition", "form-data; name=\"temperature\"");
				temperature_content := Web.HTTP.Server.MultipartContent->New(temperature_headers, temperature->ToString()->ToByteArray());
				encoder->Add(temperature_content);
			};

			data := encoder->ToByteArray();

			boundary := encoder->GetBoundary();
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickPost(Url->New(GetBaseUrl() + "/audio/transcriptions"), data, 
				"multipart/form-data; boundary={$boundary}", headers);

			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				model_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(model_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};
				
				if(model_json->Has("error")) {
					error_str := model_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return model_json->Get("text")->GetString();
			};

			return Nil;
		}
	}

	#~
	Audio APIs provides two speech to text endpoints, transcriptions and translations
	~#
	class Speech from EndPoint {
		#~
		Generates audio from the input text
		@param model available TTS models 'tts-1' or 'tts-1-hd'
		@param input the text to generate audio for, the maximum length is 4096 characters
		@param voice voice to use when generating the audio, supported voices are alloy, 'echo', 'fable', 'onyx', 'nova', and 'shimmer'. 
		@param token API token
		@return response with type and content, Nil if unsuccessful
		~#
		function : Speak(model : String, input : String, voice : String, token : String) ~ Pair<String, ByteArrayRef> {
			return Speak(model, input, voice, "mp3", 0.0, token);
		}

		#~
		Generates audio from the input text
		@param model available TTS models 'tts-1' or 'tts-1-hd'
		@param input the text to generate audio for, the maximum length is 4096 characters
		@param voice voice to use when generating the audio. Supported voices are alloy, 'echo', 'fable', 'onyx', 'nova', and 'shimmer'. 
		@param response_format format to audio in, supported formats are 'mp3', 'opus', 'aac', 'flac', 'wav', and 'pcm'.
		@param token API token
		@return response with type and content, Nil if unsuccessful
		~#
		function : Speak(model : String, input : String, voice : String, response_format : String, token : String) ~ Pair<String, ByteArrayRef> {
			return Speak(model, input, voice, response_format, 0.0, token);
		}

		#~
		Generates audio from the input text
		@param model available TTS models 'tts-1' or 'tts-1-hd'
		@param input the text to generate audio for, the maximum length is 4096 characters
		@param voice voice to use when generating the audio. Supported voices are alloy, 'echo', 'fable', 'onyx', 'nova', and 'shimmer'. 
		@param speed speed of the generated audio 0.25 to 4.0. 1.0 is the default.
		@param response_format format to audio in, supported formats are 'mp3', 'opus', 'aac', 'flac', 'wav', and 'pcm'.
		@param token API token
		@return response with type and content, Nil if unsuccessful
		~#
		function : Speak(model : String, input : String, voice : String, response_format : String, speed : Float, token : String) ~ Pair<String, ByteArrayRef> {
			audio_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			audio_json->Insert("model", model);
			audio_json->Insert("input", input);
			audio_json->Insert("voice", voice);

			if(response_format <> Nil) {
				audio_json->Insert("response_format", response_format);
			};

			if(speed >= 0.25 & speed <= 4.0) {
				audio_json->Insert("speed", speed);
			}
			else {
				audio_json->Insert("speed", 1.0);
			};
			data := audio_json->ToString()->ToByteArray();
			# data->ToString()->PrintLine();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			
			response := HttpsClient->QuickPost(Url->New(GetBaseUrl() + "/audio/speech"), data, "application/json", headers);
			# response->GetContent()->ToString()->PrintLine();		

			if(response->GetType()->Equals("application/json")) {
				audio_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(audio_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};
				
				if(audio_json->Has("error")) {
					error_str := audio_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};
			};
			
			return Pair->New(response->GetType(), ByteArrayRef->New(response->GetContent()))<String, ByteArrayRef>;
		}
	}
}

#~
Support for OpenAI responses APIs (-lib openai)
~#
bundle API.OpenAI.Responses {
	#~
	Model response for a given text and files
	~#
	class Response from EndPoint {
		@id : String;
		@object : String;
		@created_at : Int;
		@model : String;
		@outputs : Vector<Output>;

		New(json_elem : JsonElement) {
			Parent();
			
			@id := json_elem->Get("id")->GetString();
			@object := json_elem->Get("object")->GetString();
			@created_at := json_elem->Get("created_at")->GetInt();
			@model := json_elem->Get("model")->GetString();

			@outputs := Vector->New()<Output>;
			outputs_json := json_elem->Get("output");
			each(output_json in outputs_json) {
				@outputs->AddBack(Output->New(output_json));
			};
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		ID of the model to use
		@return ID of the model to use
		~#
		method : public : GetModel() ~ String {
			return @model;
		}

		#~
		Get response text
		@return response text
		~#
		method : public : GetText() ~ String {
			if(@outputs->Size() = 1) {
				output := @outputs->Get(0);
				contents := output->GetContents();
				if(contents->Size() = 1) {
					content := contents->Get(0);
					return content->GetText();
				}
			};

			return Nil;
		}

		#~
		Get response outputs
		@return response outputs
		~#
		method : public : GetOutputs() ~ Vector<Output> {
			return @outputs;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {			
			buffer := "Response: [short_id='";
			buffer += @id->SubString(10);

			buffer += "', object='"
			buffer += @object;

			buffer += "', model='"
			buffer += @model;

			buffer += "', created_at="
			buffer += @created_at;

			each(output in @outputs) {
				buffer += ",\n\t";
				buffer += output->ToString();
			};
			buffer += ']';

			return buffer;
		}

		#~
		Model response for the given query
		@param message completion message and image query.
		@param model ID of the model to use
		@param token API token
		@return completion response
		~#
		function : Respond(model : String, message : Pair<String, String>, token : String) ~ Response {
			messages := Vector->New()<Pair<String, String>>;
			messages->AddBack(message);

			return Respond(model, messages, -1, -1.0, -1.0, Nil, token);
		}

		#~
		Model response for the given query
		@param message completion message and image query.
		@param model ID of the model to use
		@param schema output schema
		@param token API token
		@return completion response
		~#
		function : Respond(model : String, message : Pair<String, String>, schema : ParameterType, token : String) ~ Response {
			messages := Vector->New()<Pair<String, String>>;
			messages->AddBack(message);

			return Respond(model, messages, -1, -1.0, -1.0, schema, token);
		}

		#~
		Model response for the given query
		@param model ID of the model to use
		@param message completion message and image query
		@param max_tokens maximum number of completion tokens returned by the API
		@param temperature amount of randomness in the response, valued between 0 inclusive and 2 exclusive
		@param top_p nucleus sampling threshold, valued between 0 and 1 inclusive
		@param token API token
		@return completion response
		~#
		function : Respond(model : String, message : Pair<String, String>, max_tokens : Int, temperature : Float, top_p : Float, token : String) ~ Response {
			messages := Vector->New()<Pair<String, String>>;
			messages->AddBack(message);

			return Respond(model, messages, max_tokens, temperature, top_p, Nil, token);
		}

		#~
		Model response for the given query
		@param model ID of the model to use
		@param message completion message and image query
		@param max_tokens maximum number of completion tokens returned by the API
		@param temperature amount of randomness in the response, valued between 0 inclusive and 2 exclusive
		@param top_p nucleus sampling threshold, valued between 0 and 1 inclusive
		@param schema output schema
		@param token API token
		@return completion response
		~#
		function : Respond(model : String, message : Pair<String, String>, max_tokens : Int, temperature : Float, top_p : Float, schema : ParameterType, token : String) ~ Response {
			messages := Vector->New()<Pair<String, String>>;
			messages->AddBack(message);

			return Respond(model, messages, max_tokens, temperature, top_p, schema, token);
		}

		#~
		Model response for the given query
		@param messages list of messages comprising the conversation
		@param model ID of the model to use
		@param schema output schema
		@param token API token
		@return completion response
		~#
		function : Respond(model : String, messages : Vector<Pair<String, String>>, schema : ParameterType, token : String) ~ Response {
			return Respond(model, messages, -1, -1.0, -1.0, schema, token);
		}

		#~
		Model response for the given query
		@param model ID of the model to use
		@param messages list of messages comprising the conversation
		@param max_tokens maximum number of completion tokens returned by the API
		@param temperature amount of randomness in the response, valued between 0 inclusive and 2 exclusive
		@param top_p nucleus sampling threshold, valued between 0 and 1 inclusive
		@param schema output schema
		@param token API token
		@return completion response
		~#
		function : Respond(model : String, messages : Vector<Pair<String, String>>, max_tokens : Int, temperature : Float, top_p : Float, schema : ParameterType, token : String) ~ Response {
			completion_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			completion_json->Insert("model", model);

			if(max_tokens > -1) {
				completion_json->Insert("max_tokens", max_tokens);
			};

			if(temperature >= 0.0) {
				completion_json->Insert("temperature", temperature);
			};

			if(top_p >= 0.0) {
				completion_json->Insert("top_p", top_p);
			};

			messages_json := JsonElement->New(JsonElement->JsonType->ARRAY);
			each(message in messages) {
				message_json := JsonElement->New(JsonElement->JsonType->OBJECT);
				message_json->Insert("role", message->GetFirst());

				# TODO: support files
				message_json->Insert("content", message->GetSecond());
				
				messages_json->Add(message_json);
			};
			completion_json->Insert("input", messages_json);

			if(schema <> Nil) {
				format_json := JsonElement->New(JsonElement->JsonType->OBJECT);
				format_json->Insert("type", "json_schema");
				format_json->Insert("strict", true);
				format_json->Insert("name", "json_response");

				openai_schema := schema->ToJson();
				openai_schema->Insert("additionalProperties", false);
				format_json->Insert("schema", openai_schema);
				
				text_json := JsonElement->New(JsonElement->JsonType->OBJECT);
				text_json->Insert("format", format_json);

				completion_json->Insert("text", text_json);
			};

			data := completion_json->ToFormattedString()->ToByteArray();
			if(IsDebug()) {
				data->ToString()->PrintLine();
			};

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickPost(Url->New(GetBaseUrl() + "/responses"), data, "application/json", headers);
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: name='/responses' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();				
				};

				chat_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(chat_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};
				
				error_str := chat_json->FindElements("error/message");
				if(error_str <> Nil) {
					SetLastError(error_str->GetString());
					return Nil;
				};

				return Response->New(chat_json);
			};

			return Nil;
		}

		#~
		Model response for the given file and query
		@param message completion message and file query.
		@param model ID of the model to use
		@param schema output schema
		@param token API token
		@return completion response
		~#
		function : Respond(model : String, message : API.OpenAI.FileQuery, schema : ParameterType, token : String) ~ Response {
			messages := Vector->New()<FileQuery>;
			messages->AddBack(message);

			return Respond(model, messages, -1, -1.0, -1.0, schema, token);
		}

		#~
		Model response for the given file and query
		@param message completion message and file query.
		@param model ID of the model to use
		@param token API token
		@return completion response
		~#
		function : Respond(model : String, message : API.OpenAI.FileQuery, token : String) ~ Response {
			messages := Vector->New()<FileQuery>;
			messages->AddBack(message);

			return Respond(model, messages, -1, -1.0, -1.0, Nil, token);
		}

		#~
		Model response for the given file and query
		@param model ID of the model to use
		@param message completion message and file query
		@param max_tokens maximum number of completion tokens returned by the API
		@param temperature amount of randomness in the response, valued between 0 inclusive and 2 exclusive
		@param top_p nucleus sampling threshold, valued between 0 and 1 inclusive
		@param schema output schema
		@param token API token
		@return completion response
		~#
		function : Respond(model : String, message : API.OpenAI.FileQuery, max_tokens : Int, temperature : Float, top_p : Float, schema : ParameterType, token : String) ~ Response {
			messages := Vector->New()<FileQuery>;
			messages->AddBack(message);

			return Respond(model, messages, max_tokens, temperature, top_p, schema, token);
		}

		#~
		Model response for the given file and query
		@param model ID of the model to use
		@param message completion message and file query
		@param max_tokens maximum number of completion tokens returned by the API
		@param temperature amount of randomness in the response, valued between 0 inclusive and 2 exclusive
		@param top_p nucleus sampling threshold, valued between 0 and 1 inclusive
		@param token API token
		@return completion response
		~#
		function : Respond(model : String, message : API.OpenAI.FileQuery, max_tokens : Int, temperature : Float, top_p : Float, token : String) ~ Response {
			messages := Vector->New()<FileQuery>;
			messages->AddBack(message);

			return Respond(model, messages, max_tokens, temperature, top_p, Nil, token);
		}

		#~
		Model response for the given file and query
		@param messages list of messages comprising the conversation
		@param model ID of the model to use
		@param schema output schema
		@param token API token
		@return completion response
		~#
		function : Respond(model : String, messages : Vector<FileQuery>, schema : ParameterType, token : String) ~ Response {
			return Respond(model, messages, -1, -1.0, -1.0, schema, token);
		}

		#~
		Model response for the given file and query
		@param model ID of the model to use
		@param messages list of messages comprising the conversation
		@param max_tokens maximum number of completion tokens returned by the API
		@param temperature amount of randomness in the response, valued between 0 inclusive and 2 exclusive
		@param top_p nucleus sampling threshold, valued between 0 and 1 inclusive
		@param schema output schema
		@param token API token
		@return completion response
		~#
		function : Respond(model : String, messages : Vector<FileQuery>, max_tokens : Int, temperature : Float, top_p : Float, schema : ParameterType, token : String) ~ Response {
			completion_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			completion_json->Insert("model", model);

			if(max_tokens > -1) {
				completion_json->Insert("max_tokens", max_tokens);
			};

			if(temperature >= 0.0) {
				completion_json->Insert("temperature", temperature);
			};

			if(top_p >= 0.0) {
				completion_json->Insert("top_p", top_p);
			};

			messages_json := JsonElement->New(JsonElement->JsonType->ARRAY);
			each(message in messages) {
				message_json := JsonElement->New(JsonElement->JsonType->OBJECT);
				message_json->Insert("role", message->GetRole());

				# insert file and text
				content_json := JsonElement->New(JsonElement->JsonType->ARRAY);

				file_json := JsonElement->New(JsonElement->JsonType->OBJECT);
				file_json->Insert("type", "input_file");
				file_json->Insert("file_id", message->GetFile()->GetId());
				content_json->Add(file_json);

				text_json := JsonElement->New(JsonElement->JsonType->OBJECT);
				text_json->Insert("type", "input_text");
				text_json->Insert("text", message->GetQuery());
				content_json->Add(text_json);

				message_json->Insert("content", content_json);

				#message_json := JsonElement->New(JsonElement->JsonType->OBJECT);
				#message_json->Insert("role", message->GetRole());
			
				messages_json->Add(message_json);
			};
			completion_json->Insert("input", messages_json);

			if(schema <> Nil) {
				format_json := JsonElement->New(JsonElement->JsonType->OBJECT);
				format_json->Insert("type", "json_schema");
				format_json->Insert("strict", true);
				format_json->Insert("name", "json_response");

				openai_schema := schema->ToJson();
				openai_schema->Insert("additionalProperties", false);
				format_json->Insert("schema", openai_schema);

				text_json := JsonElement->New(JsonElement->JsonType->OBJECT);
				text_json->Insert("format", format_json);

				completion_json->Insert("text", text_json);
			};

			data := completion_json->ToString()->ToByteArray();
			if(IsDebug()) {
				data->ToString()->PrintLine();
			};

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickPost(Url->New(GetBaseUrl() + "/responses"), data, "application/json", headers);
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: name='/responses' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();				
				};

				chat_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(chat_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};
				
				error_str := chat_json->FindElements("error/message");
				if(error_str <> Nil) {
					SetLastError(error_str->GetString());
					return Nil;
				};

				return Response->New(chat_json);
			};

			return Nil;
		}
		
		#~
		Model response for the given image and query
		@param message completion message and image query.
		@param model ID of the model to use
		@param token API token
		@param schema output schema
		@return completion response
		~#
		function : Respond(model : String, message : Pair<String, API.OpenAI.ImageQuery>, schema : ParameterType, token : String) ~ Response {
			messages := Vector->New()<Pair<String, API.OpenAI.ImageQuery>>;
			messages->AddBack(message);

			return Respond(model, messages, -1, -1.0, -1.0, schema, token);
		}

		#~
		Model response for the given image and query
		@param message completion message and image query.
		@param model ID of the model to use
		@param token API token
		@return completion response
		~#
		function : Respond(model : String, message : Pair<String, API.OpenAI.ImageQuery>, token : String) ~ Response {
			messages := Vector->New()<Pair<String, API.OpenAI.ImageQuery>>;
			messages->AddBack(message);

			return Respond(model, messages, -1, -1.0, -1.0, Nil, token);
		}

		#~
		Model response for the given image and query
		@param model ID of the model to use
		@param message completion message and image query
		@param max_tokens maximum number of completion tokens returned by the API
		@param temperature amount of randomness in the response, valued between 0 inclusive and 2 exclusive
		@param top_p nucleus sampling threshold, valued between 0 and 1 inclusive
		@param schema output schema
		@param token API token
		@return completion response
		~#
		function : Respond(model : String, message : Pair<String, API.OpenAI.ImageQuery>, max_tokens : Int, temperature : Float, top_p : Float, schema : ParameterType, token : String) ~ Response {
			messages := Vector->New()<Pair<String, API.OpenAI.ImageQuery>>;
			messages->AddBack(message);

			return Respond(model, messages, max_tokens, temperature, top_p, schema, token);
		}
		
		#~
		Model response for the given image and query
		@param model ID of the model to use
		@param message completion message and image query
		@param max_tokens maximum number of completion tokens returned by the API
		@param temperature amount of randomness in the response, valued between 0 inclusive and 2 exclusive
		@param top_p nucleus sampling threshold, valued between 0 and 1 inclusive
		@param schema output schema
		@param token API token
		@return completion response
		~#
		function : Respond(model : String, message : Pair<String, API.OpenAI.ImageQuery>, max_tokens : Int, temperature : Float, top_p : Float, token : String) ~ Response {
			messages := Vector->New()<Pair<String, API.OpenAI.ImageQuery>>;
			messages->AddBack(message);

			return Respond(model, messages, max_tokens, temperature, top_p, Nil, token);
		}

		#~
		Model response for the given image and query
		@param messages list of messages comprising the conversation
		@param model ID of the model to use
		@param token API token
		@param schema output schema
		@return completion response
		~#
		function : Respond(model : String, messages : Vector<Pair<String, API.OpenAI.ImageQuery>>, schema : ParameterType, token : String) ~ Response {
			return Respond(model, messages, -1, -1.0, -1.0, schema, token);
		}

		#~
		Model response for the given image and query
		@param model ID of the model to use
		@param messages list of messages comprising the conversation
		@param max_tokens maximum number of completion tokens returned by the API
		@param temperature amount of randomness in the response, valued between 0 inclusive and 2 exclusive
		@param top_p nucleus sampling threshold, valued between 0 and 1 inclusive
		@param token API token
		@param schema output schema
		@return completion response
		~#
		function : Respond(model : String, messages : Vector<Pair<String, API.OpenAI.ImageQuery>>, max_tokens : Int, temperature : Float, top_p : Float, schema : ParameterType, token : String) ~ Response {
			completion_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			completion_json->Insert("model", model);

			if(max_tokens > -1) {
				completion_json->Insert("max_tokens", max_tokens);
			};

			if(temperature >= 0.0) {
				completion_json->Insert("temperature", temperature);
			};

			if(top_p >= 0.0) {
				completion_json->Insert("top_p", top_p);
			};

			messages_json := JsonElement->New(JsonElement->JsonType->ARRAY);
			each(message in messages) {
				message_json := JsonElement->New(JsonElement->JsonType->OBJECT);
				message_json->Insert("role", message->GetFirst());
				
				image_query := message->GetSecond();

				if(image_query->GetQuery() = Nil) {
					return Nil;
				};

				if(image_query->GetImageUrl() = Nil & image_query->GetImage() = Nil) {
					return Nil;
				};

				# content array
				content_json := JsonElement->New(JsonElement->JsonType->ARRAY);

				# text query
				text_query_json := JsonElement->New(JsonElement->JsonType->OBJECT);
				text_query_json->Insert("type", "input_text");
				text_query_json->Insert("text", image_query->GetQuery());
				content_json->Add(text_query_json);

				# image query
				image_query_json := JsonElement->New(JsonElement->JsonType->OBJECT);

				if(image_query->GetImage() = Nil) {
					image_query_json->Insert("image_url", image_query->GetImageUrl()->GetUrl());
				}
				else {
					image_type_str := image_query->GetMimeType();
					base64_image_str := "data:{$image_type_str};base64,";
					base64_image_str += Cipher.Encrypt->Base64(image_query->GetImage());
					image_query_json->Insert("image_url", base64_image_str);
				};

				image_query_json->Insert("type", "input_image");
				content_json->Add(image_query_json);

				message_json->Insert("content", content_json);
				messages_json->Add(message_json);
			};
			completion_json->Insert("input", messages_json);

			data := completion_json->ToString()->ToByteArray();
			if(IsDebug()) {
				data->ToString()->PrintLine();
			};

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickPost(Url->New(GetBaseUrl() + "/responses"), data, "application/json", headers);
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: name='/responses' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();				
				};

				chat_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(chat_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};
				
				error_str := chat_json->FindElements("error/message");
				if(error_str <> Nil) {
					SetLastError(error_str->GetString());
					return Nil;
				};

				return Response->New(chat_json);
			};

			return Nil;
		}
	}

	#~
	Response output
	~#
	class Output from EndPoint {
		@id : String;
		@type : String;
		@status : String;
		@role : String;
		@contents : Vector<Content>;

		New(json_elem : JsonElement) {
			Parent();
			
			@id := json_elem->Get("id")->GetString();
			@type := json_elem->Get("type")->GetString();
			@status := json_elem->Get("status")->GetString();
			@role := json_elem->Get("role")->GetString();

			@contents := Vector->New()<Content>;
			contents_json := json_elem->Get("content");
			each(content_json in contents_json) {
				@contents->AddBack(Content->New(content_json));
			};
		}

		#~
		Get index
		@return index
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get type
		@return type
		~#
		method : public : GetType() ~ String {
			return @type;
		}

		#~
		Get role
		@return role
		~#
		method : public : GetRole() ~ String {
			return @role;
		}

		#~
		Get finish reason
		@return finish reason
		~#
		method : public : GetStatus() ~ String {
			return @status;
		}

		#~
		Get content
		@return content
		~#
		method : public : GetContents() ~ Vector<Content> {
			return @contents;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			short_id := @id->SubString(10);
			buffer := "Output: [short_id='{$short_id}', type='{$@type}', status='{$@status}', role='{$@role}'";
			
			each(content in @contents) {
				buffer += "\n\t\t";
				buffer += content->ToString();
			};
			buffer += ']';

			return buffer;
		}
	}

	#~
	Response content 
	~#
	class Content from EndPoint {
		@type : String;
		@text : String;
		# TODO: @annotations : Vector<Annotation>;
		
		New(json_elem : JsonElement) {
			Parent();
			
			@type := json_elem->Get("type")->GetString();
			@text := json_elem->Get("text")->GetString();
		}

		#~
		Get type
		@return type
		~#
		method : public : GetType() ~ String {
			return @type;
		}

		#~
		Get text
		@return text
		~#
		method : public : GetText() ~ String {
			return @text;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			text_len := @text->Size();
			short_text := @text->SubString(64);
			return "Content: [type='{$@type}', short_text='{$short_text}', text_len={$text_len}]"; 
		}
	}
}

#~
Support for legacy OpenAI chat APIs (-lib openai)
~#
bundle API.OpenAI.Chat {
	#~
	Model response for a given text or image query
	~#
	class Completion from EndPoint {
		@id : String;
		@object : String;
		@created_at : Int;
		@model : String;
		@choices : Vector<API.OpenAI.Chat.Choice>;

		New(chat_json : JsonElement) {
			Parent();

			@id := chat_json->Get("id")->GetString();
			@object := chat_json->Get("object")->GetString();
			@created_at := chat_json->Get("created")->GetInt();
			@model := chat_json->Get("model")->GetString();

			@choices := Vector->New()<API.OpenAI.Chat.Choice>;
			choices_json := chat_json->Get("choices");
			each(choice_json in choices_json) {
				@choices->AddBack(Choice->New(choice_json));
			};
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		ID of the model to use
		@return ID of the model to use
		~#
		method : public : GetModel() ~ String {
			return @model;
		}

		#~
		List of chat completion choices
		@return completion choices
		~#
		method : public : GetChoices() ~ Vector<API.OpenAI.Chat.Choice> {
			return @choices;
		}

		#~
		List of chat completion choices
		@return completion choices
		~#
		method : public : GetFirstChoice() ~ API.OpenAI.Chat.Choice {
			if(@choices->Size() > 0) {
				return @choices->Get(0);
			};

			return Nil;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {			
			buffer := "[id='";
			buffer += @id;

			buffer += "', object='"
			buffer += @object;

			buffer += "', model='"
			buffer += @model;

			buffer += "', created_at="
			buffer += @created_at;

			buffer += "\nchoices: ["
			for(i := 0; i < @choices->Size(); i +=1 ;) {
				buffer += i;
				buffer += ": ";
				
				buffer += @choices->Get(i)->ToString();
				
				if(i + 1 < @choices->Size()) {
					buffer += ',';
				};
			};
			buffer += ']';

			return buffer;
		}

		#~
		Model response for the given query
		@param message completion message and image query.
		@param model ID of the model to use
		@param token API token
		@return completion response
		~#
		function : Complete(model : String, message : Pair<String, String>, token : String) ~ Completion {
			messages := Vector->New()<Pair<String, String>>;
			messages->AddBack(message);

			return Complete(model, messages, -1, -1.0, -1.0, token);
		}

		#~
		Model response for the given query
		@param model ID of the model to use
		@param message completion message and image query
		@param max_tokens maximum number of completion tokens returned by the API
		@param temperature amount of randomness in the response, valued between 0 inclusive and 2 exclusive
		@param top_p nucleus sampling threshold, valued between 0 and 1 inclusive
		@param token API token
		@return completion response
		~#
		function : Complete(model : String, message : Pair<String, String>, max_tokens : Int, temperature : Float, top_p : Float, token : String) ~ Completion {
			messages := Vector->New()<Pair<String, String>>;
			messages->AddBack(message);

			return Complete(model, messages, max_tokens, temperature, top_p, token);
		}

		#~
		Model response for the given query
		@param messages list of messages comprising the conversation
		@param model ID of the model to use
		@param token API token
		@return completion response
		~#
		function : Complete(model : String, messages : Vector<Pair<String, String>>, token : String) ~ Completion {
			return Complete(model, messages, -1, -1.0, -1.0, token);
		}

		#~
		Model response for the given query
		@param model ID of the model to use
		@param messages list of messages comprising the conversation
		@param max_tokens maximum number of completion tokens returned by the API
		@param temperature amount of randomness in the response, valued between 0 inclusive and 2 exclusive
		@param top_p nucleus sampling threshold, valued between 0 and 1 inclusive
		@param token API token
		@return completion response
		~#
		function : Complete(model : String, messages : Vector<Pair<String, String>>, max_tokens : Int, temperature : Float, top_p : Float, token : String) ~ Completion {
			completion_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			completion_json->Insert("model", model);

			if(max_tokens > -1) {
				completion_json->Insert("max_tokens", max_tokens);
			};

			if(temperature >= 0.0) {
				completion_json->Insert("temperature", temperature);
			};

			if(top_p >= 0.0) {
				completion_json->Insert("top_p", top_p);
			};

			messages_json := JsonElement->New(JsonElement->JsonType->ARRAY);
			each(message in messages) {
				message_json := JsonElement->New(JsonElement->JsonType->OBJECT);
				message_json->Insert("role", message->GetFirst());
				message_json->Insert("content", message->GetSecond());
				messages_json->Add(message_json);
			};
			completion_json->Insert("messages", messages_json);

			data := completion_json->ToString()->ToByteArray();
			if(IsDebug()) {
				data->ToString()->PrintLine();
			};

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickPost(Url->New(GetBaseUrl() + "/chat/completions"), data, "application/json", headers);
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: name='/chat/completions' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();				
				};

				chat_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(chat_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};
				
				error_str := chat_json->FindElements("error/message");
				if(error_str <> Nil) {
					SetLastError(error_str->GetString());
					return Nil;
				};

				return Completion->New(chat_json);
			};

			return Nil;
		}
		
		#~
		Model response for the given image and query
		@param message completion message and image query.
		@param model ID of the model to use
		@param token API token
		@return completion response
		~#
		function : Complete(model : String, message : Pair<String, API.OpenAI.ImageQuery>, token : String) ~ Completion {
			messages := Vector->New()<Pair<String, API.OpenAI.ImageQuery>>;
			messages->AddBack(message);

			return Complete(model, messages, -1, -1.0, -1.0, token);
		}

		#~
		Model response for the given image and query
		@param model ID of the model to use
		@param message completion message and image query
		@param max_tokens maximum number of completion tokens returned by the API
		@param temperature amount of randomness in the response, valued between 0 inclusive and 2 exclusive
		@param top_p nucleus sampling threshold, valued between 0 and 1 inclusive
		@param token API token
		@return completion response
		~#
		function : Complete(model : String, message : Pair<String, API.OpenAI.ImageQuery>, max_tokens : Int, temperature : Float, top_p : Float, token : String) ~ Completion {
			messages := Vector->New()<Pair<String, API.OpenAI.ImageQuery>>;
			messages->AddBack(message);

			return Complete(model, messages, max_tokens, temperature, top_p, token);
		}

		#~
		Model response for the given image and query
		@param messages list of messages comprising the conversation
		@param model ID of the model to use
		@param token API token
		@return completion response
		~#
		function : Complete(model : String, messages : Vector<Pair<String, API.OpenAI.ImageQuery>>, token : String) ~ Completion {
			return Complete(model, messages, -1, -1.0, -1.0, token);
		}

		#~
		Model response for the given image and query
		@param model ID of the model to use
		@param messages list of messages comprising the conversation
		@param max_tokens maximum number of completion tokens returned by the API
		@param temperature amount of randomness in the response, valued between 0 inclusive and 2 exclusive
		@param top_p nucleus sampling threshold, valued between 0 and 1 inclusive
		@param token API token
		@return completion response
		~#
		function : Complete(model : String, messages : Vector<Pair<String, API.OpenAI.ImageQuery>>, max_tokens : Int, temperature : Float, top_p : Float, token : String) ~ Completion {
			completion_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			completion_json->Insert("model", model);

			if(max_tokens > -1) {
				completion_json->Insert("max_tokens", max_tokens);
			};

			if(temperature >= 0.0) {
				completion_json->Insert("temperature", temperature);
			};

			if(top_p >= 0.0) {
				completion_json->Insert("top_p", top_p);
			};

			messages_json := JsonElement->New(JsonElement->JsonType->ARRAY);
			each(message in messages) {
				message_json := JsonElement->New(JsonElement->JsonType->OBJECT);
				message_json->Insert("role", message->GetFirst());
				
				image_query := message->GetSecond();

				if(image_query->GetQuery() = Nil) {
					return Nil;
				};

				if(image_query->GetImageUrl() = Nil & image_query->GetImage() = Nil) {
					return Nil;
				};

				# content array
				content_json := JsonElement->New(JsonElement->JsonType->ARRAY);

				# text query
				text_query_json := JsonElement->New(JsonElement->JsonType->OBJECT);
				text_query_json->Insert("type", "text");
				text_query_json->Insert("text", image_query->GetQuery());
				content_json->Add(text_query_json);

				# image query
				image_url_json := JsonElement->New(JsonElement->JsonType->OBJECT);
				if(image_query->GetImage() = Nil) {
					image_url_json->Insert("url", image_query->GetImageUrl()->GetUrl());
				}
				else {
					base64_image_str := "data:image/jpeg;base64,";
					base64_image_str += Cipher.Encrypt->Base64(image_query->GetImage());
					image_url_json->Insert("url", base64_image_str);
				};

				image_query_json := JsonElement->New(JsonElement->JsonType->OBJECT);
				image_query_json->Insert("type", "image_url");
				image_query_json->Insert("image_url", image_url_json);
				content_json->Add(image_query_json);

				message_json->Insert("content", content_json);
				messages_json->Add(message_json);
			};
			completion_json->Insert("messages", messages_json);

			data := completion_json->ToString()->ToByteArray();
			if(IsDebug()) {
				data->ToString()->PrintLine();
			};

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickPost(Url->New(GetBaseUrl() + "/chat/completions"), data, "application/json", headers);
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: name='/chat/completions' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();				
				};

				chat_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(chat_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};
				
				error_str := chat_json->FindElements("error/message");
				if(error_str <> Nil) {
					SetLastError(error_str->GetString());
					return Nil;
				};

				return Completion->New(chat_json);
			};

			return Nil;
		}
	}

	#~
	Completion choice
	~#
	class Choice from EndPoint {
		@index : Int;
		@finish_reason : String;
		@message : Pair<String, String>;

		New(chat_json : JsonElement) {
			Parent();
			@index := chat_json->Get("index")->GetInt();
			@finish_reason := chat_json->Get("finish_reason")->GetString();
			message_json := chat_json->Get("message");

			role := message_json->Get("role")->GetString();
			content := message_json->Get("content")->GetString();
			@message := Pair->New(role, content)<String, String>;
		}

		#~
		Get index
		@return index
		~#
		method : public : GetIndex() ~ Int {
			return @index;
		}

		#~
		Get finish reason
		@return finish reason
		~#
		method : public : GetFinishReason() ~ String {
			return @finish_reason;
		}

		#~
		Get message
		@return message
		~#
		method : public : GetMessage() ~ Pair<String, String> {
			return @message;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			role := @message->GetFirst();
			content := @message->GetSecond();
			return "[index={$@index}, finish_reason='{$@finish_reason}', role={$role}, content={$content}]"; 
		}
	}

	#~
	Chat conversation assistant 
	~#
	class Conversation {
		@assistant : Assistant;
		@enable_spinner : Bool;
		@thread : API.OpenAI.Thread;
		@token : String;
		@funcs : Map<String, Func2Ref<JsonElement, JsonElement>>;

		#~
		Constructor 
		@param assistant assistant
		@param enable_spinner true to enable console spinner, false to disable
		@param token API token
		~#
		New(assistant : Assistant, enable_spinner : Bool, token : String) {
			@assistant := assistant;
			@enable_spinner := enable_spinner;
			@token := token;
			@thread := API.OpenAI.Thread->Create(token);
			@funcs := Map->New()<String, Func2Ref<JsonElement, JsonElement>>;
		}

		#~
		Constructor 
		@param assistant assistant
		@param token API token
		~#
		New(assistant : Assistant, token : String) {
			@assistant := assistant;
			@token := token;
			@thread := API.OpenAI.Thread->Create(token);
			@funcs := Map->New()<String, Func2Ref<JsonElement, JsonElement>>;
		}

		#~
		Maps an OpenAI function call (via webhooks) 
		@param name OpenAI function name
		@param func function to map
		@return true if successful, false otherwise
		~#
		method : public : AddFunction(name : String, func : (JsonElement) ~ JsonElement) ~ Bool {
			if(@funcs->Has(name)) {
				return false;
			};

			@funcs->Insert(name, Func2Ref->New(func)<JsonElement, JsonElement>);
			return true;
		}

		method : CallFunction(name : String, params : JsonElement) ~ JsonElement {
			func_ref := @funcs->Find(name)<Func2Ref<JsonElement, JsonElement>>;
			if(func_ref <> Nil) {
				func := func_ref->Get();
				return func(params);
			};

			return Nil;
		}

		#~
		Sends a message to the assistant 
		@param query message to send
		@param user user name
		@return response message, Nil of error
		~#
		method : public : Send(query : String, user : String)  ~ Message {
			Message->Create(user, query, @thread, @token);

			run := API.OpenAI.Run->Create(@assistant, @thread, @token);

			# poll ever 3/4 a second for max of 15 seconds
			is_done := false;
			for(i := 0; <>is_done & i < 20; i += 1;) {
				System.Concurrency.Thread->Sleep(750);
				run->Refresh(@token);
				
				if(@enable_spinner) {
					System.Utility.Spinner->Next();
				};

				if(run->IsFunctionCall()) {
					func_call := run->GetFunctionCall()<String, String, String>;

					func_call_name := Data.JSON.JsonElement->Decode(func_call->GetFirst());
					func_call_params := Data.JSON.JsonElement->Decode(func_call->GetSecond());
					response_json := CallFunction(func_call_name, JsonParser->TextToElement(func_call_params));
					if(response_json <> Nil) {
						func_callback_id := Data.JSON.JsonElement->Decode(func_call->GetThird());
						if(<>run->SubmitToolOutputs(response_json, func_callback_id, @token)) {
							Run->GetLastError()->ErrorLine();
						};
					}
					else {
						Run->SetLastError("Error: invalid function call response");
						return Nil;
					};
				}
				else {
					is_done := run->GetStatus()->Equals("completed");
				};
			};

			if(@enable_spinner) {
				System.Utility.Spinner->Last();
			};

			# last message
			messages := Message->ListMessages(@thread, @token);
			if(<>messages->IsEmpty()) {
				return messages->First();
			};

			return Nil;
		}

		#~
		Closes the chat session
		@return true if successful, false otherwise
		~#
		method : public : Close() ~ Bool {
			return Thread->Delete(@thread->GetId(), @token);
		}
	}
}

#~
Support for fine-tuning models (-lib openai)
~#
bundle API.OpenAI.Tuning {
	#~
	OpenAI fine tuning 
	~#
	class Tuner from EndPoint {
		@id : String;
		@object : String;
		@model : String;
		@created_at : Int;
		@finished_at : Int;
		@fine_tuned_model : String;
		@organization_id : String;
		@status : String;
		@training_file : String;
		@seed : String;
		@n_epochs : String;
		@batch_size : String;
		@learning_rate_multiplier : String;
		@validation_file : String;
		@trained_tokens : String;
		@user_provided_suffix : String;
		@estimated_finish : String;		
		@error_code : String;
		@error_param : String;
		@error_message : String;

		New(tune_json : JsonElement) {
			Parent();

			@id := tune_json->Get("id")->GetString();
			@object := tune_json->Get("object")->GetString();
			@model := tune_json->Get("model")->GetString();
			@created_at := tune_json->Get("created_at")->GetInt();
			
			finished_at_json := tune_json->Get("finished_at");
			if(finished_at_json <> Nil & <>finished_at_json->IsNull()) {
				@finished_at := finished_at_json->GetInt();
			};

			fine_tuned_model_json := tune_json->Get("fine_tuned_model");
			if(fine_tuned_model_json <> Nil & <>fine_tuned_model_json->IsNull()) {
				@fine_tuned_model := fine_tuned_model_json->GetString();
			};

			@organization_id := tune_json->Get("organization_id")->GetString();
			@status := tune_json->Get("status")->GetString();
			@training_file := tune_json->Get("training_file")->GetString();
			@seed := tune_json->Get("seed")->GetString();

			hyper_parameters_json := tune_json->Get("hyperparameters");
			if(hyper_parameters_json <> Nil & <>hyper_parameters_json->IsNull()) {
				@n_epochs := hyper_parameters_json->Get("n_epochs")->GetString();
				@batch_size := hyper_parameters_json->Get("batch_size")->GetString();
				@learning_rate_multiplier := hyper_parameters_json->Get("learning_rate_multiplier")->GetString();
			};

			validation_file_json := tune_json->Get("validation_file");
			if(validation_file_json <> Nil & <>validation_file_json->IsNull()) {
				@validation_file := validation_file_json->GetString();
			};

			trained_tokens_json := tune_json->Get("trained_tokens");
			if(trained_tokens_json <> Nil & <>trained_tokens_json->IsNull()) {
				@trained_tokens := trained_tokens_json->GetString();
			};

			user_provided_suffix_json := tune_json->Get("user_provided_suffix");
			if(user_provided_suffix_json <> Nil & <>user_provided_suffix_json->IsNull()) {
				@user_provided_suffix := user_provided_suffix_json->GetString();
			};

			error_code_json := tune_json->FindElements("error/code");
			if(error_code_json <> Nil) {
				@error_code := error_code_json->GetString();
				@error_param := tune_json->FindElements("error/param")->GetString();
				@error_message := tune_json->FindElements("error/message")->GetString();
			};

			estimated_finish_json := tune_json->Get("estimated_finish");
			if(estimated_finish_json <> Nil & <>estimated_finish_json->IsNull()) {
				@estimated_finish := estimated_finish_json->GetString();
			};

			#~
				"result_files":	[],
				"integrations":	[]
			~#
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		Unix timestamp (in seconds) of when the job finished
		@return time with the job finished
		~#
		method : public : GetFinishedAt() ~ Int {
			return @finished_at;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Get the name of the training file
		@return name of the training file
		~#
		method : public : GetTrainingFilename() ~ String {
			return @training_file;
		}

		#~
		Get status of the tuning job
		@return name of the training file
		~#
		method : public : GetStatus() ~ String {
			return @status;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			fine_tuned_model := @fine_tuned_model = Nil ? "<null>" : @fine_tuned_model;
			validation_file := @validation_file = Nil ? "<null>" : @validation_file;
			trained_tokens := @trained_tokens = Nil ? "<null>" : @trained_tokens;
			user_provided_suffix := @user_provided_suffix = Nil ? "<null>" : @user_provided_suffix;
			estimated_finish := @estimated_finish = Nil ? "<null>" : @estimated_finish;
			error_code := @error_code = Nil ? "<null>" : @error_code;
			error_param := @error_param = Nil ? "<null>" : @error_param;
			error_message := @error_message = Nil ? "<null>" : @error_message;
			
			buffer := "[id='{$@id}', object='{$@object}', model={$@model}, created_at={$@created_at}, ";
			buffer += "finished_at='{$@finished_at}', fine_tuned_model='{$fine_tuned_model}', ";
			buffer += "n_epochs='{$@n_epochs}', batch_size='{$@batch_size}, learning_rate_multiplier='{$@learning_rate_multiplier}', ";
			buffer += "validation_file='{$validation_file}', trained_tokens='{$trained_tokens}', ";
			buffer += "estimated_finish='{$estimated_finish}', status='{$@status}', user_provided_suffix='{$user_provided_suffix}', ";
			buffer += "error_code='{$error_code}', error_param='{$error_param}', error_message='{$error_message}', ";
			buffer += "training_file='{$@training_file}, organization_id='{$@organization_id}']";

			return buffer;
		}

		#~
		Create a fine-turning job using an uploaded file as training data
		@param model model name
		@param training_file_id uploaded training file ID to a file in JSONL format
		@param token API token
		@return fine-tuning job instance
		~#
		function : Create(model : String, training_file_id : String, token : String) ~ API.OpenAI.Tuning.Tuner {
			tune_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			tune_json->Insert("model", model);
			tune_json->Insert("training_file", training_file_id);
			data := tune_json->ToString()->ToByteArray();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickPost(Url->New(GetBaseUrl() + "/fine_tuning/jobs"), data, "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();
				tune_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(tune_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};

				error_str := tune_json->FindElements("error/message");				
				if(error_str <> Nil) {
					SetLastError(error_str->GetString());
					return Nil;
				};

				return Tuner->New(tune_json);
			};

			return Nil;
		}

		#~
		Loads a list fine-tuning jobs
		@param token API token
		@return fine-tuning jobs
		~#
		function : ListJobs(token : String) ~ Vector<API.OpenAI.Tuning.Tuner> {
			return ListJobs(-1, token);
		}

		#~
		Loads a list fine-tuning jobs
		@param limit number of jobs to retrieve
		@param token API token
		@return fine-tuning jobs
		~#
		function : ListJobs(limit : Int, token : String) ~ Vector<API.OpenAI.Tuning.Tuner> {
			jobs := Vector->New()<API.OpenAI.Tuning.Tuner>

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			
			url_str := GetBaseUrl() + "/fine_tuning/jobs";
			if(limit > 0) {
				url_str += "?limit={$limit}";
			};

			response := HttpsClient->QuickGet(Url->New(url_str), headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();
				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				error_str := root_json->FindElements("error/message");				
				if(error_str <> Nil) {
					SetLastError(error_str->GetString());
					return Nil;
				};

				jobs_json := root_json->Get("data");
				each(job_json in jobs_json) {
					jobs->AddBack(API.OpenAI.Tuning.Tuner->New(job_json));
				};
			};

			return jobs;
		}

		#~
		Lists events for a job
		@param job_id job ID
		@param token API token
		@return job events
		~#
		function : ListEvents(job_id : String, token : String) ~ Vector<API.OpenAI.Tuning.Job> {
			return ListEvents(job_id, -1, token);
		}

		#~
		Lists events for a job
		@param job_id job ID
		@param limit number of jobs to retrieve		
		@param token API token
		@return job events
		~#
		function : ListEvents(job_id : String, limit : Int, token : String) ~ Vector<API.OpenAI.Tuning.Job> {
			events := Vector->New()<API.OpenAI.Tuning.Job>

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			
			url_str := GetBaseUrl() + "/fine_tuning/jobs/{$job_id}/events";
			if(limit > 0) {
				url_str += "?limit={$limit}";
			};

			response := HttpsClient->QuickGet(Url->New(url_str), headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();
				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				error_str := root_json->FindElements("error/message");				
				if(error_str <> Nil) {
					SetLastError(error_str->GetString());
					return Nil;
				};

				events_json := root_json->Get("data");
				each(job_json in events_json) {
					events->AddBack(API.OpenAI.Tuning.Job->New(job_json));
				};
			};

			return events;
		}

		#~
		Lists checkpoints for a fine-tuning job
		@param job_id job ID
		@param token API token
		@return job checkpoints
		~#
		function : ListCheckpoints(job_id : String, token : String) ~ Vector<API.OpenAI.Tuning.Checkpoint> {
			return ListCheckpoints(job_id, -1, token);
		}

		#~
		Lists checkpoints for a fine-tuning job
		@param job_id job ID
		@param limit number of jobs to retrieve		
		@param token API token
		@return job checkpoints
		~#
		function : ListCheckpoints(job_id : String, limit : Int, token : String) ~ Vector<API.OpenAI.Tuning.Checkpoint> {
			checkpoints := Vector->New()<API.OpenAI.Tuning.Checkpoint>

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			
			url_str := GetBaseUrl() + "/fine_tuning/jobs/{$job_id}/checkpoints";
			if(limit > 0) {
				url_str += "?limit={$limit}";
			};

			response := HttpsClient->QuickGet(Url->New(url_str), headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();
				
				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				error_str := root_json->FindElements("error/message");				
				if(error_str <> Nil) {
					SetLastError(error_str->GetString());
					return Nil;
				};

				checkpoints_json := root_json->Get("data");
				each(checkpoint_json in checkpoints_json) {
					checkpoints->AddBack(API.OpenAI.Tuning.Checkpoint->New(checkpoint_json));
				};
			};

			return checkpoints;
		}

		#~
		Load a tuning job
		@param job_id tuning job ID
		@param token API token
		@return tuning reference
		~#
		function : Load(job_id : String, token : String) ~ API.OpenAI.Tuning.Tuner {
			tuning : API.OpenAI.Tuning.Tuner;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickGet(Url->New(GetBaseUrl() + "/fine_tuning/jobs/{$job_id}"), "application/json", headers);
			
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				tuning_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(tuning_json = Nil) {
					return Nil;
				};

				tuning := API.OpenAI.Tuning.Tuner->New(tuning_json);
			};

			return tuning;
		}

		#~
		Cancel a tuning job
		@param job_id tuning job ID
		@param token API token
		@return canceled tuning reference
		~#
		function : Cancel(job_id : String, token : String) ~ API.OpenAI.Tuning.Tuner {
			tuning : API.OpenAI.Tuning.Tuner;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickPost(Url->New(GetBaseUrl() + "/fine_tuning/jobs/{$job_id}/cancel"), 
				Byte->New[0], "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				tuning_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(tuning_json = Nil) {
					return Nil;
				};

				tuning := API.OpenAI.Tuning.Tuner->New(tuning_json);
			};

			return tuning;
		}
	}

	#~
	Fine-tuning checkpoint
	~#
	class Checkpoint {
		@id : String;
		@object : String;
		@created_at : Int;
		@fine_tuning_job_id : String;
		@step_number : Int;
		@full_valid_loss : String;
		@full_valid_mean_token_accuracy : Float;
		
		New(job_json : JsonElement) {
			@id := job_json->Get("id")->GetString();
			@object := job_json->Get("object")->GetString();
			@created_at := job_json->Get("created_at")->GetInt();
			@fine_tuning_job_id := job_json->Get("fine_tuning_job_id")->GetString();
			@step_number := job_json->Get("step_number")->GetInt();

			metrics_json := job_json->FindElements("metrics/full_valid_loss");
			if(metrics_json <> Nil) {
				@full_valid_loss := metrics_json->GetString();
				@full_valid_mean_token_accuracy := job_json->FindElements("metrics/full_valid_mean_token_accuracy")->GetFloat();
			};
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			full_valid_loss := @full_valid_loss = Nil ? "<null>" : @full_valid_loss;
			
			buffer := "[id='{$@id}', object='{$@object}', created_at={$@created_at}, ";
			buffer += "fine_tuning_job_id='{$@fine_tuning_job_id}', step_number={$@step_number}, ";
			buffer += "full_valid_loss='{$full_valid_loss}', full_valid_mean_token_accuracy={$@full_valid_mean_token_accuracy}]";

			return buffer;
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @fine_tuning_job_id;
		}

		#~
		Get checkpoint step
		@return checkpoint step
		~#
		method : public : GetStep() ~ Int {
			return @step_number;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		Get object job API ID
		@return job ID
		~#
		method : public : GetJobId() ~ String {
			return @id;
		}
	}

	#~
	Fine-tuning job
	~#
	class Job {
		@id : String;
		@object : String;
		@created_at : Int;
		@level : String;
		@message : String;
		@type : String;
		@error_code : String;
		@error_param : String;

		New(tune_json : JsonElement) {
			@id := tune_json->Get("id")->GetString();
			@object := tune_json->Get("object")->GetString();
			@created_at := tune_json->Get("created_at")->GetInt();
			@level := tune_json->Get("level")->GetString();
			@message := tune_json->Get("message")->GetString();
			@type := tune_json->Get("type")->GetString();

			error_code_json := tune_json->FindElements("data/error_code");
			if(error_code_json <> Nil) {
				@error_code := error_code_json->GetString();
				@error_param := tune_json->FindElements("data/error_param")->GetString();
			};
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		Get the level
		@return level
		~#
		method : public : GetLevel() ~ String {
			return @level;
		}

		#~
		Get message
		@return message
		~#
		method : public : GetMessage() ~ String {
			return @message;
		}

		#~
		Get type
		@return type
		~#
		method : public : GetType() ~ String {
			return @type;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			error_code := @error_code = Nil ? "<null>" : @error_code;
			error_param := @error_param = Nil ? "<null>" : @error_param;

			buffer := "[id='{$@id}', object='{$@object}', created_at={$@created_at}, level='{$@level}', ";
			buffer += "message='{$@message}', type='{$@type}', error_code='{$error_code}', error_param='{$error_param}']";

			return buffer;
		}
	}
}

#~
Support for OpenAIs models, assistants, realtime and general APIs (-lib openai)
~#
bundle API.OpenAI {
	#~
	Realtime API support
	~#
	class Realtime {
		#~
		Query with text input and text and audio outputs
		@param text text query
		@param model model name
		@param wait_sec time to wait for response to build, in seconds
		@param token API token
		@return pair with text and binary audio outputs
		~#
		function : Respond(text : String, model : String, wait_sec : Int, token : String) ~ Pair<String, ByteArrayRef> {
			client := Connect(Url->New("wss://api.openai.com/v1/realtime?model={$model}"), token);
			if(<>SendQuery(text, client)) {
				">>> Error sending query <<<"->PrintLine();
				return Nil;
			};

			# binary audio and text
			response := ReceiveResponse(client, wait_sec);
			client->CloseSocket();

			return response;
		}

		function : private : Connect(url : Url, token : String) ~ SecureWebSocket {
			client := SecureWebSocket->New(url);
			client->AddHeader("Authorization", "Bearer {$token}");
			client->AddHeader("OpenAI-Beta", "realtime=v1");

			if(client->Connect()) {
				recv_msg := client->ReadSocketText();
				if(recv_msg = Nil) {
					return Nil;
				};

				response_json := JsonParser->TextToElement(recv_msg);
				if(response_json = Nil) {
					status_code := client->GetStatusMessage();
					">>> closed: code={$status_code} <<<"->PrintLine();

					return Nil;
				};

				type_str := response_json->Get("type")->GetString();
				if(<>type_str->Equals("session.created")) {
					status_code := client->GetStatusMessage();
					">>> closed: code={$status_code} <<<"->PrintLine();

					return Nil;
				};

				return client;
			};

			return Nil;
		}

		function : private : SendQuery(query : String, client : SecureWebSocket) ~ Bool {
			builder := JsonBuilder->New();
			convo_json := builder->PushObject();
			convo_json->Insert("type", "conversation.item.create");

			item_json := builder->PushObject("item");
			item_json->Insert("type", "message");
			item_json->Insert("role", "user");
			
			content_elem_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			content_elem_json->Insert("type", "input_text");
	        content_elem_json->Insert("text", query)

			content_array_json := JsonElement->New(JsonElement->JsonType->ARRAY);
			content_array_json->Add(content_elem_json);
			item_json->Insert("content", content_array_json);

			send_msg := builder->PopAll()->ToString();
			# "send_msg_1=\"{$send_msg}\""->PrintLine();
			client->WriteSocket(send_msg);

			recv_msg := client->ReadSocketText();
			if(recv_msg = Nil) {
				status_code := client->GetStatusMessage();
				">>> closed: code={$status_code} <<<"->PrintLine();
				return false;
			};

			response_json := JsonParser->TextToElement(recv_msg);
			if(response_json = Nil) {
				">>> Error: Unable to parse response <<<"->ErrorLine();
			};

			type_str := response_json->Get("type")->GetString();
			if(<>type_str->Equals("conversation.item.created")) {
				error_msg := response_json->Get("error")->Get("message")->GetString();
				">>> Error: {$error_msg} <<<"->ErrorLine();
				return false;
			};

			status := response_json->Get("item")->Get("status")->GetString();
			if(<>status->Equals("completed")) {
				">>> Error: Unexpected: status={$status} <<<"->ErrorLine();
				return false;
			};

			builder := JsonBuilder->New();
			create_json := builder->PushObject();
			create_json->Insert("type", "response.create");
			create_response_json := create_json->PushObject("response");
			create_response_json->Insert("voice", "sage");
	       	create_response_json->Insert("output_audio_format", "pcm16");
	       	create_response_json->Insert("tool_choice", "auto");

			modalities_array_json := JsonElement->New(JsonElement->JsonType->ARRAY);
			modalities_array_json->Add("text");
			modalities_array_json->Add("audio");
			create_response_json->Insert("modalities", modalities_array_json);

	        send_msg := builder->PopAll()->ToString();
			# "send_msg_2=\"{$send_msg}\""->PrintLine();
			client->WriteSocket(send_msg);

			recv_msg := client->ReadSocketText();
			if(recv_msg = Nil) {
				status_code := client->GetStatusMessage();
				">>> closed: code={$status_code} <<<"->PrintLine();
				return false;
			};

			response_json := JsonParser->TextToElement(recv_msg);
			if(response_json = Nil) {
				">>> Error: Unable to parse response <<<"->ErrorLine();
			};

			type_str := response_json->Get("type")->GetString();
			if(<>type_str->Equals("response.created")) {
				error_msg := response_json->Get("error")->Get("message")->GetString();
				">>> Error: {$error_msg} <<<"->ErrorLine();
				return false;
			};

			return true;
		}

		function : private : ReceiveResponse(client : SecureWebSocket, wait_sec : Int) ~ Pair<String, ByteArrayRef> {
			response_text := "";
			response_audio := "";
				
			is_done := false;
			while(<>is_done) {
				recv_msg := client->ReadSocketText();
				if(recv_msg = Nil) {
					return Nil;
				};

				response_json := JsonParser->TextToElement(recv_msg);
				if(response_json = Nil) {
					">>> Error: Unable to parse response <<<"->ErrorLine();
					return Nil;
				};

				type_str := response_json->Get("type")->GetString();
				if(type_str->Equals("response.text.delta") | type_str->Equals("response.audio_transcript.delta")) {
					response_text += response_json->Get("delta")->GetString();
				}
				else if(type_str->Equals("response.audio.delta")) {
					response_audio += response_json->Get("delta")->GetString();
				}
				else if(type_str->Equals("response.done")) {
					is_done := true;
				}
				else if(type_str->Equals("response.cancelled")) {
					response_text := "";
				}
				else if(type_str->Equals("conversation.item.created")) {
					status := response_json->Get("item")->Get("status")->GetString();
					if(<>status->Equals("in_progress")) {
						">>> Error: Unexpected: status={$status} <<<"->ErrorLine();
						return Nil;
					};
					System.Concurrency.Thread->Sleep(wait_sec * 1000);
				}
				else if(type_str->Equals("rate_limits.updated")) {
					rate_limits := response_json->Get("rate_limits");
					if(rate_limits->Size() <> 2) {
						">>> Error invalid rate limits <<<"->ErrorLine();
						return Nil;
					};
				}
				else if(<>type_str->EndsWith(".added") & <>type_str->EndsWith(".done")) {
					">>> Error unexpected type: {$recv_msg} <<<"->ErrorLine();
					return Nil;
				};
			};

			return Pair->New(response_text, ByteArrayRef->New(Cipher.Decrypt->Base64(response_audio)))<String, ByteArrayRef>;
		}
	}

	#~
	File query
	~#
	class FileQuery {
		@role : String;
		@query : String;
		@file : API.OpenAI.File;

		#~
		Constructor 
		@param query text query
		@param file upload file
		@param role user role
		~#
		New(query : String, file : API.OpenAI.File, role : String) {
			@query := query;
			@file := file;
			@role := role;
		}

		#~
		Get the text query
		@return text query
		~#
		method : public : GetQuery() ~ String {
			return @query;
		}

		#~
		Get the role
		@return role
		~#
		method : public : GetRole() ~ String {
			return @role;
		}

		#~
		Get the file ID
		@return file ID
		~#
		method : public : GetFile() ~ API.OpenAI.File {
			return @file;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			file_id := @file->GetId();
			buffer := "[query='{$@query}', file_id='{$file_id}']";

			return buffer;
		}
	}

	#~
	Image query
	~#
	class ImageQuery {
		#~
		Binary image MIME type
		~#
		enum MimeType {
			 PNG,
			 JPEG,
			 WEBP,
			 GIF
		}

		@query : String;
		
		@image_url : Url;

		@image : Byte[];
		@mime_type : ImageQuery->MimeType;

		#~
		Constructor 
		@param query text query
		@param image_url URL to image
		~#
		New(query : String, image_url : Url) {
			@query := query;
			@image_url := image_url;
		}

		#~
		Constructor 
		@param query text query
		@param image binary image
		@param mime_type imag MIME type
		~#
		New(query : String, image : Byte[], mime_type : ImageQuery->MimeType) {
			@query := query;
			@image := image;
			@mime_type := mime_type;
		}

		#~
		Get the text query
		@return text query
		~#
		method : public : GetQuery() ~ String {
			return @query;
		}

		#~
		Get the image URL
		@return image URL
		~#
		method : public : GetImageUrl() ~ Url {
			return @image_url;
		}

		#~
		Get the image URL
		@return image bytes
		~#
		method : public : GetImage() ~ Byte[] {
			return @image;
		}

		#~
		Get the image mime type
		@return image mime type
		~#
		method : public : GetMimeType() ~ String {
			select(@mime_type) {
				label MimeType->PNG {
					return "image/png";
				}

				label MimeType->JPEG {
					return "image/jpeg";
				}

				label MimeType->WEBP {
					return "image/webp";
				}

				label MimeType->GIF {
					return "image/gif";
				}
			};

			return "application/octet-stream";
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			buffer := "[query='{$@query}'";

			
			if(@image_url <> Nil) {
				image_url_str := @image_url->GetUrl();
				buffer += ", image_url='{$image_url_str}";
			}
			else {
				buffer += ", image_size=";
				buffer += @image->Size();
				buffer += " bytes, mime_type='";
				buffer += GetMimeType();
			};
			buffer += "']";

			return buffer;
		}
	}

	#~
	OpenAI image generator
	~#
	class Image from EndPoint {
		@created_at : Int;
		@urls : Url[];

		enum Size {
			DALLE2_256_256, 
			DALLE2_512_512,
			DALLE2_1024_1024,
			DALLE3_1024_1024,
			DALLE3_1792_1024,
			DALLE3_1024_1792,
			DALLE_DEFAULT
		}

		New(image_json : JsonElement) {
			Parent();

			@created_at := image_json->Get("created")->GetInt();

			urls_json := image_json->Get("data");
			@urls := Url->New[urls_json->Size()];
			each(i : urls_json) {
				url_json := urls_json->Get(i);
				url := url_json->Get("url")->GetString();
				@urls[i] := Url->New(url);
			};
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		Get the generated images URLs
		@return generated images URLs
		~#
		method : public : GetUrls() ~ Url[] {
			return @urls
		}

		#~
		Creates an image given a prompt
		@param prompt text description of the desired image
		@param token API token
		@return generated image
		~#
		function : Create(prompt : String, token : String) ~ API.OpenAI.Image {
			return Create(prompt, Nil, -1, Nil, Nil, Image->Size->DALLE_DEFAULT, Nil, Nil, token);
		}

		#~
		Creates an image given a prompt
		@param prompt text description of the desired image
		@param model model name
		@param size size of the generated image
		@param token API token
		@return generated image
		~#
		function : Create(prompt : String, model : String, size : Image->Size, token : String) ~ API.OpenAI.Image {
			return Create(prompt, model, -1, Nil, Nil, Image->Size->DALLE_DEFAULT, Nil, Nil, token);
		}

		#~
		Creates an image given a prompt
		@param prompt text description of the desired image
		@param model model name
		@param n number of images
		@param quality quality of the image that will be generated		
		@param response_format format in which the generated images are returned
		@param size size of the generated image
		@param style style of the generated image
		@param user identifier representing your end-user
		@param token API token
		@return generated image
		~#
		function : Create(prompt : String, model : String, n : Int, quality : String, response_format : String,
				size : Image->Size, style : String, user : String, token : String) ~ API.OpenAI.Image {
			image_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			image_json->Insert("prompt", prompt);
			
			if(model <> Nil) {
				image_json->Insert("model", model);
			}
			
			if(n > 0 & n <= 10) {
				image_json->Insert("n", n);
			};
			
			if(quality <> Nil) {
				image_json->Insert("quality", quality);
			};

			if(response_format <> Nil) {
				image_json->Insert("response_format", response_format);
			};
			
			select(size) {
				label Image->Size->DALLE2_256_256 {
					image_json->Insert("size", "256x256");
				}

				label Image->Size->DALLE2_512_512 {
					image_json->Insert("size", "512x512");
				}

				label Image->Size->DALLE2_1024_1024:
				label Image->Size->DALLE3_1024_1024 {
					image_json->Insert("size", "1024x1024");
				}

				label Image->Size->DALLE3_1792_1024:
				label Image->Size->DALLE3_1024_1792 {					
					image_json->Insert("size", "1792x1024");
				}
			};

			if(style <> Nil) {
				image_json->Insert("style", style);
			};

			if(user <> Nil) {
				image_json->Insert("user", user);
			};

			data := image_json->ToString()->ToByteArray();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickPost(Url->New(GetBaseUrl() + "/images/generations"), data, "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();
				image_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(image_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};

				error_str := image_json->FindElements("error/message");				
				if(error_str <> Nil) {
					SetLastError(error_str->GetString());
					return Nil;
				};

				return API.OpenAI.Image->New(image_json);
			};

			return Nil;
		}
		
		#~
		Creates an edited or extended image given an original image and a prompt
		@param image_name image name
		@param image_content image content
		@param prompt text description of the desired image
		@param token API token
		@return edited image
		~#
		function : Edit(image_name : String, image_content : Byte[], prompt : String, token : String) ~ API.OpenAI.Image {
			return Edit(image_name, image_content, prompt, Nil, Nil->As(Byte[]), Nil, -1, Image->Size->DALLE_DEFAULT, Nil, Nil, token);
		}

		#~
		Creates an edited or extended image given an original image and a prompt
		@param image_name image name
		@param image_content image content
		@param prompt text description of the desired image
		@param mask_name mask name
		@param mask_content additional image whose fully transparent areas (e.g. where alpha is zero) 
		@param model model name
		@param n number of images
		@param size size of the generated image
		@param response_format format in which the generated images are returned		
		@param user identifier representing your end-user
		@param token API token
		@return edited image
		~#
		function : Edit(image_name : String, image_content : Byte[], prompt : String, mask_name : String, mask_content : Byte[], 
				model : String, n : Int, size : Image->Size, response_format : String, user : String, token : String) ~ API.OpenAI.Image {
			
			encoder := Web.HTTP.Server.MultipartEncoder->New();

			# image
			image_headers := Map->New()<String, String>;
			image_headers->Insert("Content-Disposition", "form-data; name=\"image\"; filename=\"{$image_name}\"");
			image_headers->Insert("Content-Type", "application/octet-stream");
			encoder->Add(Web.HTTP.Server.MultipartContent->New(image_headers, image_content));

			# prompt
			prompt_headers := Map->New()<String, String>;
			prompt_headers->Insert("Content-Disposition", "form-data; name=\"prompt\"");
			encoder->Add(Web.HTTP.Server.MultipartContent->New(prompt_headers, prompt->ToByteArray()));

			# mask
			if(mask_name <> Nil & mask_content <> Nil) {
				mask_headers := Map->New()<String, String>;
				mask_headers->Insert("Content-Disposition", "form-data; name=\"mask\"; filename=\"{$mask_name}\"");
				mask_headers->Insert("Content-Type", "application/octet-stream");
				encoder->Add(Web.HTTP.Server.MultipartContent->New(mask_headers, mask_content));
			};

			# model
			if(model <> Nil) {
				model_headers := Map->New()<String, String>;
				model_headers->Insert("Content-Disposition", "form-data; name=\"model\"");
				encoder->Add(Web.HTTP.Server.MultipartContent->New(model_headers, model->ToByteArray()));
			};

			# n
			if(n > 0 & n <= 10) {
				n_headers := Map->New()<String, String>;
				n_headers->Insert("Content-Disposition", "form-data; name=\"n\"");
				encoder->Add(Web.HTTP.Server.MultipartContent->New(n_headers, n->ToString()->ToByteArray()));
			};
			
			# size
			select(size) {
				label Image->Size->DALLE2_256_256 {
					size_headers := Map->New()<String, String>;
					size_headers->Insert("Content-Disposition", "form-data; name=\"size\"");
					encoder->Add(Web.HTTP.Server.MultipartContent->New(size_headers, "256x256"->ToByteArray()));
				}

				label Image->Size->DALLE2_512_512 {
					size_headers := Map->New()<String, String>;
					size_headers->Insert("Content-Disposition", "form-data; name=\"size\"");
					encoder->Add(Web.HTTP.Server.MultipartContent->New(size_headers, "512x512"->ToByteArray()));
				}

				label Image->Size->DALLE2_1024_1024:
				label Image->Size->DALLE3_1024_1024 {
					size_headers := Map->New()<String, String>;
					size_headers->Insert("Content-Disposition", "form-data; name=\"size\"");
					encoder->Add(Web.HTTP.Server.MultipartContent->New(size_headers, "1024x1024"->ToByteArray()));
				}

				label Image->Size->DALLE3_1792_1024:
				label Image->Size->DALLE3_1024_1792 {					
					size_headers := Map->New()<String, String>;
					size_headers->Insert("Content-Disposition", "form-data; name=\"size\"");
					encoder->Add(Web.HTTP.Server.MultipartContent->New(size_headers, "1792x1024"->ToByteArray()));
				}
			};

			# response format
			if(response_format <> Nil) {
				response_format_headers := Map->New()<String, String>;
				response_format_headers->Insert("Content-Disposition", "form-data; name=\"response_format\"");
				encoder->Add(Web.HTTP.Server.MultipartContent->New(response_format_headers, response_format->ToByteArray()));
			};

			# user
			if(user <> Nil) {
				user_headers := Map->New()<String, String>;
				user_headers->Insert("Content-Disposition", "form-data; name=\"user\"");
				encoder->Add(Web.HTTP.Server.MultipartContent->New(user_headers, user->ToByteArray()));
			};

			boundary := encoder->GetBoundary();
			data := encoder->ToByteArray();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickPost(Url->New(GetBaseUrl() + "/images/edits"), data, 
				"multipart/form-data; boundary={$boundary}", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();
				image_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(image_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};

				error_str := image_json->FindElements("error/message");				
				if(error_str <> Nil) {
					SetLastError(error_str->GetString());
					return Nil;
				};

				return API.OpenAI.Image->New(image_json);					
			};

			return Nil;
		}

		#~
		Creates a variation of a given image
		@param image_name image name
		@param image_content image content
		@param token API token
		@return image variation
		~#
		function : Variation(image_name : String, image_content : Byte[], token : String) ~ API.OpenAI.Image {
			return Variation(image_name, image_content, Nil, -1, Nil, Image->Size->DALLE_DEFAULT, Nil, token);
		}

		#~
		Creates a variation of a given image
		@param image_name image name
		@param image_content image content
		@param model model name
		@param n number of images
		@param response_format format in which the generated images are returned		
		@param size size of the generated image
		@param user identifier representing your end-user
		@param token API token
		@return image variation
		~#
		function : Variation(image_name : String, image_content : Byte[], model : String, n : Int, response_format : String, size : Image->Size, user : String, token : String) ~ API.OpenAI.Image {
			
			encoder := Web.HTTP.Server.MultipartEncoder->New();

			# image
			image_headers := Map->New()<String, String>;
			image_headers->Insert("Content-Disposition", "form-data; name=\"image\"; filename=\"{$image_name}\"");
			image_headers->Insert("Content-Type", "application/octet-stream");
			encoder->Add(Web.HTTP.Server.MultipartContent->New(image_headers, image_content));

			# model
			if(model <> Nil) {
				model_headers := Map->New()<String, String>;
				model_headers->Insert("Content-Disposition", "form-data; name=\"model\"");
				encoder->Add(Web.HTTP.Server.MultipartContent->New(model_headers, model->ToByteArray()));
			};

			# n
			if(n > 0 & n <= 10) {
				n_headers := Map->New()<String, String>;
				n_headers->Insert("Content-Disposition", "form-data; name=\"n\"");
				encoder->Add(Web.HTTP.Server.MultipartContent->New(n_headers, n->ToString()->ToByteArray()));
			};

			# response format
			if(response_format <> Nil) {
				response_format_headers := Map->New()<String, String>;
				response_format_headers->Insert("Content-Disposition", "form-data; name=\"response_format\"");
				encoder->Add(Web.HTTP.Server.MultipartContent->New(response_format_headers, response_format->ToByteArray()));
			};
			
			# size
			select(size) {
				label Image->Size->DALLE2_256_256 {
					size_headers := Map->New()<String, String>;
					size_headers->Insert("Content-Disposition", "form-data; name=\"size\"");
					encoder->Add(Web.HTTP.Server.MultipartContent->New(size_headers, "256x256"->ToByteArray()));
				}

				label Image->Size->DALLE2_512_512 {
					size_headers := Map->New()<String, String>;
					size_headers->Insert("Content-Disposition", "form-data; name=\"size\"");
					encoder->Add(Web.HTTP.Server.MultipartContent->New(size_headers, "512x512"->ToByteArray()));
				}

				label Image->Size->DALLE2_1024_1024:
				label Image->Size->DALLE3_1024_1024 {
					size_headers := Map->New()<String, String>;
					size_headers->Insert("Content-Disposition", "form-data; name=\"size\"");
					encoder->Add(Web.HTTP.Server.MultipartContent->New(size_headers, "1024x1024"->ToByteArray()));
				}

				label Image->Size->DALLE3_1792_1024:
				label Image->Size->DALLE3_1024_1792 {					
					size_headers := Map->New()<String, String>;
					size_headers->Insert("Content-Disposition", "form-data; name=\"size\"");
					encoder->Add(Web.HTTP.Server.MultipartContent->New(size_headers, "1792x1024"->ToByteArray()));
				}
			};

			# user
			if(user <> Nil) {
				user_headers := Map->New()<String, String>;
				user_headers->Insert("Content-Disposition", "form-data; name=\"user\"");
				encoder->Add(Web.HTTP.Server.MultipartContent->New(user_headers, user->ToByteArray()));
			};

			boundary := encoder->GetBoundary();
			data := encoder->ToByteArray();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickPost(Url->New(GetBaseUrl() + "/images/variations"), data, 
				"multipart/form-data; boundary={$boundary}", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();
				image_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(image_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};

				error_str := image_json->FindElements("error/message");				
				if(error_str <> Nil) {
					SetLastError(error_str->GetString());
					return Nil;
				};

				return API.OpenAI.Image->New(image_json);					
			};

			return Nil;
		}
	}

	#~
	Vector store files represent files inside a vector store

```
store := API.OpenAI.VectorStore->Load(store_id, token);
file := API.OpenAI.File->Load(file_id, token);
if(store <> Nil & file <> Nil) {
  VectorStoreFile->Create(file, store, token)->ToString()->PrintLine();
};
```	
	~#
	class VectorStoreFile from EndPoint {
		@id : String;
		@object : String;
		@created_at : Int;
		@usage_bytes : Int;
		@store : VectorStore;
		@status : String;
		
		New(response_json : JsonElement, token : String) {
			Parent();

			@id := response_json->Get("id")->GetString();
			@object := response_json->Get("object")->GetString();
			@store := VectorStore->Load(response_json->Get("vector_store_id")->GetString(), token);
			@created_at := response_json->Get("created_at")->GetInt();
			@usage_bytes := response_json->Get("usage_bytes")->GetInt();
			@status := response_json->Get("status")->GetString();
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Get the store's usage in bytes
		@return store's usage in bytes
		~#
		method : public : GetBytes() ~ Int {
			return @usage_bytes;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		Get the store's status
		@return store's status
		~#
		method : public : GetStatus() ~ String {
			return @status;
		}

		#~
		Get vector store
		@return vector store
		~#
		method : public : GetVectorStore() ~ VectorStore {
			return @store;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			return "[id='{$@id}', object='{$@object}', created_at={$@created_at}, store='{$@store}', usage_bytes='{$@usage_bytes}'']"; 
		}

		#~
		Create a vector store
		@param file file to add to store
		@param store store to add file to
		@param token API token
		@return vector store file
		~#
		function : Create(file : API.OpenAI.File, store : VectorStore, token : String) ~ VectorStoreFile {
			query_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			query_json->Insert("file_id", file->GetId());
			data := query_json->ToString()->ToByteArray();

			if(IsDebug()) {
				query_json->ToString()->PrintLine();
			};

			store_id := store->GetId()

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickPost(Url->New(GetBaseUrl() + "/vector_stores/{$store_id}/files"), data, "application/json", headers);
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: name='/vector_stores' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();
				};

				response_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(response_json = Nil) {
					"### Error: Unable to parse thread response ###"->ErrorLine();
					return Nil;
				};
				
				if(response_json->Has("error")) {
					error_str := response_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return API.OpenAI.VectorStoreFile->New(response_json, token);
			};
			
			return Nil;	
		}

		#~
		Lists vector store files
		@param store vector store that the files belong to
		@param token API token
		@return list of vector store files 
		~#
		function : ListStoreFiles(store : VectorStore, token : String) ~ Vector<VectorStoreFile> {
			file : API.OpenAI.File;

			store_id := store->GetId();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickGet(Url->New(GetBaseUrl() + "/vector_stores/{$store_id}/files"), "application/json", headers);
			
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: name='/vector_stores/{$store_id}/files' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();
				};

				response_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(response_json = Nil) {
					return Nil;
				};

				if(response_json->Has("error")) {
					error_str := response_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				store_files := Vector->New()<VectorStoreFile>;
				
				stores_json := response_json->Get("data");
				each(store_json in stores_json) {
					store_files->AddBack(VectorStoreFile->New(store_json, token));
				};

				return store_files;
			};

			return Nil;
		}

		#~
		Loads vector store file
		@param store_file_id vector store file ID
		@param store vector store that the files belong to
		@param token API token
		@return store file
		~#
		function : Load(store_file_id : String, store : VectorStore, token : String) ~ VectorStoreFile {
			store_id := store->GetId();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickGet(Url->New(GetBaseUrl() + "/vector_stores/{$store_id}/files/{$store_file_id}"), "application/json", headers);
			
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: name='/vector_stores/{$store_id}/files/{$store_file_id}' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();
				};

				response_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(response_json = Nil) {
					return Nil;
				};

				if(response_json->Has("error")) {
					error_str := response_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return VectorStoreFile->New(response_json, token);
			};

			return Nil;
		}

		#~
		Deletes a file store
		@param store_file_id vector store file ID
		@param store vector store that the files belong to
		@param token API token
		@return true if successful, false otherwise
		~#
		function : Delete(store_file_id : String, store : VectorStore, token : String) ~ Bool {
			store_id := store->GetId();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickDelete(Url->New(GetBaseUrl() + "/vector_stores/{$store_id}/files/{$store_file_id}"), "application/json", headers);
			
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: name='/vector_stores/{$store_id}/files/{$store_file_id}' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();
				};

				file_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(file_json = Nil) {
					return false;
				};

				if(file_json->Has("error")) {
					error_str := file_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				}

				return file_json->Get("deleted")->GetString()->Equals("true");
			};

			return false;
		}
	}

	#~
	OpenAI vector store support

```
file_ids := ["file-xxxxxxxxxxxxxxxxxxxxxxxx", "file-yyyyyyyyyyyyyyyyyyyyyyyy", "file-zzzzzzzzzzzzzzzzzzzzzzzz"];
files := Vector->New()<API.OpenAI.File>;
each(i : file_ids) {
  file_id := file_ids[i];
  file := API.OpenAI.File->Load(file_id, token);
  if(file <> Nil) {
  	file->ToString()->PrintLine();
  	files->AddBack(file);
  };
};

store := VectorStore->Create("test_1", files, token);
if(store <> Nil) {
  store->ToString()->PrintLine();
};
```	
	~#
	class VectorStore from EndPoint {
		@id : String;
		@object : String;
		@created_at : Int;
		@last_active_at : Int;
		@usage_bytes : Int;
		@completed_count : Int;
		@name : String;
		@status : String;
		
		New(response_json : JsonElement) {
			Parent();

			@id := response_json->Get("id")->GetString();
			@object := response_json->Get("object")->GetString();
			@name := response_json->Get("name")->GetString();
			@created_at := response_json->Get("created_at")->GetInt();
			@last_active_at := response_json->Get("last_active_at")->GetInt();
			@usage_bytes := response_json->Get("usage_bytes")->GetInt();
			@status := response_json->Get("status")->GetString();

			file_counts_json := response_json->Get("file_counts");
			if(file_counts_json <> Nil) {
				@completed_count := file_counts_json->Get("completed")->GetInt();
			};
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Get the store's usage in bytes
		@return store's usage in bytes
		~#
		method : public : GetBytes() ~ Int {
			return @usage_bytes;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was last active
		@return time with the object instance was last active
		~#
		method : public : GetLastActiveAt() ~ Int {
			return @last_active_at;
		}

		#~
		Get the number of files successfully processed
		@return number of files successfully processed
		~#
		method : public : CompletedCount() ~ Int {
			return @completed_count;
		}

		#~
		Get the store's status
		@return store's status
		~#
		method : public : GetStatus() ~ String {
			return @status;
		}

		#~
		Get the name of the store
		@return name of the store
		~#
		method : public : GetName() ~ String {
			return @name;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			return "[id='{$@id}', object='{$@object}', created_at={$@created_at}, name='{$@name}', usage_bytes='{$@usage_bytes}', completed_count='{$@completed_count}']"; 
		}

		#~
		Create a vector store
		@param name name of the store
		@param token API token
		@return vector store
		~#
		function : Create(name : String, token : String) ~ VectorStore {
			return Create(name, Nil, token);
		}

		#~
		Create a vector store
		@param name name of the store
		@param files to add to the store
		@param token API token
		@return vector store
		~#
		function : Create(name : String, files : Vector<API.OpenAI.File>, token : String) ~ VectorStore {
			query_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			query_json->Insert("name", name);
			data := query_json->ToString()->ToByteArray();

			if(files <> Nil) {
				file_ids_json := JsonElement->New(JsonElement->JsonType->ARRAY);

				each(file in files) {
					file_ids_json->Add(file->GetId());
				};

				query_json->Insert("file_ids", file_ids_json);				
			};
			
			if(IsDebug()) {
				query_json->ToString()->PrintLine();
			};

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickPost(Url->New(GetBaseUrl() + "/vector_stores"), data, "application/json", headers);
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: name='/vector_stores' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();
				};

				response_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(response_json = Nil) {
					"### Error: Unable to parse thread response ###"->ErrorLine();
					return Nil;
				};
				
				if(response_json->Has("error")) {
					error_str := response_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return API.OpenAI.VectorStore->New(response_json);
			};
			
			return Nil;	
		}

		#~
		Lists vector stores
		@param token API token
		@return list of vector stores 
		~#
		function : ListStores(token : String) ~ Vector<VectorStore> {
			return ListStores(false, token);
		}

		#~
		Lists vector stores
		@param non_empties if true, non empty stores are include, otherwise excluded
		@param token API token
		@return list of vector stores 
		~#
		function : ListStores(non_empties : Bool, token : String) ~ Vector<VectorStore> {
			file : API.OpenAI.File;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickGet(Url->New(GetBaseUrl() + "/vector_stores"), "application/json", headers);
			
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: name='/vector_stores' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();
				};

				response_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(response_json = Nil) {
					return Nil;
				};

				if(response_json->Has("error")) {
					error_str := response_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				stores := Vector->New()<VectorStore>;

				stores_json := response_json->Get("data");
				each(store_json in stores_json) {
					usage_bytes := store_json->Get("usage_bytes")->GetInt();
					if(non_empties) {
						stores->AddBack(VectorStore->New(store_json));
					}
					else if(usage_bytes > 0) {
						stores->AddBack(VectorStore->New(store_json));
					};
				};

				return stores;
			};

			return Nil;
		}

		#~
		Deletes a store
		@param id store ID
		@param token API token
		@return true if successful, false otherwise
		~#
		function : Delete(id : String, token : String) ~ Bool {
			file : API.OpenAI.File;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickDelete(Url->New(GetBaseUrl() + "/vector_stores/{$id}"), "application/json", headers);
			
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: name='/vector_stores/{$id}' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();
				};

				file_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(file_json = Nil) {
					return false;
				};

				if(file_json->Has("error")) {
					error_str := file_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				}

				return file_json->Get("deleted")->GetString()->Equals("true");
			};

			return false;
		}

		#~
		Deletes all stores
		@param token API token
		@return true if successful, false otherwise
		~#
		function : DeleteAll(token : String) ~ Bool {
			stores := ListStores(token);
			each(store in stores) {
				if(<>store->Delete(store->GetId(), token)) {
					return false;
				};
			};

			return true;
		}

		#~
		Load a store
		@param store_id vector store ID
		@param token API token
		@return vector store
		~#
		function : Load(store_id : String, token : String) ~ API.OpenAI.VectorStore {
			tuning : API.OpenAI.Tuning.Tuner;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickGet(Url->New(GetBaseUrl() + "/vector_stores/{$store_id}"), "application/json", headers);
			
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: name='/vector_stores/{$store_id}' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();
				};

				response_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(response_json = Nil) {
					return Nil;
				};

				return API.OpenAI.VectorStore->New(response_json);
			};

			return Nil;
		}
	}

	#~
	OpenAI file support

```
# upload tuning file
filename := "tuning.json";
data := FileReader->ReadFile(filename)->ToByteArray();
API.OpenAI.File->Create(filename, "fine-tune", data, token)->PrintLine();

# list files
files := API.OpenAI.File->ListFiles(token);
if(files <> Nil) {
  each(file in files) {
    name := file->GetFilename();
    id := file->GetId();
    "file='{$name}', id='{$id}'"->PrintLine();
  };
}
else {
  API.OpenAI.File->GetLastError()->PrintLine();
};

# start tuning job
file := API.OpenAI.File->LoadOrCreate(filename, "fine-tune", token);
name := file->GetFilename();
id := file->GetId();
"file='{$name}', id='{$id}'"->PrintLine();

tuning_job := Tuner->Create("gpt-3.5-turbo", id, token);
model_id := tuning_job->GetId();

# query model

assistant := Assistant->Create(model_id, token);
if(assistant = Nil) {
  Assistant->GetLastError()->PrintLine();
  return;
};

assistant_id := assistant->GetId();
assistant_name := assistant->GetName();
assistant_model := assistant->GetModel();
"Created: id='{$id}', name='{$name}', model='{$model}', files={$file_count}, tools={$tool_count}"->PrintLine();

# chat with tuned assistant
session := API.OpenAI.Chat.Conversation->New(Assistant->Load(assistant_id, token), true, token);
session->AddFunction("get_coach_by_year", Callback(JsonElement) ~ JsonElement);

done := false;
do {
  query := Console->ReadLine();
  if(query->Equals("/quit")) {
    session->Close();    
    done := true;
  }
  else {
    response := session->Send(query, "user");

    index := 0;
    role := response->GetRole();
    contents := response->GetContents();
    each(content in contents) {
      type := content->GetFirst()->As(String);
      value := content->GetSecond()->As(String);

      "{$index}: [{$role}, type='{$type}']: value='{$value}'"->PrintLine();
    };
  };
}
while(<>done);

session->Close();
```	
	~#
	class File from EndPoint {
		@id : String;
		@object : String;
		@created_at : Int;
		@bytes : Int;
		@filename : String;
		@purpose : String;
		
		New(file_json : JsonElement, token : String) {
			Parent();

			@id := file_json->Get("id")->GetString();
			@object := file_json->Get("object")->GetString();
			@bytes := file_json->Get("bytes")->GetInt();
			@created_at := file_json->Get("created_at")->GetInt();
			@filename := file_json->Get("filename")->GetString();
			@purpose := file_json->Get("purpose")->GetString();
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Get the size of the file
		@return size of the file
		~#
		method : public : GetBytes() ~ Int {
			return @bytes;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		Get the name of the file
		@return name of the file
		~#
		method : public : GetFilename() ~ String {
			return @filename;
		}

		#~
		Get the purpose
		@return purpose
		~#
		method : public : GetPurpose() ~ String {
			return @purpose;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			return "[id='{$@id}', object='{$@object}', bytes={$@bytes}, created_at={$@created_at}, filename='{$@filename}', purpose='{$@purpose}']"; 
		}

		#~
		Upload a file that can be used across various endpoints
		@param name file object name
		@param content file content
		@param token API token
		@return string representation
		~#
		function : Create(name : String, content : Byte[], token : String) ~ Bool {
			return Create(name, "assistants", content, token);
		}

		#~
		Upload a file that can be used across various endpoints
		@param name file object name
		@param content file content
		@param purpose file purpose 'assistants', 'vision' or 'fine-tune'
		@param token API token
		@return string representation
		~#
		function : Create(name : String, purpose : String, content : Byte[], token : String) ~ Bool {
			purpose_headers := Map->New()<String, String>;
			purpose_headers->Insert("Content-Disposition", "form-data; name=\"purpose\"");
			purpose_content := Web.HTTP.Server.MultipartContent->New(purpose_headers, purpose->ToByteArray());

			content_headers := Map->New()<String, String>;
			content_headers->Insert("Content-Disposition", "form-data; name=\"file\"; filename=\"{$name}\"");
			content_headers->Insert("Content-Type", "application/octet-stream");
			multi_content := Web.HTTP.Server.MultipartContent->New(content_headers, content);

			encoder := Web.HTTP.Server.MultipartEncoder->New();
			encoder->Add(purpose_content);
			encoder->Add(multi_content);
			boundary := encoder->GetBoundary();
			data := encoder->ToByteArray();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickPost(Url->New(GetBaseUrl() + "/files"), data, 
				"multipart/form-data; boundary={$boundary}", headers);

			return response->GetCode() = 200;
		}

		#~
		Loads a file
		@param id file ID
		@param token API token
		@return file reference
		~#
		function : Load(id : String, token : String) ~ API.OpenAI.File {
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickGet(Url->New(GetBaseUrl() + "/files/{$id}"), "application/json", headers);
			
			if(response <> Nil) {
				file_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(file_json = Nil) {
					return Nil;
				};

				if(file_json->Has("error")) {
					error_str := file_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return API.OpenAI.File->New(file_json, token);
			};

			return Nil;
		}

		#~
		Deletes a file
		@param id file ID
		@param token API token
		@return true if successful, false otherwise
		~#
		function : Delete(id : String, token : String) ~ Bool {
			file : API.OpenAI.File;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickDelete(Url->New(GetBaseUrl() + "/files/{$id}"), "application/json", headers);
			
			if(response <> Nil) {
				file_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(file_json = Nil) {
					return false;
				};

				if(file_json->Has("error")) {
					error_str := file_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				}

				return file_json->Get("deleted")->GetString()->Equals("true");
			};

			return false;
		}
		
		#~
		Loads or creates an OpenAI file from the local filesystem
		@param filename local file path
		@param token API token
		@return file reference
		~#
		function : LoadOrCreate(filename : String, token : String) ~ API.OpenAI.File {
			return LoadOrCreate(filename, "assistants", token);
		}

		#~
		Loads or creates an OpenAI file from the local filesystem
		@param filename local file path
		@param purpose file purpose 'assistants', 'vision' or 'fine-tune'		
		@param token API token
		@return file reference
		~#
		function : LoadOrCreate(filename : String, purpose : String, token : String) ~ API.OpenAI.File {
			file := LoadByName(filename, token);
			
			if(file = Nil) {
				# "Uploading file: '{$filename}'"->PrintLine();
				content := FileReader->ReadBinaryFile(filename);
				if(content = Nil | content->Size() = 0) {
					"### Error: Unable to load file: '{$filename}' ###"->PrintLine();
					Runtime->Exit(1);
				};

				if(API.OpenAI.File->Create(filename, purpose, content, token)) {
					file := LoadByName(filename, token);
				};
			};

			return file;
		}

		#~
		Loads an OpenAI file from the local filesystem
		@param filename local file path
		@param token API token
		@return file reference
		~#
		function : LoadByName(filename : String, token : String) ~ API.OpenAI.File {
			found : API.OpenAI.File;
			
			files := API.OpenAI.File->ListFiles(token);
			each(file in files) {
				decoded_filename := JsonElement->Decode(file->GetFilename());
				if(decoded_filename->Equals(filename)) {
					found := file;
					break;
				};
			};

			return found;
		}

		#~
		Loads a list available OpenAI files
		@param token API token
		@return file reference
		~#
		function : ListFiles(token : String) ~ Vector<API.OpenAI.File> {
			files := Vector->New()<API.OpenAI.File>

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickGet(Url->New(GetBaseUrl() + "/files"), "application/json", headers);
			if(response <> Nil) {
				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				if(root_json->Has("error")) {
					error_str := root_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				files_json := root_json->Get("data");
				each(file_json in files_json) {
					files->AddBack(API.OpenAI.File->New(file_json, token));
				};
			};

			return files;
		}

		#~
		Returns the contents of the specified file
		@param id file ID
		@param token API token
		@return file content
		~#
		function : Retrieve(id : String, token : String) ~ Byte[] {
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			return HttpsClient->QuickGet(Url->New(GetBaseUrl() + "/files/{$id}/content"), "application/json", headers)->GetContent();
		}
	}

	#~
	Builds assistants that can call models and use tools to perform tasks
	~#
	class Assistant from EndPoint {
		@id : String;
		@object : String;
		@model : String;
		@name : String;
		@description : String;
		@instructions : String;
		@funcs : Vector<FunctionType>;
		@created_at : Int;

		@tools : Vector<String>;
		@vector_stores : Vector<String>;
		@token : String;

		New : private(assistant_json : JsonElement, token : String) {
			Parent();

			@id := assistant_json->Get("id")->GetString();
			@created_at := assistant_json->Get("created_at")->GetInt();
			@object := assistant_json->Get("object")->GetString();
			@name := assistant_json->Get("name")->GetString();
			@description := assistant_json->Get("description")->GetString();
			@model := assistant_json->Get("model")->GetString();
			@instructions := assistant_json->Get("instructions")->GetString();
			@token := token;

			# tools
			@tools := Vector->New()<String>;
			tools := assistant_json->Get("tools");
			each(tool in tools) {
				tool_desc := tool->Get("type")->GetString();
				if(tool_desc->Equals("function")) {
					func_json := tool->Get("function");
					if(@funcs = Nil) {
						@funcs := Vector->New()<FunctionType>;
					};

					func := FunctionType->New(func_json);
					@funcs->AddBack(func);
				}

				@tools->AddBack(tool_desc);
			};

			@vector_stores := Vector->New()<String>;
			vector_store_ids_json := assistant_json->FindElements("tool_resources/file_search/vector_store_ids");
			if(vector_store_ids_json <> Nil) {
				each(vector_store_id_json in vector_store_ids_json) {
					@vector_stores->AddBack(vector_store_id_json->GetString());
				};
			};
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		ID of the model to use
		@return ID of the model to use
		~#
		method : public : GetModel() ~ String {
			return @model;
		}

		#~
		Name of the assistant
		@return name of the assistant
		~#
		method : public : GetName() ~ String {
			return @name;
		}

		#~
		List of vector stores associated with the assistant
		@return vector stores associated with the assistant
		~#
		method : public : GetVectorStores() ~ Vector<String> {
			return @vector_stores;
		}

		#~
		Description of the assistant
		@return description of the assistant
		~#
		method : public : GetDescription() ~ String {
			return @description;
		}

		#~
		System instructions that the assistant uses
		@return system instructions
		~#
		method : public : GetInstructions() ~ String {
			return @instructions;
		}

		#~
		Adds a file to assistant
		@param file file to add to assistant
		@return true if successful, false otherwise
		~#
		method : public : AddFile(file : API.OpenAI.File) ~ Bool {
			file_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			file_json->Insert("file_id", file->GetId());
			data := file_json->ToString()->ToByteArray();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$@token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickPost(Url->New(GetBaseUrl() + "/assistants/{$@id}/files"), data, "application/json", headers);
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: name='/assistants/{$@id}/files' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();
				};

				file_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(file_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return false;
				};
				
				if(file_json->Has("error")) {
					error_str := file_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				};

				return file->GetId()->Equals(file_json->Get("id")->GetString());
			}

			return false;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {			
			buffer := "[id='";
			buffer += @id;

			buffer += "', object='"
			buffer += @object;

			buffer += "', model='"
			buffer += @model;

			buffer += "', name='"
			buffer += @name;

			buffer += "', description='"
			buffer += @description;

			buffer += "', instructions='"
			buffer += @instructions;

			buffer += "', created_at="
			buffer += @created_at;

			buffer += "\ntools: ["
			for(i := 0; i < @tools->Size(); i +=1 ;) {
				buffer += i;
				buffer += ": ";
				buffer += @tools->Get(i);
				buffer += '\'';
				
				if(i + 1 < @tools->Size()) {
					buffer += ',';
				};
			};

			buffer += "]\nvector_stores: [";
			for(i := 0; i < @vector_stores->Size(); i +=1 ;) {
				buffer += i;
				buffer += ": ";
				buffer += @vector_stores->Get(i)->ToString();
								
				if(i + 1 < @vector_stores->Size()) {
					buffer += "\n\t";
				};
			};
			buffer += ']';

			return buffer;
		}

		#~
		Returns a list of assistants
		@param token API token
		@return list of assistants
		~#
		function : ListAssistants(token : String) ~ Vector<API.OpenAI.Assistant> {
			assistants := Vector->New()<API.OpenAI.Assistant>

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickGet(Url->New(GetBaseUrl() + "/assistants"), "application/json", headers);
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: name='/assistants' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();
				};

				assistants_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(assistants_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};
				
				if(assistants_json->Has("error")) {
					error_str := assistants_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				assistants_json := assistants_json->Get("data");
				each(assistant_json in assistants_json) {
					assistants->AddBack(API.OpenAI.Assistant->New(assistant_json, token));
				};
			};

			return assistants;
		}

		#~
		Loads or creates an OpenAI file from the local filesystem
		@param name name lookup
		@param token API token
		@return file reference
		~#
		function : LoadByName(name : String, token : String) ~ API.OpenAI.Assistant {
			assistants := ListAssistants(token);
			if(<>assistants->IsEmpty()) {
				each(assistant in assistants) {
					if(name->Equals(assistant->GetName())) {
						return assistant;
					};
				};
			};

			return Nil;
		}

		#~
		Create an assistant with a model and instructions
		@param model ID of the model to use
		@param token API token
		@return assistant
		~#
		function : Create(model : String, token : String) ~ API.OpenAI.Assistant {
			return Create(model, Nil, Nil, Nil, Nil, Nil, Nil, token);
		}

		#~
		Create an assistant with a model and instructions
		@param model ID of the model to use
		@param name name to use
		@param description description of the assistant.
		@param instructions the system instructions that the assistant uses
		@param token API token
		@return newly created assistant
		~#
		function : Create(model : String, name : String, description : String, instructions : String, token : String) ~ API.OpenAI.Assistant {
			return Create(model, name, description, instructions, Nil, Nil, Nil, token);
		}

		#~
		Creates an assistant with a model and instructions
		@param model ID of the model to use
		@param name name to use
		@param description description of the assistant.
		@param instructions the system instructions that the assistant uses
		@param tools list of tool enabled on the assistant
		@param files list of file IDs attached to this assistant
		@param token API token
		@return newly created assistant
		~#
		function : Create(model : String, name : String, description : String, instructions : String, 
				tools : Vector<String>, files : Vector<API.OpenAI.File>, token : String) ~ API.OpenAI.Assistant {
			return Create(model, name, description, instructions, tools, files, Nil, token);
		}
		
		#~
		Creates an assistant with a model and instructions
		@param model ID of the model to use
		@param name name to use
		@param description description of the assistant.
		@param instructions the system instructions that the assistant uses
		@param tools list of tool enabled on the assistant
		@param files list of file IDs attached to this assistant
		@param funcs list of callback function definitions
		@param token API token
		@return newly created assistant
		~#
		function : Create(model : String, name : String, description : String, instructions : String, 
				tools : Vector<String>, files : Vector<API.OpenAI.File>, funcs : Vector<FunctionType>, token : String) ~ API.OpenAI.Assistant {

			if(model = Nil) {
				return Nil;
			};

			builder := JsonBuilder->New();
			create_json := builder->PushObject();
			create_json->Insert("model", model);

			if(name <> Nil) {
				create_json->Insert("name", name);
			};

			if(description <> Nil) {
				create_json->Insert("description", description);
			};

			if(instructions <> Nil) {
				create_json->Insert("instructions", instructions);
			};

			# tools
			if((tools <> Nil & <>tools->IsEmpty()) | (funcs <> Nil & <>funcs->IsEmpty())) {
				tools_json := JsonElement->New(JsonElement->JsonType->ARRAY);

				# tools to enable, functions are enabled separately below 
				each(tool in tools) {
					if(<>tool->Equals("function")) {
						tool_json := JsonElement->New(JsonElement->JsonType->OBJECT);
						tool_json->Insert("type", tool);
						tools_json->Add(tool_json);
					};
				};

				# function definitions 
				each(func in funcs) {
					tool_json := JsonElement->New(JsonElement->JsonType->OBJECT);
					tool_json->Insert("type", "function");

					func_json := JsonParser->TextToElement(func->ToString());					
					tool_json->Insert("function", func_json);

					tools_json->Add(tool_json);
				};

				create_json->Insert("tools", tools_json);
			};

			# files
			if(files <> Nil & <>files->IsEmpty()) {
				files_ids_array_json := JsonElement->New(JsonElement->JsonType->ARRAY);
				each(file in files) {
					files_ids_array_json->Add(file->GetId());
				};

				files_ids_array_obj_json := JsonElement->New(JsonElement->JsonType->OBJECT);
				files_ids_array_obj_json->Insert("file_ids", files_ids_array_json);

				vector_stores_array_json := JsonElement->New(JsonElement->JsonType->ARRAY);
				vector_stores_array_json->Add(files_ids_array_obj_json);

				file_search_json := JsonElement->New(JsonElement->JsonType->OBJECT);
				file_search_json->Insert("vector_stores", vector_stores_array_json);

				vector_stores_array_obj_json := JsonElement->New(JsonElement->JsonType->OBJECT);
				vector_stores_array_obj_json->Insert("file_search", file_search_json);

				create_json->Insert("tool_resources", vector_stores_array_obj_json);				
			};
			
			data := builder->PopAll()->ToString()->ToByteArray();

			if(IsDebug()) {
				"--- Prepared ---"->PrintLine();
				data->ToString()->PrintLine();			
			};

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickPost(Url->New(GetBaseUrl() + "/assistants"), data, "application/json", headers);
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: name='/assistants' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();
				};

				assistant_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(assistant_json = Nil) {
					return Nil;
				};
				
				if(assistant_json->Has("error")) {
					error_str := assistant_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				}

				return API.OpenAI.Assistant->New(assistant_json, token);
			};

			return Nil;
		}

		#~
		Loads an assistant with a model and instructions
		@param id model ID of the model to use
		@param token API token
		@return loaded assistant
		~#
		function : Load(id : String, token : String) ~ API.OpenAI.Assistant {
			assistant : API.OpenAI.Assistant;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickGet(Url->New(GetBaseUrl() + "/assistants/{$id}"), "application/json", headers);
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: name='/assistants/{$id}' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();
				};

				assistant_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(assistant_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};
				
				if(assistant_json->Has("error")) {
					error_str := assistant_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				assistant := API.OpenAI.Assistant->New(assistant_json, token);
			};

			return assistant;
		}

		#~
		Deletes all assistants
		@param token API token
		@return true if successful, false otherwise
		~#
		function : DeleteAll(token : String) ~ Bool {
			assists := ListAssistants(token);
			each(assist in assists) {
				if(<>assist->Delete(assist->GetId(), token)) {
					return false;
				};
			};

			return true;
		}

		#~
		Deletes an assistant with a model and instructions
		@param id model ID
		@param token API token
		@return true if successful, false otherwise
		~#
		function : Delete(id : String, token : String) ~ Bool {
			file : API.OpenAI.File;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickDelete(Url->New(GetBaseUrl() + "/assistants/{$id}"), "application/json", headers);
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: name='/assistants/{$id}' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();
				};

				file_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(file_json = Nil) {
					return false;
				};

				if(file_json->Has("error")) {
					error_str := file_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				}

				return file_json->Get("deleted")->GetString()->Equals("true");
			};

			return false;
		}
	}

	#~
	Create threads that assistants can interact with
	~#
	class Thread from EndPoint {
		@id : String;
		@object : String;
		@created_at : Int;

		New : private(thread_json : JsonElement) {
			Parent();

			@id := thread_json->Get("id")->GetString();
			@created_at := thread_json->Get("created_at")->GetInt();
			@object := thread_json->Get("object")->GetString();
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			buffer := "[id='";
			buffer += @id;

			buffer += "', object='"
			buffer += @object;

			buffer += "', created_at="
			buffer += @created_at;

			buffer += "]";

			return buffer;
		}

		#~
		Creates a thread
		@param token API token
		@return newly created thread
		~#
		function : Create(token : String) ~ API.OpenAI.Thread {
			thread : API.OpenAI.Thread;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickPost(Url->New(GetBaseUrl() + "/threads"), ""->ToByteArray(), "application/json", headers);
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: name='/threads' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();
				};

				thread_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(thread_json = Nil) {
					"### Error: Unable to parse thread response ###"->ErrorLine();
					return Nil;
				};
				
				if(thread_json->Has("error")) {
					error_str := thread_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return API.OpenAI.Thread->New(thread_json);
			};
			
			return Nil;	
		}

		#~
		Loads an existing thread
		@param id ID of the model to use
		@param token API token
		@return loaded thread
		~#
		function : Load(id : String, token : String) ~ API.OpenAI.Thread {
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickGet(Url->New(GetBaseUrl() + "/threads/{$id}"), "application/json", headers);
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: 'https://api.openai.com/v1/threads/{$id}' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();
				};

				thread_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(thread_json = Nil) {
					"### Error: Unable to parse thread response ###"->ErrorLine();
					return Nil;
				};
				
				if(thread_json->Has("error")) {
					error_str := thread_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return API.OpenAI.Thread->New(thread_json);

			};

			return Nil;
		}

		#~
		Loads an existing thread
		@param id ID of the model to use
		@param token API token
		@return loaded thread
		~#
		function : Delete(id : String, token : String) ~ Bool {
			thread : API.OpenAI.Thread;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickDelete(Url->New(GetBaseUrl() + "/threads/{$id}"), "application/json", headers);
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: 'https://api.openai.com/v1/threads/{$id}' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();
				};

				thread_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(thread_json = Nil) {
					return false;
				};

				if(thread_json->Has("error")) {
					error_str := thread_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				}

				return thread_json->Get("deleted")->GetString()->Equals("true");
			};

			return false;
		}
	}

	#~
	Message contents
	~#
	class Contents {
		@contents : Vector<Pair<String, String>>;

		New(contents : Vector<Pair<String, String>>) {
			@contents := contents;
		}

		#~
		Get content by index
		@param index index of content
		@return content, user and message
		~#
		method : public : Get(index : Int) ~ Pair<String, String> {
			return @contents->Get(index);
		}

		#~
		Gets the size of contents
		@return size of contents
		~#
		method : public : Size() ~ Int {
			return @contents->Size();
		}
	}

	#~
	Create messages within threads
	~#
	class Message from EndPoint {
		@id : String;
		@object : String;
		@created_at : Int;
		
		@thread_id : String;
		@role : String;
		@contents : Vector<Pair<String, String>>;
		@files : Vector<API.OpenAI.File>;

		New : private(message_json : JsonElement, token : String) {
			Parent();

# "--- Message ---"->PrintLine();
# message_json->ToString()->PrintLine();

			@id := message_json->Get("id")->GetString();
			@created_at := message_json->Get("created_at")->GetInt();
			@object := message_json->Get("object")->GetString();
			@thread_id := message_json->Get("thread_id")->GetString();
			@role := message_json->Get("role")->GetString();

			@contents := Vector->New()<Pair<String, String>>;	
			contents_json := message_json->Get("content");
			each(content_json in contents_json) {
				type := content_json->Get("type")->GetString();
				value := content_json->Get("text")->Get("value")->GetString();
				@contents->AddBack(Pair->New(type, value)<String, String>);
			};

			@files := Vector->New()<API.OpenAI.File>;
			file_ids := message_json->Get("attachments");
			if(file_ids <> Nil & file_ids->Size() > 0) {
				each(file_id in file_ids) {
					file := API.OpenAI.File->Load(file_id->GetString(), token);
					if(file <> Nil) {
						@files->AddBack(file);
					};
				};
			};
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		Get the ID of the thread associated with message
		@return thread ID
		~#
		method : public : GetThreadId() ~ String {
			return @thread_id;
		}

		#~
		Get the role of the entity that is creating the message
		@return role of the entity that is creating the message
		~#
		method : public : GetRole() ~ String {
			return @role;
		}

		#~
		Get the content of the message
		@return list of messages with roles
		~#
		method : public : GetContents() ~ Contents {
			return Contents->New(@contents);
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			buffer := "[id='";
			buffer += @id;

			buffer += "', object='"
			buffer += @object;

			buffer += "', created_at="
			buffer += @created_at;

			buffer += ", role='"
			buffer += @role;

			buffer += "''\ncontents: [";
			for(i := 0; i < @contents->Size(); i +=1 ;) {
				buffer += '{';
				buffer += i;
				buffer += ": type=";

				content := @contents->Get(i);
				buffer += content->GetFirst();
				buffer += ", text=\"";
				buffer += content->GetSecond();
				buffer += "\"}";
												
				if(i + 1 < @contents->Size()) {
					buffer += "\n\t";
				};
			};
			buffer += ']';

			return buffer;
		}

		#~
		Loads a message
		@param role role of the entity that is creating the message
		@param content content of the message.
		@param thread thread associated with message
		@param token API token
		@return loaded Message
		~#
		function : Create(role : String, content : String, thread : API.OpenAI.Thread, token : String) ~ API.OpenAI.Message {
			return Create(role, content , thread, Nil, token);
		}

		#~
		Create a message.
		@param role role of the entity that is creating the message
		@param content content of the message.
		@param thread thread associated with message
		@param files list to attach to the message
		@param token API token
		@return newly created message
		~#
		function : Create(role : String, content : String, thread : API.OpenAI.Thread, files : Vector<API.OpenAI.File>, token : String) ~ API.OpenAI.Message {
			message_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			message_json->Insert("role", role);
			message_json->Insert("content", content);

			# files
			if(files <> Nil & <>files->IsEmpty()) {
				files_json := JsonElement->New(JsonElement->JsonType->ARRAY);
				each(file in files) {
					files_json->Add(file->GetId());
				};
				message_json->Insert("attachments", files_json);
			};

			data := message_json->ToString()->ToByteArray();
			# data->ToString()->PrintLine();
			
			thread_id := thread->GetId();
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickPost(Url->New(GetBaseUrl() + "/threads/{$thread_id}/messages"), data, "application/json", headers);
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: 'https://api.openai.com/v1/threads/{$thread_id}/messages' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();
				};

				message_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(message_json = Nil) {
					"### Error: Unable to parse thread response ###"->ErrorLine();
					return Nil;
				};
				
				if(message_json->Has("error")) {
					error_str := message_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return API.OpenAI.Message->New(message_json, token);
			};
			
			return Nil;	
		}

		#~
		Loads a message
		@param id message ID
		@param thread thread associated with message
		@param token API token
		@return loaded Message
		~#
		function : Load(id : String, thread : API.OpenAI.Thread, token : String) ~ API.OpenAI.Message {
			thread_id := thread->GetId();
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickGet(Url->New(GetBaseUrl() + "/threads/{$thread_id}/messages/{$id}"), "application/json", headers);
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: 'https://api.openai.com/v1/threads/{$thread_id}/messages/{$id}' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();
				};

				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				if(root_json->Has("error")) {
					error_str := root_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				if(root_json->Has("error")) {
					error_str := root_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return API.OpenAI.Message->New(root_json, token);
			}

			return Nil;
		}

		#~
		Loads a messages associated with thread
		@param thread thread associated with message
		@param token API token
		@return messages associated with thread
		~#
		function : ListMessages(thread : API.OpenAI.Thread, token : String) ~ Vector<API.OpenAI.Message> {
			messages := Vector->New()<API.OpenAI.Message>

			thread_id := thread->GetId();
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickGet(Url->New(GetBaseUrl() + "/threads/{$thread_id}/messages"), "application/json", headers);
			if(response <> Nil) {
				if(IsDebug()) {
					"--- https://api.openai.com/v1/threads/{$thread_id}/messages' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();
				};

				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				if(root_json->Has("error")) {
					error_str := root_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				messages_json := root_json->Get("data");
				each(message_json in messages_json) {
					messages->AddBack(API.OpenAI.Message->New(message_json, token));
				};
			};

			return messages;
		}
	}

	#~
	Represents an execution run on a thread
	~#
	class Run from EndPoint {
		@id : String;
		@object : String;
		@created_at : Int;
		@thread_id : String;
		@assistant_id : String;
		@status : String;

		@func_callback_id : String;
		@func_call_name : String;
		@func_call_params : String;

		New : private(run_json : JsonElement) {
			Parent();
			Set(run_json);
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		The status of the run, which can be either: 'queued', 'in_progress', 
		'requires_action', 'cancelling', 'cancelled', 'failed', 'completed', or 'expired'.
		~#
		method : public : GetStatus() ~ String {
			return @status;
		}

		#~
		Get function callback information
		~#
		method : public : IsFunctionCall() ~ Bool {
			return @func_callback_id <> Nil & @func_call_name <> Nil & @func_call_params <> Nil;
		}

		#~
		Get function callback information
		@return pair function name and calling parameters in JSON format
		~#
		method : public : GetFunctionCall() ~ Collection.Tuple.Triplet<String, String, String> {
			return Collection.Tuple.Triplet->New(@func_call_name, @func_call_params, @func_callback_id)<String, String, String>;
		}
		
		method: Set(run_json : JsonElement) ~ Nil {

# "--- Run ---"->PrintLine();
# run_json->ToString()->PrintLine();


			@id := run_json->Get("id")->GetString();
			@created_at := run_json->Get("created_at")->GetInt();
			@object := run_json->Get("object")->GetString();
			@thread_id := run_json->Get("thread_id")->GetString();
			@assistant_id := run_json->Get("assistant_id")->GetString();
			
			@status := run_json->Get("status")->GetString();
			if(@status->Equals("requires_action")) {
				tool_calls_json := run_json->FindElements("required_action/submit_tool_outputs/tool_calls");
				each(tool_call_json in tool_calls_json) {
					@func_callback_id := tool_call_json->Get("id")->GetString();
					@func_call_name := tool_call_json->FindElements("function/name")->GetString();
					@func_call_params := tool_call_json->FindElements("function/arguments")->GetString();
				};
			}
			else {
				@func_call_name := @func_call_params := Nil;
			};
		}

		#~
		Create a run
		@param assistant the assistant to use to execute this run
		@param thread thread to run
		@param token API token
		@return newly created Run
		~#
		function : Create(assistant : API.OpenAI.Assistant, thread : API.OpenAI.Thread, token : String) ~ API.OpenAI.Run {
			run_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			run_json->Insert("assistant_id", assistant->GetId());
			data := run_json->ToString()->ToByteArray();
			
			thread_id := thread->GetId();
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickPost(Url->New(GetBaseUrl() + "/threads/{$thread_id}/runs"), data, "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				run_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(run_json = Nil) {
					"### Error: Unable to parse thread response ###"->ErrorLine();
					return Nil;
				};
				
				if(run_json->Has("error")) {
					error_str := run_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return API.OpenAI.Run->New(run_json);
			};
			
			return Nil;	
		}

		#~
		Refreshed the run's data such as status
		@param token API token
		@return newly created Run
		~#
		method : public : Refresh(token : String) ~ Bool {
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickGet(Url->New(GetBaseUrl() + "/threads/{$@thread_id}/runs/{$@id}"), "application/json", headers);
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: 'https://api.openai.com/v1/threads/{$@thread_id}/runs/{$@id}' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();
				};

				run_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(run_json = Nil) {
					return false;
				};

				if(run_json->Has("error")) {
					error_str := run_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				};

				run_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(run_json = Nil) {
					return false;
				};

				if(run_json->Has("error")) {
					error_str := run_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				};

				Set(run_json);				
				return true;
			}

			return false;
		}

		#~
		Submits a tool's response
		@param func_response_json response in JSON format
		@param func_callback_id function callback ID
		@param token API token
		@return true if successful, false otherwise
		~#
		method : public : SubmitToolOutputs(func_response_json : JsonElement, func_callback_id : String, token : String) ~ Bool {
			tool_callback_output_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			tool_callback_output_json->Insert("tool_call_id", func_callback_id);
			tool_callback_output_json->Insert("output", func_response_json->GetString());

			tool_callback_array_json := JsonElement->New(JsonElement->JsonType->ARRAY);
			tool_callback_array_json->Add(tool_callback_output_json);

			tool_callback_obj_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			tool_callback_obj_json->Insert("tool_outputs", tool_callback_array_json);

			data := tool_callback_obj_json->ToString()->ToByteArray();
			# data->ToString()->PrintLine();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickPost(Url->New(GetBaseUrl() + "/threads/{$@thread_id}/runs/{$@id}/submit_tool_outputs"), data, "application/json", headers);
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: 'https://api.openai.com/v1/threads/{$@thread_id}/runs/{$@id}/submit_tool_outputs' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();
				};

				run_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(run_json = Nil) {
					return false;
				};

				if(run_json->Has("error")) {
					error_str := run_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				};

				run_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(run_json = Nil) {
					return false;
				};

				if(run_json->Has("error")) {
					error_str := run_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				};

				return true;
			}

			return false;

		}

		#~
		Loads a run
		@param id run ID
		@param thread instance associated with run
		@param token API token
		@return loaded Run
		~#
		function : Load(id : String, thread : API.OpenAI.Thread, token : String) ~ API.OpenAI.Run {
			thread_id := thread->GetId();
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v2");
			response := HttpsClient->QuickGet(Url->New(GetBaseUrl() + "/threads/{$thread_id}/runs/{$id}"), "application/json", headers);
			if(response <> Nil) {
				if(IsDebug()) {
					"--- Called: 'https://api.openai.com/v1/threads/{$thread_id}/runs/{$id}' ---"->PrintLine();
					response->GetContent()->ToString()->PrintLine();
				};

				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				if(root_json->Has("error")) {
					error_str := root_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				if(root_json->Has("error")) {
					error_str := root_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return API.OpenAI.Run->New(root_json);
			}

			return Nil;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			buffer := "[id='";
			buffer += @id;

			buffer += "', object='"
			buffer += @object;

			buffer += "', created_at='"
			buffer += @created_at;

			buffer += "', created_at="
			buffer += @created_at;

			buffer += ", assistant_id='"
			buffer += @assistant_id;

			buffer += "', thread_id='"
			buffer += @thread_id;

			buffer += "', status='"
			buffer += @status;

			buffer += "']";
			return buffer;
		}
	}

	#~
	OpenAI endpoint
	~#
	class EndPoint {
		@base_url : static : String;
		@last_message : static : String;
		@api_key : static : String;

		function : IsDebug() ~ Bool {
			return false;
		}

		#~
		Set the base URL
		@param base_url base URL
		~#
		function : SetBaseUrl(base_url : String) ~ Nil {
			if(base_url <> Nil & <>base_url->IsEmpty()) {
				if(base_url->EndsWith('/')) {
					base_url->Pop();
				};

				@base_url := base_url;
			};
		}

		#~
		Get the base URL
		@return base
		~#
		function : GetBaseUrl() ~ String {
			if(@base_url = Nil) {
				@base_url := "https://api.openai.com/v1";
			};

			return @base_url;
		}

		function : SetLastError(last_message : String) ~ Nil {
			@last_message := last_message;
		}

		#~
		Get the last error
		@return last error
		~#
		function : GetLastError() ~ String {
			if(@last_message = Nil) {
				return "<none>";
			}

			return @last_message;
		}

		#~
		Set the API file key path
		@param api_key API file key path
		~#
		function : SetApiKey(api_key : String) ~ Nil {
			@api_key := api_key;
		}

		#~
		Reads API from 'api_key.dat'
		@return API key
		~#
		function : GetApiKey() ~ String {
			if(@api_key = Nil) {
				filename := "openai_api_key.dat";
				token := System.IO.Filesystem.FileReader->ReadFile(filename);
				if(token = Nil) {
					dir_str := System.IO.Filesystem.Directory->GetWorking();
					dir_str += System.IO.Filesystem.Directory->GetSlash();
					dir_str += filename;
					
					">>> Unable to read API key from: '{$dir_str}', also consider calling SetApiKey(..)"->ErrorLine();
				}
				else {
					@api_key := token->Trim();
				};
			};

			return @api_key;
		}
	}
}
