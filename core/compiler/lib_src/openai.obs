#~~
Copyright (c) 2024 Randy Hollines
~~#	

use Web.HTTP, Collection, System.IO.Filesystem, Data.JSON, Data.JSON.Scheme;

#~
Support for OpenAI audio APIs (-lib openai)
~#
bundle API.OpenAI.Audio {
	#~
	Transcribes audio into the given output format.
	~#
	class Transcription from EndPoint {
		#~
		Transcribes audio into the output format.
		@param name transcription name
		@param content byte stream to translate
		@param model ID of the model to use
		@param token API token
		@return translated text, Nil if unsuccessful
		~#
		function : Translate(name : String, content : Byte[], model : String, token : String) ~ String {
			return Translate(name, content, model, Nil, Nil, -1.0, token)
		}

		#~
		Transcribes audio into the given output format.
		@param name transcription name
		@param content byte stream to translate
		@param model ID of the model to use
		@param prompt text to guide the model's style or continue a previous audio segment
		@param response_format format of the transcript output, options: 'json', 'text', 'srt', 'verbose_json', or 'vtt'
		@param temperature sampling temperature, between 0 and 1, higher values make the output more random
		@param token API token
		@return translated text, Nil if unsuccessful
		~#
		function : Translate(name : String, content : Byte[], model : String, prompt : String, response_format : String, temperature : Float, token : String) ~ String {
			encoder := Web.HTTP.Server.MultipartEncoder->New();

			model_headers := Map->New()<String, String>;
			model_headers->Insert("Content-Disposition", "form-data; name=\"model\"");
			model_content := Web.HTTP.Server.MultipartContent->New(model_headers, model->ToByteArray());
			encoder->Add(model_content);

			content_headers := Map->New()<String, String>;
			content_headers->Insert("Content-Disposition", "form-data; name=\"file\"; filename=\"{$name}\"");
			content_headers->Insert("Content-Type", "application/octet-stream");
			multi_content := Web.HTTP.Server.MultipartContent->New(content_headers, content);
			encoder->Add(multi_content);

			if(prompt <> Nil) {
				prompt_headers := Map->New()<String, String>;
				prompt_headers->Insert("Content-Disposition", "form-data; name=\"prompt\"");
				prompt_content := Web.HTTP.Server.MultipartContent->New(prompt_headers, prompt->ToByteArray());
				encoder->Add(prompt_content);
			};

			if(response_format <> Nil) {
				response_format_headers := Map->New()<String, String>;
				response_format_headers->Insert("Content-Disposition", "form-data; name=\"response_format\"");
				response_format_content := Web.HTTP.Server.MultipartContent->New(response_format_headers, response_format->ToByteArray());
				encoder->Add(response_format_content);
			};

			if(temperature >= 0.0 & temperature <= 1.0) {
				temperature_headers := Map->New()<String, String>;
				temperature_headers->Insert("Content-Disposition", "form-data; name=\"temperature\"");
				temperature_content := Web.HTTP.Server.MultipartContent->New(temperature_headers, temperature->ToString()->ToByteArray());
				encoder->Add(temperature_content);
			};

			data := encoder->ToByteArray();

			boundry := encoder->GetBoundary();
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/audio/transcriptions"), data, 
				"multipart/form-data; boundary={$boundry}", headers);

			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				model_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(model_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};
				
				if(model_json->Has("error")) {
					error_str := model_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return model_json->Get("text")->GetString();
			};

			return Nil;
		}
	}

	#~
	Audio APIs provides two speech to text endpoints, transcriptions and translations
	~#
	class Speech from EndPoint {
		#~
		Generates audio from the input text
		@param model available TTS models 'tts-1' or 'tts-1-hd'
		@param input the text to generate audio for, the maximum length is 4096 characters
		@param voice voice to use when generating the audio, supported voices are alloy, 'echo', 'fable', 'onyx', 'nova', and 'shimmer'. 
		@param token API token
		@return response with type and content, Nil if unsuccessful
		~#
		function : Speak(model : String, input : String, voice : String, token : String) ~ Pair<String, ByteArrayRef> {
			return Speak(model, input, voice, "mp3", 0.0, token);
		}

		#~
		Generates audio from the input text
		@param model available TTS models 'tts-1' or 'tts-1-hd'
		@param input the text to generate audio for, the maximum length is 4096 characters
		@param voice voice to use when generating the audio. Supported voices are alloy, 'echo', 'fable', 'onyx', 'nova', and 'shimmer'. 
		@param response_format format to audio in, supported formats are 'mp3', 'opus', 'aac', 'flac', 'wav', and 'pcm'.
		@param token API token
		@return response with type and content, Nil if unsuccessful
		~#
		function : Speak(model : String, input : String, voice : String, response_format : String, token : String) ~ Pair<String, ByteArrayRef> {
			return Speak(model, input, voice, response_format, 0.0, token);
		}

		#~
		Generates audio from the input text
		@param model available TTS models 'tts-1' or 'tts-1-hd'
		@param input the text to generate audio for, the maximum length is 4096 characters
		@param voice voice to use when generating the audio. Supported voices are alloy, 'echo', 'fable', 'onyx', 'nova', and 'shimmer'. 
		@param speed speed of the generated audio 0.25 to 4.0. 1.0 is the default.
		@param response_format format to audio in, supported formats are 'mp3', 'opus', 'aac', 'flac', 'wav', and 'pcm'.
		@param token API token
		@return response with type and content, Nil if unsuccessful
		~#
		function : Speak(model : String, input : String, voice : String, response_format : String, speed : Float, token : String) ~ Pair<String, ByteArrayRef> {
			audio_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			audio_json->Insert("model", model);
			audio_json->Insert("input", input);
			audio_json->Insert("voice", voice);

			if(response_format <> Nil) {
				audio_json->Insert("response_format", response_format);
			};

			if(speed >= 0.25 & speed <= 4.0) {
				audio_json->Insert("speed", speed);
			}
			else {
				audio_json->Insert("speed", 1.0);
			};
			data := audio_json->ToString()->ToByteArray();
			# data->ToString()->PrintLine();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/audio/speech"), data, "application/json", headers);
			# response->GetContent()->ToString()->PrintLine();		

			if(response->GetType()->Equals("application/json")) {
				audio_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(audio_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};
				
				if(audio_json->Has("error")) {
					error_str := audio_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};
			};
			
			return Pair->New(response->GetType(), ByteArrayRef->New(response->GetContent()))<String, ByteArrayRef>;
		}
	}
}

#~
Support for OpenAI chat APIs (-lib openai)
~#
bundle API.OpenAI.Chat {
	#~
	Model response for a given chat conversation
	~#
	class Completion from EndPoint {
		@id : String;
		@object : String;
		@created_at : Int;
		@model : String;
		@choices : Vector<API.OpenAI.Chat.Choice>;

		New(chat_json : JsonElement) {
			Parent();

			@id := chat_json->Get("id")->GetString();
			@object := chat_json->Get("object")->GetString();
			@created_at := chat_json->Get("created")->GetInt();
			@model := chat_json->Get("model")->GetString();

			@choices := Vector->New()<API.OpenAI.Chat.Choice>;
			choices_json := chat_json->Get("choices");
			each(choice_json in choices_json) {
				@choices->AddBack(Choice->New(choice_json));
			};
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		ID of the model to use
		@return ID of the model to use
		~#
		method : public : GetModel() ~ String {
			return @model;
		}

		#~
		List of chat completion choices
		@return completion choices
		~#
		method : public : GetChoices() ~ Vector<API.OpenAI.Chat.Choice> {
			return @choices;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {			
			buffer := "[id='";
			buffer += @id;

			buffer += "', object='"
			buffer += @object;

			buffer += "', model='"
			buffer += @model;

			buffer += "', created_at="
			buffer += @created_at;

			buffer += "\nchoices: ["
			for(i := 0; i < @choices->Size(); i +=1 ;) {
				buffer += i;
				buffer += ": ";
				
				buffer += @choices->Get(i)->ToString();
				
				if(i + 1 < @choices->Size()) {
					buffer += ',';
				};
			};
			buffer += ']';

			return buffer;
		}

		#~
		Model response for the given chat conversation
		@param messages list of messages comprising the conversation so far.
		@param model ID of the model to use
		@param token API token
		@return completion response
		~#
		function : Complete(model : String, messages : Vector<Pair<String, String>>, token : String) ~ Completion {
			completion_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			completion_json->Insert("model", model);

			messages_json := JsonElement->New(JsonElement->JsonType->ARRAY);
			each(message in messages) {
				message_json := JsonElement->New(JsonElement->JsonType->OBJECT);
				message_json->Insert("role", message->GetFirst());
				message_json->Insert("content", message->GetSecond());
				messages_json->Add(message_json);
			};
			completion_json->Insert("messages", messages_json);

			data := completion_json->ToString()->ToByteArray();
			# data->ToString()->PrintLine();			

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/chat/completions"), data, "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				chat_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(chat_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};
				
				error_str := chat_json->FindElements("error/message");
				if(error_str <> Nil) {
					SetLastError(error_str->GetString());
					return Nil;
				};

				return Completion->New(chat_json);
			};

			return Nil;
		}
	}

	#~
	Completion choice
	~#
	class Choice from EndPoint {
		@index : Int;
		@finish_reason : String;
		@message : Pair<String, String>;

		New(chat_json : JsonElement) {
			Parent();
			@index := chat_json->Get("index")->GetInt();
			@finish_reason := chat_json->Get("finish_reason")->GetString();
			message_json := chat_json->Get("message");

			role := message_json->Get("role")->GetString();
			content := message_json->Get("content")->GetString();
			@message := Pair->New(role, content)<String, String>;
		}

		#~
		Get index
		@return index
		~#
		method : public : GetIndex() ~ Int {
			return @index;
		}

		#~
		Get finish reason
		@return finish reason
		~#
		method : public : GetFinishReason() ~ String {
			return @finish_reason;
		}

		#~
		Get message
		@return message
		~#
		method : public : GetMessage() ~ Pair<String, String> {
			return @message;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			role := @message->GetFirst();
			content := @message->GetSecond();
			return "[index={$@index}, finish_reason='{$@finish_reason}', role={$role}, content={$content}]"; 
		}
	}

	#~
	Chat conversation assistant 
	~#
	class Conversation {
		@assistant : Assistant;
		@enable_spinner : Bool;
		@thread : API.OpenAI.Thread;
		@token : String;
		@funcs : Map<String, Func2Ref<JsonElement, JsonElement>>;

		#~
		Constructor 
		@param assistant assistant
		@param enable_spinner true to enable console spinner, false to disable
		@param token API token
		~#
		New(assistant : Assistant, enable_spinner : Bool, token : String) {
			@assistant := assistant;
			@enable_spinner := enable_spinner;
			@token := token;
			@thread := API.OpenAI.Thread->Create(token);
			@funcs := Map->New()<String, Func2Ref<JsonElement, JsonElement>>;
		}

		#~
		Constructor 
		@param assistant assistant
		@param token API token
		~#
		New(assistant : Assistant, token : String) {
			@assistant := assistant;
			@token := token;
			@thread := API.OpenAI.Thread->Create(token);
			@funcs := Map->New()<String, Func2Ref<JsonElement, JsonElement>>;
		}

		#~
		Maps an OpenAI function call (via webhooks) 
		@param name OpenAI function name
		@param func function to map
		@return true if successful, false otherwise
		~#
		method : public : AddFunction(name : String, func : (JsonElement) ~ JsonElement) ~ Bool {
			if(@funcs->Has(name)) {
				return false;
			};

			@funcs->Insert(name, Func2Ref->New(func)<JsonElement, JsonElement>);
			return true;
		}

		method : CallFunction(name : String, params : JsonElement) ~ JsonElement {
			func_ref := @funcs->Find(name)<Func2Ref<JsonElement, JsonElement>>;
			if(func_ref <> Nil) {
				func := func_ref->Get();
				return func(params);
			};

			return Nil;
		}

		#~
		Sends a message to the assistant 
		@param query message to send
		@param user user name
		@return response message, Nil of error
		~#
		method : public : Send(query : String, user : String)  ~ Message {
			Message->Create(user, query, @thread, @token);

			run := API.OpenAI.Run->Create(@assistant, @thread, @token);

			# poll ever 3/4 a second for max of 15 seconds
			is_done := false;
			for(i := 0; <>is_done & i < 20; i += 1;) {
				System.Concurrency.Thread->Sleep(750);
				run->Refresh(@token);
				
				if(@enable_spinner) {
					System.Utility.Spinner->Next();
				};

				if(run->IsFunctionCall()) {
					func_call := run->GetFunctionCall()<String, String, String>;

					func_call_name := Data.JSON.JsonElement->Decode(func_call->GetFirst());
					func_call_params := Data.JSON.JsonElement->Decode(func_call->GetSecond());
					response_json := CallFunction(func_call_name, JsonParser->TextToElement(func_call_params));
					if(response_json <> Nil) {
						func_callback_id := Data.JSON.JsonElement->Decode(func_call->GetThird());
						if(<>run->SubmitToolOutputs(response_json, func_callback_id, @token)) {
							Run->GetLastError()->ErrorLine();
						};
					}
					else {
						Run->SetLastError("Error: invalid function call response");
						return Nil;
					};
				}
				else {
					is_done := run->GetStatus()->Equals("completed");
				};
			};

			if(@enable_spinner) {
				System.Utility.Spinner->Last();
			};

			# last message
			messages := Message->ListMessages(@thread, @token);
			if(<>messages->IsEmpty()) {
				return messages->First();
			};

			return Nil;
		}

		#~
		Closes the chat session
		@return true if successful, false otherwise
		~#
		method : public : Close() ~ Bool {
			return Thread->Delete(@thread->GetId(), @token);
		}
	}
}

#~
Support for fine-tuning models (-lib openai)
~#
bundle API.OpenAI.Tuning {
	#~
	OpenAI fine tuning 
	~#
	class Tuner from EndPoint {
		@id : String;
		@object : String;
		@model : String;
		@created_at : Int;
		@finished_at : Int;
		@fine_tuned_model : String;
		@organization_id : String;
		@status : String;
		@training_file : String;
		@seed : String;
		@n_epochs : String;
		@batch_size : String;
		@learning_rate_multiplier : String;
		@validation_file : String;
		@trained_tokens : String;
		@user_provided_suffix : String;
		@estimated_finish : String;		
		@error_code : String;
		@error_param : String;
		@error_message : String;

		New(tune_json : JsonElement) {
			Parent();

			@id := tune_json->Get("id")->GetString();
			@object := tune_json->Get("object")->GetString();
			@model := tune_json->Get("model")->GetString();
			@created_at := tune_json->Get("created_at")->GetInt();
			
			finished_at_json := tune_json->Get("finished_at");
			if(finished_at_json <> Nil & <>finished_at_json->IsNull()) {
				@finished_at := finished_at_json->GetInt();
			};

			fine_tuned_model_json := tune_json->Get("fine_tuned_model");
			if(fine_tuned_model_json <> Nil & <>fine_tuned_model_json->IsNull()) {
				@fine_tuned_model := fine_tuned_model_json->GetString();
			};

			@organization_id := tune_json->Get("organization_id")->GetString();
			@status := tune_json->Get("status")->GetString();
			@training_file := tune_json->Get("training_file")->GetString();
			@seed := tune_json->Get("seed")->GetString();

			hyper_parameters_json := tune_json->Get("hyperparameters");
			if(hyper_parameters_json <> Nil & <>hyper_parameters_json->IsNull()) {
				@n_epochs := hyper_parameters_json->Get("n_epochs")->GetString();
				@batch_size := hyper_parameters_json->Get("batch_size")->GetString();
				@learning_rate_multiplier := hyper_parameters_json->Get("learning_rate_multiplier")->GetString();
			};

			validation_file_json := tune_json->Get("validation_file");
			if(validation_file_json <> Nil & <>validation_file_json->IsNull()) {
				@validation_file := validation_file_json->GetString();
			};

			trained_tokens_json := tune_json->Get("trained_tokens");
			if(trained_tokens_json <> Nil & <>trained_tokens_json->IsNull()) {
				@trained_tokens := trained_tokens_json->GetString();
			};

			user_provided_suffix_json := tune_json->Get("user_provided_suffix");
			if(user_provided_suffix_json <> Nil & <>user_provided_suffix_json->IsNull()) {
				@user_provided_suffix := user_provided_suffix_json->GetString();
			};

			error_code_json := tune_json->FindElements("error/code");
			if(error_code_json <> Nil) {
				@error_code := error_code_json->GetString();
				@error_param := tune_json->FindElements("error/param")->GetString();
				@error_message := tune_json->FindElements("error/message")->GetString();
			};

			estimated_finish_json := tune_json->Get("estimated_finish");
			if(estimated_finish_json <> Nil & <>estimated_finish_json->IsNull()) {
				@estimated_finish := estimated_finish_json->GetString();
			};

			#~
				"result_files":	[],
				"integrations":	[]
			~#
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		Unix timestamp (in seconds) of when the job finished
		@return time with the job finished
		~#
		method : public : GetFinishedAt() ~ Int {
			return @finished_at;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Get the name of the training file
		@return name of the training file
		~#
		method : public : GetTrainingFilename() ~ String {
			return @training_file;
		}

		#~
		Get status of the tuning job
		@return name of the training file
		~#
		method : public : GetStatus() ~ String {
			return @status;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			fine_tuned_model := @fine_tuned_model = Nil ? "<null>" : @fine_tuned_model;
			validation_file := @validation_file = Nil ? "<null>" : @validation_file;
			trained_tokens := @trained_tokens = Nil ? "<null>" : @trained_tokens;
			user_provided_suffix := @user_provided_suffix = Nil ? "<null>" : @user_provided_suffix;
			estimated_finish := @estimated_finish = Nil ? "<null>" : @estimated_finish;
			error_code := @error_code = Nil ? "<null>" : @error_code;
			error_param := @error_param = Nil ? "<null>" : @error_param;
			error_message := @error_message = Nil ? "<null>" : @error_message;
			
			buffer := "[id='{$@id}', object='{$@object}', model={$@model}, created_at={$@created_at}, ";
			buffer += "finished_at='{$@finished_at}', fine_tuned_model='{$fine_tuned_model}', ";
			buffer += "n_epochs='{$@n_epochs}', batch_size='{$@batch_size}, learning_rate_multiplier='{$@learning_rate_multiplier}', ";
			buffer += "validation_file='{$validation_file}', trained_tokens='{$trained_tokens}', ";
			buffer += "estimated_finish='{$estimated_finish}', status='{$@status}', user_provided_suffix='{$user_provided_suffix}', ";
			buffer += "error_code='{$error_code}', error_param='{$error_param}', error_message='{$error_message}', ";
			buffer += "training_file='{$@training_file}, organization_id='{$@organization_id}']";

			return buffer;
		}

		#~
		Create a fine-turning job using an uploaded file as training data
		@param model model name
		@param training_file_id uploaded training file ID to a file in JSONL format
		@param token API token
		@return fine-tuning job instance
		~#
		function : Create(model : String, training_file_id : String, token : String) ~ API.OpenAI.Tuning.Tuner {
			tune_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			tune_json->Insert("model", model);
			tune_json->Insert("training_file", training_file_id);
			data := tune_json->ToString()->ToByteArray();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/fine_tuning/jobs"), data, "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();
				tune_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(tune_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};

				error_str := tune_json->FindElements("error/message");				
				if(error_str <> Nil) {
					SetLastError(error_str->GetString());
					return Nil;
				};

				return Tuner->New(tune_json);
			};

			return Nil;
		}

		#~
		Loads a list fine-tuning jobs
		@param token API token
		@return fine-tuning jobs
		~#
		function : ListJobs(token : String) ~ Vector<API.OpenAI.Tuning.Tuner> {
			return ListJobs(-1, token);
		}

		#~
		Loads a list fine-tuning jobs
		@param limit number of jobs to retrieve
		@param token API token
		@return fine-tuning jobs
		~#
		function : ListJobs(limit : Int, token : String) ~ Vector<API.OpenAI.Tuning.Tuner> {
			jobs := Vector->New()<API.OpenAI.Tuning.Tuner>

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			
			url_str := "https://api.openai.com/v1/fine_tuning/jobs";
			if(limit > 0) {
				url_str += "?limit={$limit}";
			};

			response := HttpsClient->QuickGet(Url->New(url_str), headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();
				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				error_str := root_json->FindElements("error/message");				
				if(error_str <> Nil) {
					SetLastError(error_str->GetString());
					return Nil;
				};

				jobs_json := root_json->Get("data");
				each(job_json in jobs_json) {
					jobs->AddBack(API.OpenAI.Tuning.Tuner->New(job_json));
				};
			};

			return jobs;
		}

		#~
		Lists events for a job
		@param job_id job ID
		@param token API token
		@return job events
		~#
		function : ListEvents(job_id : String, token : String) ~ Vector<API.OpenAI.Tuning.Job> {
			return ListEvents(job_id, -1, token);
		}

		#~
		Lists events for a job
		@param job_id job ID
		@param limit number of jobs to retrieve		
		@param token API token
		@return job events
		~#
		function : ListEvents(job_id : String, limit : Int, token : String) ~ Vector<API.OpenAI.Tuning.Job> {
			events := Vector->New()<API.OpenAI.Tuning.Job>

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			
			url_str := "https://api.openai.com/v1/fine_tuning/jobs/{$job_id}/events";
			if(limit > 0) {
				url_str += "?limit={$limit}";
			};

			response := HttpsClient->QuickGet(Url->New(url_str), headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();
				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				error_str := root_json->FindElements("error/message");				
				if(error_str <> Nil) {
					SetLastError(error_str->GetString());
					return Nil;
				};

				events_json := root_json->Get("data");
				each(job_json in events_json) {
					events->AddBack(API.OpenAI.Tuning.Job->New(job_json));
				};
			};

			return events;
		}

		#~
		Lists checkpoints for a fine-tuning job
		@param job_id job ID
		@param token API token
		@return job checkpoints
		~#
		function : ListCheckpoints(job_id : String, token : String) ~ Vector<API.OpenAI.Tuning.Checkpoint> {
			return ListCheckpoints(job_id, -1, token);
		}

		#~
		Lists checkpoints for a fine-tuning job
		@param job_id job ID
		@param limit number of jobs to retrieve		
		@param token API token
		@return job checkpoints
		~#
		function : ListCheckpoints(job_id : String, limit : Int, token : String) ~ Vector<API.OpenAI.Tuning.Checkpoint> {
			checkpoints := Vector->New()<API.OpenAI.Tuning.Checkpoint>

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			
			url_str := "https://api.openai.com/v1/fine_tuning/jobs/{$job_id}/checkpoints";
			if(limit > 0) {
				url_str += "?limit={$limit}";
			};

			response := HttpsClient->QuickGet(Url->New(url_str), headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();
				
				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				error_str := root_json->FindElements("error/message");				
				if(error_str <> Nil) {
					SetLastError(error_str->GetString());
					return Nil;
				};

				checkpoints_json := root_json->Get("data");
				each(checkpoint_json in checkpoints_json) {
					checkpoints->AddBack(API.OpenAI.Tuning.Checkpoint->New(checkpoint_json));
				};
			};

			return checkpoints;
		}

		#~
		Load a tuning job
		@param job_id tuning job ID
		@param token API token
		@return tuning reference
		~#
		function : Load(job_id : String, token : String) ~ API.OpenAI.Tuning.Tuner {
			tuning : API.OpenAI.Tuning.Tuner;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickGet(Url->New("https://api.openai.com/v1/fine_tuning/jobs/{$job_id}"), "application/json", headers);
			
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				tuning_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(tuning_json = Nil) {
					return Nil;
				};

				tuning := API.OpenAI.Tuning.Tuner->New(tuning_json);
			};

			return tuning;
		}

		#~
		Cancel a tuning job
		@param job_id tuning job ID
		@param token API token
		@return canceled tuning reference
		~#
		function : Cancel(job_id : String, token : String) ~ API.OpenAI.Tuning.Tuner {
			tuning : API.OpenAI.Tuning.Tuner;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/fine_tuning/jobs/{$job_id}/cancel"), 
				Byte->New[0], "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				tuning_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(tuning_json = Nil) {
					return Nil;
				};

				tuning := API.OpenAI.Tuning.Tuner->New(tuning_json);
			};

			return tuning;
		}
	}

	#~
	Fine-tuning checkpoint
	~#
	class Checkpoint {
		@id : String;
		@object : String;
		@created_at : Int;
		@fine_tuning_job_id : String;
		@step_number : Int;
		@full_valid_loss : String;
		@full_valid_mean_token_accuracy : Float;
		
		New(job_json : JsonElement) {
			@id := job_json->Get("id")->GetString();
			@object := job_json->Get("object")->GetString();
			@created_at := job_json->Get("created_at")->GetInt();
			@fine_tuning_job_id := job_json->Get("fine_tuning_job_id")->GetString();
			@step_number := job_json->Get("step_number")->GetInt();

			metrics_json := job_json->FindElements("metrics/full_valid_loss");
			if(metrics_json <> Nil) {
				@full_valid_loss := metrics_json->GetString();
				@full_valid_mean_token_accuracy := job_json->FindElements("metrics/full_valid_mean_token_accuracy")->GetFloat();
			};
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			full_valid_loss := @full_valid_loss = Nil ? "<null>" : @full_valid_loss;
			
			buffer := "[id='{$@id}', object='{$@object}', created_at={$@created_at}, ";
			buffer += "fine_tuning_job_id='{$@fine_tuning_job_id}', step_number={$@step_number}, ";
			buffer += "full_valid_loss='{$full_valid_loss}', full_valid_mean_token_accuracy={$@full_valid_mean_token_accuracy}]";

			return buffer;
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @fine_tuning_job_id;
		}

		#~
		Get checkpoint step
		@return checkpoint step
		~#
		method : public : GetStep() ~ Int {
			return @step_number;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		Get object job API ID
		@return job ID
		~#
		method : public : GetJobId() ~ String {
			return @id;
		}
	}

	#~
	Fine-tuning job
	~#
	class Job {
		@id : String;
		@object : String;
		@created_at : Int;
		@level : String;
		@message : String;
		@type : String;
		@error_code : String;
		@error_param : String;

		New(tune_json : JsonElement) {
			@id := tune_json->Get("id")->GetString();
			@object := tune_json->Get("object")->GetString();
			@created_at := tune_json->Get("created_at")->GetInt();
			@level := tune_json->Get("level")->GetString();
			@message := tune_json->Get("message")->GetString();
			@type := tune_json->Get("type")->GetString();

			error_code_json := tune_json->FindElements("data/error_code");
			if(error_code_json <> Nil) {
				@error_code := error_code_json->GetString();
				@error_param := tune_json->FindElements("data/error_param")->GetString();
			};
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		Get the level
		@return level
		~#
		method : public : GetLevel() ~ String {
			return @level;
		}

		#~
		Get message
		@return message
		~#
		method : public : GetMessage() ~ String {
			return @message;
		}

		#~
		Get type
		@return type
		~#
		method : public : GetType() ~ String {
			return @type;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			error_code := @error_code = Nil ? "<null>" : @error_code;
			error_param := @error_param = Nil ? "<null>" : @error_param;

			buffer := "[id='{$@id}', object='{$@object}', created_at={$@created_at}, level='{$@level}', ";
			buffer += "message='{$@message}', type='{$@type}', error_code='{$error_code}', error_param='{$error_param}']";

			return buffer;
		}
	}
}

#~
Support for OpenAIs models and assistant and general APIs (-lib openai)
~#
bundle API.OpenAI {
	#~
	OpenAI image generator
	~#
	class Image from EndPoint {
		@created_at : Int;
		@urls : Url[];

		enum Size {
			DALLE2_256_256, 
			DALLE2_512_512,
			DALLE2_1024_1024,
			DALLE3_1024_1024,
			DALLE3_1792_1024,
			DALLE3_1024_1792,
			DALLE_DEFAULT
		}

		New(image_json : JsonElement) {
			Parent();

			@created_at := image_json->Get("created")->GetInt();

			urls_json := image_json->Get("data");
			@urls := Url->New[urls_json->Size()];
			each(i : urls_json) {
				url_json := urls_json->Get(i);
				url := url_json->Get("url")->GetString();
				@urls[i] := Url->New(url);
			};
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		Get the generated images URLs
		@return generated images URLs
		~#
		method : public : GetUrls() ~ Url[] {
			return @urls
		}

		#~
		Creates an image given a prompt
		@param prompt text description of the desired image
		@param token API token
		@return generated image
		~#
		function : Create(prompt : String, token : String) ~ API.OpenAI.Image {
			return Create(prompt, Nil, -1, Nil, Nil, Image->Size->DALLE_DEFAULT, Nil, Nil, token);
		}

		#~
		Creates an image given a prompt
		@param prompt text description of the desired image
		@param model model name
		@param size size of the generated image
		@param token API token
		@return generated image
		~#
		function : Create(prompt : String, model : String, size : Image->Size, token : String) ~ API.OpenAI.Image {
			return Create(prompt, model, -1, Nil, Nil, Image->Size->DALLE_DEFAULT, Nil, Nil, token);
		}

		#~
		Creates an image given a prompt
		@param prompt text description of the desired image
		@param model model name
		@param n number of images
		@param quality quality of the image that will be generated		
		@param response_format format in which the generated images are returned
		@param size size of the generated image
		@param style style of the generated image
		@param user identifier representing your end-user
		@param token API token
		@return generated image
		~#
		function : Create(prompt : String, model : String, n : Int, quality : String, response_format : String,
				size : Image->Size, style : String, user : String, token : String) ~ API.OpenAI.Image {
			image_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			image_json->Insert("prompt", prompt);
			
			if(model <> Nil) {
				image_json->Insert("model", model);
			}
			
			if(n > 0 & n <= 10) {
				image_json->Insert("n", n);
			};
			
			if(quality <> Nil) {
				image_json->Insert("quality", quality);
			};

			if(response_format <> Nil) {
				image_json->Insert("response_format", response_format);
			};
			
			select(size) {
				label Image->Size->DALLE2_256_256 {
					image_json->Insert("size", "256x256");
				}

				label Image->Size->DALLE2_512_512 {
					image_json->Insert("size", "512x512");
				}

				label Image->Size->DALLE2_1024_1024:
				label Image->Size->DALLE3_1024_1024 {
					image_json->Insert("size", "1024x1024");
				}

				label Image->Size->DALLE3_1792_1024:
				label Image->Size->DALLE3_1024_1792 {					
					image_json->Insert("size", "1792x1024");
				}
			};

			if(style <> Nil) {
				image_json->Insert("style", style);
			};

			if(user <> Nil) {
				image_json->Insert("user", user);
			};

			data := image_json->ToString()->ToByteArray();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/images/generations"), data, "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();
				image_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(image_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};

				error_str := image_json->FindElements("error/message");				
				if(error_str <> Nil) {
					SetLastError(error_str->GetString());
					return Nil;
				};

				return API.OpenAI.Image->New(image_json);
			};

			return Nil;
		}
		
		#~
		Creates an edited or extended image given an original image and a prompt
		@param image_name image name
		@param image_content image content
		@param prompt text description of the desired image
		@param token API token
		@return edited image
		~#
		function : Edit(image_name : String, image_content : Byte[], prompt : String, token : String) ~ API.OpenAI.Image {
			return Edit(image_name, image_content, prompt, Nil, Nil->As(Byte[]), Nil, -1, Image->Size->DALLE_DEFAULT, Nil, Nil, token);
		}

		#~
		Creates an edited or extended image given an original image and a prompt
		@param image_name image name
		@param image_content image content
		@param prompt text description of the desired image
		@param mask_name mask name
		@param mask_content additional image whose fully transparent areas (e.g. where alpha is zero) 
		@param model model name
		@param n number of images
		@param size size of the generated image
		@param response_format format in which the generated images are returned		
		@param user identifier representing your end-user
		@param token API token
		@return edited image
		~#
		function : Edit(image_name : String, image_content : Byte[], prompt : String, mask_name : String, mask_content : Byte[], 
				model : String, n : Int, size : Image->Size, response_format : String, user : String, token : String) ~ API.OpenAI.Image {
			
			encoder := Web.HTTP.Server.MultipartEncoder->New();

			# image
			image_headers := Map->New()<String, String>;
			image_headers->Insert("Content-Disposition", "form-data; name=\"image\"; filename=\"{$image_name}\"");
			image_headers->Insert("Content-Type", "application/octet-stream");
			encoder->Add(Web.HTTP.Server.MultipartContent->New(image_headers, image_content));

			# prompt
			prompt_headers := Map->New()<String, String>;
			prompt_headers->Insert("Content-Disposition", "form-data; name=\"prompt\"");
			encoder->Add(Web.HTTP.Server.MultipartContent->New(prompt_headers, prompt->ToByteArray()));

			# mask
			if(mask_name <> Nil & mask_content <> Nil) {
				mask_headers := Map->New()<String, String>;
				mask_headers->Insert("Content-Disposition", "form-data; name=\"mask\"; filename=\"{$mask_name}\"");
				mask_headers->Insert("Content-Type", "application/octet-stream");
				encoder->Add(Web.HTTP.Server.MultipartContent->New(mask_headers, mask_content));
			};

			# model
			if(model <> Nil) {
				model_headers := Map->New()<String, String>;
				model_headers->Insert("Content-Disposition", "form-data; name=\"model\"");
				encoder->Add(Web.HTTP.Server.MultipartContent->New(model_headers, model->ToByteArray()));
			};

			# n
			if(n > 0 & n <= 10) {
				n_headers := Map->New()<String, String>;
				n_headers->Insert("Content-Disposition", "form-data; name=\"n\"");
				encoder->Add(Web.HTTP.Server.MultipartContent->New(n_headers, n->ToString()->ToByteArray()));
			};
			
			# size
			select(size) {
				label Image->Size->DALLE2_256_256 {
					size_headers := Map->New()<String, String>;
					size_headers->Insert("Content-Disposition", "form-data; name=\"size\"");
					encoder->Add(Web.HTTP.Server.MultipartContent->New(size_headers, "256x256"->ToByteArray()));
				}

				label Image->Size->DALLE2_512_512 {
					size_headers := Map->New()<String, String>;
					size_headers->Insert("Content-Disposition", "form-data; name=\"size\"");
					encoder->Add(Web.HTTP.Server.MultipartContent->New(size_headers, "512x512"->ToByteArray()));
				}

				label Image->Size->DALLE2_1024_1024:
				label Image->Size->DALLE3_1024_1024 {
					size_headers := Map->New()<String, String>;
					size_headers->Insert("Content-Disposition", "form-data; name=\"size\"");
					encoder->Add(Web.HTTP.Server.MultipartContent->New(size_headers, "1024x1024"->ToByteArray()));
				}

				label Image->Size->DALLE3_1792_1024:
				label Image->Size->DALLE3_1024_1792 {					
					size_headers := Map->New()<String, String>;
					size_headers->Insert("Content-Disposition", "form-data; name=\"size\"");
					encoder->Add(Web.HTTP.Server.MultipartContent->New(size_headers, "1792x1024"->ToByteArray()));
				}
			};

			# response format
			if(response_format <> Nil) {
				response_format_headers := Map->New()<String, String>;
				response_format_headers->Insert("Content-Disposition", "form-data; name=\"response_format\"");
				encoder->Add(Web.HTTP.Server.MultipartContent->New(response_format_headers, response_format->ToByteArray()));
			};

			# user
			if(user <> Nil) {
				user_headers := Map->New()<String, String>;
				user_headers->Insert("Content-Disposition", "form-data; name=\"user\"");
				encoder->Add(Web.HTTP.Server.MultipartContent->New(user_headers, user->ToByteArray()));
			};

			boundry := encoder->GetBoundary();
			data := encoder->ToByteArray();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/images/edits"), data, 
				"multipart/form-data; boundary={$boundry}", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();
				image_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(image_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};

				error_str := image_json->FindElements("error/message");				
				if(error_str <> Nil) {
					SetLastError(error_str->GetString());
					return Nil;
				};

				return API.OpenAI.Image->New(image_json);					
			};

			return Nil;
		}

		#~
		Creates a variation of a given image
		@param image_name image name
		@param image_content image content
		@param token API token
		@return image variation
		~#
		function : Variation(image_name : String, image_content : Byte[], token : String) ~ API.OpenAI.Image {
			return Variation(image_name, image_content, Nil, -1, Nil, Image->Size->DALLE_DEFAULT, Nil, token);
		}

		#~
		Creates a variation of a given image
		@param image_name image name
		@param image_content image content
		@param model model name
		@param n number of images
		@param response_format format in which the generated images are returned		
		@param size size of the generated image
		@param user identifier representing your end-user
		@param token API token
		@return image variation
		~#
		function : Variation(image_name : String, image_content : Byte[], model : String, n : Int, response_format : String, size : Image->Size, user : String, token : String) ~ API.OpenAI.Image {
			
			encoder := Web.HTTP.Server.MultipartEncoder->New();

			# image
			image_headers := Map->New()<String, String>;
			image_headers->Insert("Content-Disposition", "form-data; name=\"image\"; filename=\"{$image_name}\"");
			image_headers->Insert("Content-Type", "application/octet-stream");
			encoder->Add(Web.HTTP.Server.MultipartContent->New(image_headers, image_content));

			# model
			if(model <> Nil) {
				model_headers := Map->New()<String, String>;
				model_headers->Insert("Content-Disposition", "form-data; name=\"model\"");
				encoder->Add(Web.HTTP.Server.MultipartContent->New(model_headers, model->ToByteArray()));
			};

			# n
			if(n > 0 & n <= 10) {
				n_headers := Map->New()<String, String>;
				n_headers->Insert("Content-Disposition", "form-data; name=\"n\"");
				encoder->Add(Web.HTTP.Server.MultipartContent->New(n_headers, n->ToString()->ToByteArray()));
			};

			# response format
			if(response_format <> Nil) {
				response_format_headers := Map->New()<String, String>;
				response_format_headers->Insert("Content-Disposition", "form-data; name=\"response_format\"");
				encoder->Add(Web.HTTP.Server.MultipartContent->New(response_format_headers, response_format->ToByteArray()));
			};
			
			# size
			select(size) {
				label Image->Size->DALLE2_256_256 {
					size_headers := Map->New()<String, String>;
					size_headers->Insert("Content-Disposition", "form-data; name=\"size\"");
					encoder->Add(Web.HTTP.Server.MultipartContent->New(size_headers, "256x256"->ToByteArray()));
				}

				label Image->Size->DALLE2_512_512 {
					size_headers := Map->New()<String, String>;
					size_headers->Insert("Content-Disposition", "form-data; name=\"size\"");
					encoder->Add(Web.HTTP.Server.MultipartContent->New(size_headers, "512x512"->ToByteArray()));
				}

				label Image->Size->DALLE2_1024_1024:
				label Image->Size->DALLE3_1024_1024 {
					size_headers := Map->New()<String, String>;
					size_headers->Insert("Content-Disposition", "form-data; name=\"size\"");
					encoder->Add(Web.HTTP.Server.MultipartContent->New(size_headers, "1024x1024"->ToByteArray()));
				}

				label Image->Size->DALLE3_1792_1024:
				label Image->Size->DALLE3_1024_1792 {					
					size_headers := Map->New()<String, String>;
					size_headers->Insert("Content-Disposition", "form-data; name=\"size\"");
					encoder->Add(Web.HTTP.Server.MultipartContent->New(size_headers, "1792x1024"->ToByteArray()));
				}
			};

			# user
			if(user <> Nil) {
				user_headers := Map->New()<String, String>;
				user_headers->Insert("Content-Disposition", "form-data; name=\"user\"");
				encoder->Add(Web.HTTP.Server.MultipartContent->New(user_headers, user->ToByteArray()));
			};

			boundry := encoder->GetBoundary();
			data := encoder->ToByteArray();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/images/variations"), data, 
				"multipart/form-data; boundary={$boundry}", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();
				image_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(image_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};

				error_str := image_json->FindElements("error/message");				
				if(error_str <> Nil) {
					SetLastError(error_str->GetString());
					return Nil;
				};

				return API.OpenAI.Image->New(image_json);					
			};

			return Nil;
		}
	}

	#~
	OpenAI file support

```
# upload tuning file
filename := "tuning.json";
data := FileReader->ReadFile(filename)->ToByteArray();
API.OpenAI.File->Create(filename, "fine-tune", data, token)->PrintLine();

# list files
files := API.OpenAI.File->ListFiles(token);
if(files <> Nil) {
  each(file in files) {
    name := file->GetFilename();
    id := file->GetId();
    "file='{$name}', id='{$id}'"->PrintLine();
  };
}
else {
  API.OpenAI.File->GetLastError()->PrintLine();
};

# start tuning job
file := API.OpenAI.File->LoadOrCreate(filename, "fine-tune", token);
name := file->GetFilename();
id := file->GetId();
"file='{$name}', id='{$id}'"->PrintLine();

tuning_job := Tuner->Create("gpt-3.5-turbo", id, token);
model_id := tuning_job->GetId();

# query model

assistant := Assistant->Create(model_id, token);
if(assistant = Nil) {
  Assistant->GetLastError()->PrintLine();
  return;
};

assistant_id := assistant->GetId();
assistant_name := assistant->GetName();
assistant_model := assistant->GetModel();
"Created: id='{$id}', name='{$name}', model='{$model}', files={$file_count}, tools={$tool_count}"->PrintLine();

# chat with tuned assistant
session := API.OpenAI.Chat.Conversation->New(Assistant->Load(assistant_id, token), true, token);
session->AddFunction("get_coach_by_year", Callback(JsonElement) ~ JsonElement);

done := false;
do {
  query := Console->ReadLine();
  if(query->Equals("/quit")) {
    session->Close();    
    done := true;
  }
  else {
    response := session->Send(query, "user");

    index := 0;
    role := response->GetRole();
    contents := response->GetContents();
    each(content in contents) {
      type := content->GetFirst()->As(String);
      value := content->GetSecond()->As(String);

      "{$index}: [{$role}, type='{$type}']: value='{$value}'"->PrintLine();
    };
  };
}
while(<>done);

session->Close();
```	
	~#
	class File from EndPoint {
		@id : String;
		@object : String;
		@created_at : Int;
		@bytes : Int;
		@filename : String;
		@purpose : String;
		
		New(file_json : JsonElement, token : String) {
			Parent();

			@id := file_json->Get("id")->GetString();
			@object := file_json->Get("object")->GetString();
			@bytes := file_json->Get("bytes")->GetInt();
			@created_at := file_json->Get("created_at")->GetInt();
			@filename := file_json->Get("filename")->GetString();
			@purpose := file_json->Get("purpose")->GetString();
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Get the size of the file
		@return size of the file
		~#
		method : public : GetBytes() ~ Int {
			return @bytes;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		Get the name of the file
		@return name of the file
		~#
		method : public : GetFilename() ~ String {
			return @filename;
		}

		#~
		Get the purpose
		@return purpose
		~#
		method : public : GetPurpose() ~ String {
			return @purpose;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			return "[id='{$@id}', object='{$@object}', bytes={$@bytes}, created_at={$@created_at}, filename='{$@filename}', purpose='{$@purpose}']"; 
		}

		#~
		Upload a file that can be used across various endpoints
		@param name file object name
		@param content file content
		@param token API token
		@return string representation
		~#
		function : Create(name : String, content : Byte[], token : String) ~ Bool {
			return Create(name, "assistants", content, token);
		}

		#~
		Upload a file that can be used across various endpoints
		@param name file object name
		@param content file content
		@param purpose file purpose 'assistants', 'vision' or 'fine-tune'
		@param token API token
		@return string representation
		~#
		function : Create(name : String, purpose : String, content : Byte[], token : String) ~ Bool {
			purpose_headers := Map->New()<String, String>;
			purpose_headers->Insert("Content-Disposition", "form-data; name=\"purpose\"");
			purpose_content := Web.HTTP.Server.MultipartContent->New(purpose_headers, purpose->ToByteArray());

			content_headers := Map->New()<String, String>;
			content_headers->Insert("Content-Disposition", "form-data; name=\"file\"; filename=\"{$name}\"");
			content_headers->Insert("Content-Type", "application/octet-stream");
			multi_content := Web.HTTP.Server.MultipartContent->New(content_headers, content);

			encoder := Web.HTTP.Server.MultipartEncoder->New();
			encoder->Add(purpose_content);
			encoder->Add(multi_content);
			boundry := encoder->GetBoundary();
			data := encoder->ToByteArray();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/files"), data, 
				"multipart/form-data; boundary={$boundry}", headers);

			return response->GetCode() = 200;
		}

		#~
		Loads a file
		@param id file ID
		@param token API token
		@return file reference
		~#
		function : Load(id : String, token : String) ~ API.OpenAI.File {
			file : API.OpenAI.File;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickGet(Url->New("https://api.openai.com/v1/files/{$id}"), "application/json", headers);
			
			if(response <> Nil) {
				file_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(file_json = Nil) {
					return Nil;
				};

				if(file_json->Has("error")) {
					error_str := file_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				}

				file := API.OpenAI.File->New(file_json, token);
			};

			return file;
		}

		#~
		Deletes a file
		@param id file ID
		@param token API token
		@return true if successful, false otherwise
		~#
		function : Delete(id : String, token : String) ~ Bool {
			file : API.OpenAI.File;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickDelete(Url->New("https://api.openai.com/v1/files/{$id}"), "application/json", headers);
			
			if(response <> Nil) {
				file_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(file_json = Nil) {
					return false;
				};

				if(file_json->Has("error")) {
					error_str := file_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				}

				return file_json->Get("deleted")->GetString()->Equals("true");
			};

			return false;
		}
		
		#~
		Loads or creates an OpenAI file from the local filesystem
		@param filename local file path
		@param token API token
		@return file reference
		~#
		function : LoadOrCreate(filename : String, token : String) ~ API.OpenAI.File {
			return LoadOrCreate(filename, "assistants", token);
		}

		#~
		Loads or creates an OpenAI file from the local filesystem
		@param filename local file path
		@param purpose file purpose 'assistants', 'vision' or 'fine-tune'		
		@param token API token
		@return file reference
		~#
		function : LoadOrCreate(filename : String, purpose : String, token : String) ~ API.OpenAI.File {
			file := LoadByName(filename, token);
			
			if(file = Nil) {
				# "Uploading file: '{$filename}'"->PrintLine();
				content := FileReader->ReadBinaryFile(filename);
				if(content = Nil | content->Size() = 0) {
					"### Error: Unable to load file: '{$filename}' ###"->PrintLine();
					Runtime->Exit(1);
				};

				if(API.OpenAI.File->Create(filename, purpose, content, token)) {
					file := LoadByName(filename, token);
				};
			};

			return file;
		}

		#~
		Loads an OpenAI file from the local filesystem
		@param filename local file path
		@param token API token
		@return file reference
		~#
		function : LoadByName(filename : String, token : String) ~ API.OpenAI.File {
			found : API.OpenAI.File;
			
			files := API.OpenAI.File->ListFiles(token);
			each(file in files) {
				decoded_filename := JsonElement->Decode(file->GetFilename());
				if(decoded_filename->Equals(filename)) {
					found := file;
					break;
				};
			};

			return found;
		}

		#~
		Loads a list available OpenAI files
		@param token API token
		@return file reference
		~#
		function : ListFiles(token : String) ~ Vector<API.OpenAI.File> {
			files := Vector->New()<API.OpenAI.File>

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			response := HttpsClient->QuickGet(Url->New("https://api.openai.com/v1/files"), "application/json", headers);
			if(response <> Nil) {
				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				if(root_json->Has("error")) {
					error_str := root_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				files_json := root_json->Get("data");
				each(file_json in files_json) {
					files->AddBack(API.OpenAI.File->New(file_json, token));
				};
			};

			return files;
		}

		#~
		Returns the contents of the specified file
		@param id file ID
		@param token API token
		@return file content
		~#
		function : Retrieve(id : String, token : String) ~ Byte[] {
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			return HttpsClient->QuickGet(Url->New("https://api.openai.com/v1/files/{$id}/content"), "application/json", headers)->GetContent();
		}
	}

	#~
	Builds assistants that can call models and use tools to perform tasks
	~#
	class Assistant from EndPoint {
		@id : String;
		@object : String;
		@model : String;
		@name : String;
		@description : String;
		@instructions : String;
		@funcs : Vector<FunctionType>;
		@created_at : Int;

		@tools : Vector<String>;
		@files : Vector<API.OpenAI.File>;
		@token : String;

		New : private(assistant_json : JsonElement, token : String) {
			Parent();

			@id := assistant_json->Get("id")->GetString();
			@created_at := assistant_json->Get("created_at")->GetInt();
			@object := assistant_json->Get("object")->GetString();
			@name := assistant_json->Get("name")->GetString();
			@description := assistant_json->Get("description")->GetString();
			@model := assistant_json->Get("model")->GetString();
			@instructions := assistant_json->Get("instructions")->GetString();
			@token := token;

			@tools := Vector->New()<String>;
			tools := assistant_json->Get("tools");
			each(tool in tools) {
				tool_desc := tool->Get("type")->GetString();
				if(tool_desc->Equals("function")) {
					func_json := tool->Get("function");
					if(	@funcs = Nil) {
						@funcs := Vector->New()<FunctionType>;
					};

					func := FunctionType->New(func_json);
					# func->ToString()->PrintLine();					
					@funcs->AddBack(func);
				}

				@tools->AddBack(tool_desc);
			};

			@files := Vector->New()<API.OpenAI.File>;
			file_ids := assistant_json->Get("file_ids");
			each(file_id in file_ids) {
				file := API.OpenAI.File->Load(file_id->GetString(), token);
				if(file <> Nil) {
					@files->AddBack(file);
				};
			};
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		ID of the model to use
		@return ID of the model to use
		~#
		method : public : GetModel() ~ String {
			return @model;
		}

		#~
		Name of the assistant
		@return name of the assistant
		~#
		method : public : GetName() ~ String {
			return @name;
		}

		#~
		Description of the assistant
		@return description of the assistant
		~#
		method : public : GetDescription() ~ String {
			return @description;
		}

		#~
		System instructions that the assistant uses
		@return system instructions
		~#
		method : public : GetInstructions() ~ String {
			return @instructions;
		}

		#~
		Adds a file to assistant
		@param file file to add to assistant
		@return true if successful, false otherwise
		~#
		method : public : AddFile(file : API.OpenAI.File) ~ Bool {
			file_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			file_json->Insert("file_id", file->GetId());
			data := file_json->ToString()->ToByteArray();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$@token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/assistants/{$@id}/files"), data, "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				file_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(file_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return false;
				};
				
				if(file_json->Has("error")) {
					error_str := file_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				};

				return file->GetId()->Equals(file_json->Get("id")->GetString());
			}

			return false;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {			
			buffer := "[id='";
			buffer += @id;

			buffer += "', object='"
			buffer += @object;

			buffer += "', model='"
			buffer += @model;

			buffer += "', name='"
			buffer += @name;

			buffer += "', description='"
			buffer += @description;

			buffer += "', instructions='"
			buffer += @instructions;

			buffer += "', created_at="
			buffer += @created_at;

			buffer += "\ntools: ["
			for(i := 0; i < @tools->Size(); i +=1 ;) {
				buffer += i;
				buffer += ": ";
				buffer += @tools->Get(i);
				buffer += '\'';
				
				if(i + 1 < @tools->Size()) {
					buffer += ',';
				};
			};

			buffer += "]\nfiles: [";
			for(i := 0; i < @files->Size(); i +=1 ;) {
				buffer += i;
				buffer += ": ";
				buffer += @files->Get(i)->ToString();
								
				if(i + 1 < @files->Size()) {
					buffer += "\n\t";
				};
			};
			buffer += ']';

			return buffer;
		}

		#~
		Returns a list of assistants
		@param token API token
		@return list of assistants
		~#
		function : ListAssistants(token : String) ~ Vector<API.OpenAI.Assistant> {
			assistants := Vector->New()<API.OpenAI.Assistant>

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickGet(Url->New("https://api.openai.com/v1/assistants"), "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				assistants_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(assistants_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};
				
				if(assistants_json->Has("error")) {
					error_str := assistants_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				assistants_json := assistants_json->Get("data");
				each(assistant_json in assistants_json) {
					assistants->AddBack(API.OpenAI.Assistant->New(assistant_json, token));
				};
			};

			return assistants;
		}

		#~
		Create an assistant with a model and instructions
		@param model ID of the model to use
		@param token API token
		@return assistant
		~#
		function : Create(model : String, token : String) ~ API.OpenAI.Assistant {
			return Create(model, Nil, Nil, Nil, Nil, Nil, Nil, token);
		}

		#~
		Create an assistant with a model and instructions
		@param model ID of the model to use
		@param name name to use
		@param description description of the assistant.
		@param instructions the system instructions that the assistant uses
		@param token API token
		@return newly created assistant
		~#
		function : Create(model : String, name : String, description : String, instructions : String, token : String) ~ API.OpenAI.Assistant {
			return Create(model, name, description, instructions, Nil, Nil, Nil, token);
		}

		#~
		Creates an assistant with a model and instructions
		@param model ID of the model to use
		@param name name to use
		@param description description of the assistant.
		@param instructions the system instructions that the assistant uses
		@param tools list of tool enabled on the assistant
		@param files list of file IDs attached to this assistant
		@param token API token
		@return newly created assistant
		~#
		function : Create(model : String, name : String, description : String, instructions : String, 
				tools : Vector<String>, files : Vector<API.OpenAI.File>, token : String) ~ API.OpenAI.Assistant {
			return Create(model, name, description, instructions, tools, files, Nil, token);
		}
		
		#~
		Creates an assistant with a model and instructions
		@param model ID of the model to use
		@param name name to use
		@param description description of the assistant.
		@param instructions the system instructions that the assistant uses
		@param tools list of tool enabled on the assistant
		@param files list of file IDs attached to this assistant
		@param funcs list of callback function definitions
		@param token API token
		@return newly created assistant
		~#
		function : Create(model : String, name : String, description : String, instructions : String, 
				tools : Vector<String>, files : Vector<API.OpenAI.File>, funcs : Vector<FunctionType>, token : String) ~ API.OpenAI.Assistant {

			if(model = Nil) {
				return Nil;
			};

			builder := JsonBuilder->New();
			create_json := builder->PushObject();
			create_json->Insert("model", model);

			if(name <> Nil) {
				create_json->Insert("name", name);
			};

			if(description <> Nil) {
				create_json->Insert("description", description);
			};

			if(instructions <> Nil) {
				create_json->Insert("instructions", instructions);
			};

			# tools
			if((tools <> Nil & <>tools->IsEmpty()) | (funcs <> Nil & <>funcs->IsEmpty())) {
				tools_json := JsonElement->New(JsonElement->JsonType->ARRAY);

				# tools to enable, functions are enabled separately below 
				each(tool in tools) {
					if(<>tool->Equals("function")) {
						tool_json := JsonElement->New(JsonElement->JsonType->OBJECT);
						tool_json->Insert("type", tool);
						tools_json->Add(tool_json);
					};
				};

				# function definitions 
				each(func in funcs) {
					tool_json := JsonElement->New(JsonElement->JsonType->OBJECT);
					tool_json->Insert("type", "function");

					func_json := JsonParser->TextToElement(func->ToString());					
					tool_json->Insert("function", func_json);

					tools_json->Add(tool_json);
				};

				create_json->Insert("tools", tools_json);
			};

			# files
			if(files <> Nil & <>files->IsEmpty()) {
				files_json := JsonElement->New(JsonElement->JsonType->ARRAY);
				each(file in files) {
					files_json->Add(file->GetId());
				};
				create_json->Insert("file_ids", files_json);
			};
			
			data := builder->PopAll()->ToString()->ToByteArray();

			# data->ToString()->PrintLine();			
			# "---"->PrintLine();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/assistants"), data, "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();

				assistant_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(assistant_json = Nil) {
					return Nil;
				};
				
				if(assistant_json->Has("error")) {
					error_str := assistant_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				}

				return API.OpenAI.Assistant->New(assistant_json, token);
			};

			return Nil;
		}

		#~
		Loads an assistant with a model and instructions
		@param id model ID of the model to use
		@param token API token
		@return loaded assistant
		~#
		function : Load(id : String, token : String) ~ API.OpenAI.Assistant {
			assistant : API.OpenAI.Assistant;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickGet(Url->New("https://api.openai.com/v1/assistants/{$id}"), "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				assistant_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(assistant_json = Nil) {
					"### Error: Unable to parse response ###"->ErrorLine();
					return Nil;
				};
				
				if(assistant_json->Has("error")) {
					error_str := assistant_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				assistant := API.OpenAI.Assistant->New(assistant_json, token);
			};

			return assistant;
		}

		#~
		Deletes an assistant with a model and instructions
		@param id model ID of the model to use
		@param token API token
		@return true if successful, false otherwise
		~#
		function : Delete(id : String, token : String) ~ Bool {
			file : API.OpenAI.File;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickDelete(Url->New("https://api.openai.com/v1/assistants/{$id}"), "application/json", headers);
			
			if(response <> Nil) {
				file_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(file_json = Nil) {
					return false;
				};

				if(file_json->Has("error")) {
					error_str := file_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				}

				return file_json->Get("deleted")->GetString()->Equals("true");
			};

			return false;
		}
	}

	#~
	Create threads that assistants can interact with
	~#
	class Thread from EndPoint {
		@id : String;
		@object : String;
		@created_at : Int;

		New : private(thread_json : JsonElement) {
			Parent();

			@id := thread_json->Get("id")->GetString();
			@created_at := thread_json->Get("created_at")->GetInt();
			@object := thread_json->Get("object")->GetString();
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			buffer := "[id='";
			buffer += @id;

			buffer += "', object='"
			buffer += @object;

			buffer += "', created_at="
			buffer += @created_at;

			buffer += "]";

			return buffer;
		}

		#~
		Creates a thread
		@param token API token
		@return newly created thread
		~#
		function : Create(token : String) ~ API.OpenAI.Thread {
			thread : API.OpenAI.Thread;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/threads"), ""->ToByteArray(), "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				thread_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(thread_json = Nil) {
					"### Error: Unable to parse thread response ###"->ErrorLine();
					return Nil;
				};
				
				if(thread_json->Has("error")) {
					error_str := thread_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return API.OpenAI.Thread->New(thread_json);
			};
			
			return Nil;	
		}

		#~
		Loads an existing thread
		@param id ID of the model to use
		@param token API token
		@return loaded thread
		~#
		function : Load(id : String, token : String) ~ API.OpenAI.Thread {
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickGet(Url->New("https://api.openai.com/v1/threads/{$id}"), "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				thread_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(thread_json = Nil) {
					"### Error: Unable to parse thread response ###"->ErrorLine();
					return Nil;
				};
				
				if(thread_json->Has("error")) {
					error_str := thread_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return API.OpenAI.Thread->New(thread_json);

			};

			return Nil;
		}

		#~
		Loads an existing thread
		@param id ID of the model to use
		@param token API token
		@return loaded thread
		~#
		function : Delete(id : String, token : String) ~ Bool {
			thread : API.OpenAI.Thread;

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickDelete(Url->New("https://api.openai.com/v1/threads/{$id}"), "application/json", headers);
			
			if(response <> Nil) {
				thread_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(thread_json = Nil) {
					return false;
				};

				if(thread_json->Has("error")) {
					error_str := thread_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				}

				return thread_json->Get("deleted")->GetString()->Equals("true");
			};

			return false;
		}
	}

	#~
	Message contents
	~#
	class Contents {
		@contents : Vector<Pair<String, String>>;

		New(contents : Vector<Pair<String, String>>) {
			@contents := contents;
		}

		#~
		Get content by index
		@param index index of content
		@return content, user and message
		~#
		method : public : Get(index : Int) ~ Pair<String, String> {
			return @contents->Get(index);
		}

		#~
		Gets the size of contents
		@return size of contents
		~#
		method : public : Size() ~ Int {
			return @contents->Size();
		}
	}

	#~
	Create messages within threads
	~#
	class Message from EndPoint {
		@id : String;
		@object : String;
		@created_at : Int;
		
		@thread_id : String;
		@role : String;
		@contents : Vector<Pair<String, String>>;
		@files : Vector<API.OpenAI.File>;

		New : private(message_json : JsonElement, token : String) {
			Parent();

			@id := message_json->Get("id")->GetString();
			@created_at := message_json->Get("created_at")->GetInt();
			@object := message_json->Get("object")->GetString();
			@thread_id := message_json->Get("thread_id")->GetString();
			@role := message_json->Get("role")->GetString();

			@contents := Vector->New()<Pair<String, String>>;	
			contents_json := message_json->Get("content");
			each(content_json in contents_json) {
				type := content_json->Get("type")->GetString();
				value := content_json->Get("text")->Get("value")->GetString();
				@contents->AddBack(Pair->New(type, value)<String, String>);
			};

			@files := Vector->New()<API.OpenAI.File>;
			file_ids := message_json->Get("file_ids");
			each(file_id in file_ids) {
				file := API.OpenAI.File->Load(file_id->GetString(), token);
				if(file <> Nil) {
					@files->AddBack(file);
				};
			};
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		Get the ID of the thread associated with message
		@return thread ID
		~#
		method : public : GetThreadId() ~ String {
			return @thread_id;
		}

		#~
		Get the role of the entity that is creating the message
		@return role of the entity that is creating the message
		~#
		method : public : GetRole() ~ String {
			return @role;
		}

		#~
		Get the content of the message
		@return list of messages with roles
		~#
		method : public : GetContents() ~ Contents {
			return Contents->New(@contents);
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			buffer := "[id='";
			buffer += @id;

			buffer += "', object='"
			buffer += @object;

			buffer += "', created_at="
			buffer += @created_at;

			buffer += ", role='"
			buffer += @role;

			buffer += "''\ncontents: [";
			for(i := 0; i < @contents->Size(); i +=1 ;) {
				buffer += '{';
				buffer += i;
				buffer += ": type=";

				content := @contents->Get(i);
				buffer += content->GetFirst();
				buffer += ", text=\"";
				buffer += content->GetSecond();
				buffer += "\"}";
												
				if(i + 1 < @contents->Size()) {
					buffer += "\n\t";
				};
			};
			buffer += ']';

			return buffer;
		}

		#~
		Loads a message
		@param role role of the entity that is creating the message
		@param content content of the message.
		@param thread thread associated with message
		@param token API token
		@return loaded Message
		~#
		function : Create(role : String, content : String, thread : API.OpenAI.Thread, token : String) ~ API.OpenAI.Message {
			return Create(role, content , thread, Nil, token);
		}

		#~
		Create a message.
		@param role role of the entity that is creating the message
		@param content content of the message.
		@param thread thread associated with message
		@param files list to attach to the message
		@param token API token
		@return newly created message
		~#
		function : Create(role : String, content : String, thread : API.OpenAI.Thread, files : Vector<API.OpenAI.File>, token : String) ~ API.OpenAI.Message {
			message_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			message_json->Insert("role", role);
			message_json->Insert("content", content);

			# files
			if(files <> Nil & <>files->IsEmpty()) {
				files_json := JsonElement->New(JsonElement->JsonType->ARRAY);
				each(file in files) {
					files_json->Add(file->GetId());
				};
				message_json->Insert("file_ids", files_json);
			};

			data := message_json->ToString()->ToByteArray();
			# data->ToString()->PrintLine();
			
			thread_id := thread->GetId();
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/threads/{$thread_id}/messages"), data, "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();
				message_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(message_json = Nil) {
					"### Error: Unable to parse thread response ###"->ErrorLine();
					return Nil;
				};
				
				if(message_json->Has("error")) {
					error_str := message_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return API.OpenAI.Message->New(message_json, token);
			};
			
			return Nil;	
		}

		#~
		Loads a message
		@param id message ID
		@param thread thread associated with message
		@param token API token
		@return loaded Message
		~#
		function : Load(id : String, thread : API.OpenAI.Thread, token : String) ~ API.OpenAI.Message {
			thread_id := thread->GetId();
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickGet(Url->New("https://api.openai.com/v1/threads/{$thread_id}/messages/{$id}"), "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				if(root_json->Has("error")) {
					error_str := root_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				if(root_json->Has("error")) {
					error_str := root_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return API.OpenAI.Message->New(root_json, token);
			}

			return Nil;
		}

		#~
		Loads a messages associated with thread
		@param thread thread associated with message
		@param token API token
		@return messages associated with thread
		~#
		function : ListMessages(thread : API.OpenAI.Thread, token : String) ~ Vector<API.OpenAI.Message> {
			messages := Vector->New()<API.OpenAI.Message>

			thread_id := thread->GetId();
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickGet(Url->New("https://api.openai.com/v1/threads/{$thread_id}/messages"), "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				if(root_json->Has("error")) {
					error_str := root_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				messages_json := root_json->Get("data");
				each(message_json in messages_json) {
					messages->AddBack(API.OpenAI.Message->New(message_json, token));
				};
			};

			return messages;
		}
	}

	#~
	Represents an execution run on a thread
	~#
	class Run from EndPoint {
		@id : String;
		@object : String;
		@created_at : Int;
		@thread_id : String;
		@assistant_id : String;
		@status : String;

		@func_callback_id : String;
		@func_call_name : String;
		@func_call_params : String;

		New : private(run_json : JsonElement) {
			Parent();
			Set(run_json);
		}

		#~
		Get object instance API ID
		@return instance ID
		~#
		method : public : GetId() ~ String {
			return @id;
		}

		#~
		Get the object type
		@return object type
		~#
		method : public : GetObject() ~ String {
			return @object;
		}

		#~
		Unix timestamp (in seconds) of when the object instance was created
		@return time with the object instance was created
		~#
		method : public : GetCreatedAt() ~ Int {
			return @created_at;
		}

		#~
		The status of the run, which can be either: 'queued', 'in_progress', 
		'requires_action', 'cancelling', 'cancelled', 'failed', 'completed', or 'expired'.
		~#
		method : public : GetStatus() ~ String {
			return @status;
		}

		#~
		Get function callback information
		~#
		method : public : IsFunctionCall() ~ Bool {
			return @func_callback_id <> Nil & @func_call_name <> Nil & @func_call_params <> Nil;
		}

		#~
		Get function callback information
		@return pair function name and calling parameters in JSON format
		~#
		method : public : GetFunctionCall() ~ Collection.Tuple.Triplet<String, String, String> {
			return Collection.Tuple.Triplet->New(@func_call_name, @func_call_params, @func_callback_id)<String, String, String>;
		}
		
		method: Set(run_json : JsonElement) ~ Nil {
			@id := run_json->Get("id")->GetString();
			@created_at := run_json->Get("created_at")->GetInt();
			@object := run_json->Get("object")->GetString();
			@thread_id := run_json->Get("thread_id")->GetString();
			@assistant_id := run_json->Get("assistant_id")->GetString();
			
			@status := run_json->Get("status")->GetString();
			if(@status->Equals("requires_action")) {
				tool_calls_json := run_json->FindElements("required_action/submit_tool_outputs/tool_calls");
				each(tool_call_json in tool_calls_json) {
					@func_callback_id := tool_call_json->Get("id")->GetString();
					@func_call_name := tool_call_json->FindElements("function/name")->GetString();
					@func_call_params := tool_call_json->FindElements("function/arguments")->GetString();
				};
			}
			else {
				@func_call_name := @func_call_params := Nil;
			};
		}

		#~
		Create a run
		@param assistant the assistant to use to execute this run
		@param thread thread to run
		@param token API token
		@return newly created Run
		~#
		function : Create(assistant : API.OpenAI.Assistant, thread : API.OpenAI.Thread, token : String) ~ API.OpenAI.Run {
			run_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			run_json->Insert("assistant_id", assistant->GetId());
			data := run_json->ToString()->ToByteArray();
			
			thread_id := thread->GetId();
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/threads/{$thread_id}/runs"), data, "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				run_json := JsonParser->TextToElement(response->GetContent()->ToString());
				if(run_json = Nil) {
					"### Error: Unable to parse thread response ###"->ErrorLine();
					return Nil;
				};
				
				if(run_json->Has("error")) {
					error_str := run_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return API.OpenAI.Run->New(run_json);
			};
			
			return Nil;	
		}

		#~
		Refreshed the run's data such as status
		@param token API token
		@return newly created Run
		~#
		method : public : Refresh(token : String) ~ Bool {
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickGet(Url->New("https://api.openai.com/v1/threads/{$@thread_id}/runs/{$@id}"), "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				run_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(run_json = Nil) {
					return false;
				};

				if(run_json->Has("error")) {
					error_str := run_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				};

				run_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(run_json = Nil) {
					return false;
				};

				if(run_json->Has("error")) {
					error_str := run_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				};

				Set(run_json);				
				return true;
			}

			return false;
		}

		#~
		Submits a tool's response
		@param func_response_json response in JSON format
		@param func_callback_id function callback ID
		@param token API token
		@return true if successful, false otherwise
		~#
		method : public : SubmitToolOutputs(func_response_json : JsonElement, func_callback_id : String, token : String) ~ Bool {
			tool_callback_output_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			tool_callback_output_json->Insert("tool_call_id", func_callback_id);
			tool_callback_output_json->Insert("output", func_response_json->GetString());

			tool_callback_array_json := JsonElement->New(JsonElement->JsonType->ARRAY);
			tool_callback_array_json->Add(tool_callback_output_json);

			tool_callback_obj_json := JsonElement->New(JsonElement->JsonType->OBJECT);
			tool_callback_obj_json->Insert("tool_outputs", tool_callback_array_json);

			data := tool_callback_obj_json->ToString()->ToByteArray();
			# data->ToString()->PrintLine();

			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickPost(Url->New("https://api.openai.com/v1/threads/{$@thread_id}/runs/{$@id}/submit_tool_outputs"), data, "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();
				run_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(run_json = Nil) {
					return false;
				};

				if(run_json->Has("error")) {
					error_str := run_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				};

				run_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(run_json = Nil) {
					return false;
				};

				if(run_json->Has("error")) {
					error_str := run_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return false;
				};

				return true;
			}

			return false;

		}

		#~
		Loads a run
		@param id run ID
		@param thread instance associated with run
		@param token API token
		@return loaded Run
		~#
		function : Load(id : String, thread : API.OpenAI.Thread, token : String) ~ API.OpenAI.Run {
			thread_id := thread->GetId();
			headers := Map->New()<String, String>;
			headers->Insert("Authorization", "Bearer {$token}");
			headers->Insert("OpenAI-Beta", "assistants=v1");
			response := HttpsClient->QuickGet(Url->New("https://api.openai.com/v1/threads/{$thread_id}/runs/{$id}"), "application/json", headers);
			if(response <> Nil) {
				# response->GetContent()->ToString()->PrintLine();				
				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				if(root_json->Has("error")) {
					error_str := root_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				root_json := JsonParser->TextToElement(response->GetContent()->ToString());

				if(root_json = Nil) {
					return Nil;
				};

				if(root_json->Has("error")) {
					error_str := root_json->FindElements("error/message")->GetString();
					SetLastError(error_str);
					return Nil;
				};

				return API.OpenAI.Run->New(root_json);
			}

			return Nil;
		}

		#~
		String representation of the object
		@return string representation
		~#
		method : public : ToString() ~ String {
			buffer := "[id='";
			buffer += @id;

			buffer += "', object='"
			buffer += @object;

			buffer += "', created_at='"
			buffer += @created_at;

			buffer += "', created_at="
			buffer += @created_at;

			buffer += ", assistant_id='"
			buffer += @assistant_id;

			buffer += "', thread_id='"
			buffer += @thread_id;

			buffer += "', status='"
			buffer += @status;

			buffer += "']";
			return buffer;
		}
	}

	#~
	OpenAI endpoint
	~#
	class EndPoint {
		@last_message : static : String;
		@api_key : static : String;

		function : SetLastError(last_message : String) ~ Nil {
			@last_message := last_message;
		}

		#~
		Set the API file key path
		@param api_key API file key path
		~#
		function : SetApiKey(api_key : String) ~ Nil {
			@api_key := api_key;
		}

		#~
		Get the last error
		@return last error
		~#
		function : GetLastError() ~ String {
			return @last_message;
		}

		#~
		Reads API from 'api_key.dat'
		@return API key
		~#
		function : GetApiKey() ~ String {
			if(@api_key = Nil) {
				filename := "openai_api_key.dat";
				token := System.IO.Filesystem.FileReader->ReadFile(filename);
				if(token = Nil) {
					dir_str := System.IO.Filesystem.Directory->GetWorking();
					dir_str += System.IO.Filesystem.Directory->GetSlash();
					dir_str += filename;
					
					">>> Unable to read API key from: '{$dir_str}', also consider calling SetApiKey(..)"->ErrorLine();
				}
				else {
					@api_key := token->Trim();
				};
			};

			return @api_key;
		}
	}
}
