#~~
# Objeck matrix manipulation and machine learning libraries 
# Copyright (c) 2024 Randy Hollines
# 
# Credits:
# Eigen matrix library - https://eigen.tuxfamily.org
~~#	

use Collection;
use Data.CSV;

#~
Machine learning and data science routines (-lib ml)
~#
bundle System.ML {
	class Proxy {
		@lib_proxy : static : System.API.DllProxy;
		
		function : GetDllProxy() ~ System.API.DllProxy {
			if(@lib_proxy = Nil) {
				@lib_proxy := System.API.DllProxy->New("libobjk_ml");
			};

			return @lib_proxy;
		}
	}

	#~
	2D matrix operations
	~#
	class Matrix2D {
		function : private : SafeDiv(num : Float, dom : Float) ~ Float {
			if(dom = 0.0) {
				return dom;
			};

			return num / dom;
		}

		#~
		Calculates the Euclidean Distance between the two vectors
		@param m1 data matrix
		@return Euclidean Distance between the two vectors
		~#
		function : native : EuclideanDistance(m1 : Float[,]) ~ Float {
			dims := m1->Size();
			rows := dims[0];

			accumulator := 0.0;
			each(i : rows) {
				value := m1[i,0] - m1[i,1];
				if(value > -0.1e-4 & value < -0.1e-4) {
					value := 0.0;
				};
				accumulator += value * value;
			};

			return accumulator->Sqrt();
		}

		#~
		Solves a unit of equations
		@param m1 data matrix
		@param m2 result matrix
		@return least squares
		~#
		function : native : Solve(m1 : Float[,], m2 : Float[,]) ~ Float[] {
			if(m1 <> Nil | m2 <> Nil) {
				array_args := Base->New[3];
				array_args[0] := FloatArrayRef->New();
				array_args[1] := FloatMatrixRef->New(m1);
				array_args[2] := FloatMatrixRef->New(m2);
				Proxy->GetDllProxy()->CallFunction("ml_matrix_solve_matrix_matrix", array_args);
				
				holder := array_args[0]->As(FloatArrayRef);
				return holder->Get();
			};
			
			return Nil;
		}

		#~
		Parsers a decimal value
		@param m matrix
		@return decimal value
		~#
		function : ToFloat(m : Float[,]) ~ Float {
			dim := m->Size();
			if(dim->Size() = 2 & dim[0] = 1 & dim[1] = 1) {
				return m[0,0];
			};

			return 0.0;
		}

		#~
		Parsers a boolean value
		@param m matrix
		@return boolean value
		~#
		function : ToBool(m : Float[,]) ~ Bool {
			return ToInt(m) <> 0;
		}

		#~
		Parsers an integer value
		@param m matrix
		@return integer value
		~#
		function : ToInt(m : Float[,]) ~ Int {
			return Float->Round(ToFloat(m));
		}

		#~
		Creates an identity a matrix
		@param s size of matrix
		@return row from matrix
		~#
		function : native : Identity(s : Int) ~ Float[,] {
			m := Float->New[s,s];

			each(i : s) {
				each(j : s) {
					if(i = j) {
						m[i,j] := 1;
					};
				};
			};

			return m;
		}

		#~
		Get the row from a matrix
		@param r row index
		@param matrix matrix
		@return row from matrix
		~#
		function : native : GetRow(r : Int, matrix : Float[,]) ~ Float[] {
			dims := matrix->Size();
			rows := dims[0];
			cols := dims[1];

			if(r < rows) {
				row := Float->New[cols];

				each(i : cols) {
					row[i] := matrix[r, i];
				};

				return row;
			};
			
			return Nil;
		}

		#~
		Sum of the given row
		@param r row index
		@param matrix matrix
		@return sum of the row
		~#
		function : native : SumRow(r : Int, matrix : Float[,]) ~ Float {
			dims := matrix->Size();
			rows := dims[0];
			cols := dims[1];

			if(r < rows) {
				sum := 0.0;

				each(i : cols) {
					sum += matrix[r, i];
				};

				return sum;
			};
			
			return 0.0;
		}

		#~
		Average of the given row
		@param r row index
		@param matrix matrix
		@return average of the row
		~#
		function : native : AverageRow(r : Int, matrix : Float[,]) ~ Float {
			dims := matrix->Size();
			rows := dims[0];
			cols := dims[1];

			if(r < rows) {
				sum := 0.0;

				each(i : cols) {
					sum += matrix[r, i];
				};

				return SafeDiv(sum, cols->As(Float));
			};
			
			return 0.0;
		}

		function : StdDevRow(row : Int, m : Float[,]) ~ Float {
			m_dim := m->Size();
			m_rows := m_dim[1];

			total_sum := 0.0;
			each(i : m_rows) {
				total_sum += m[0,i];
			};
			m_avg := SafeDiv(total_sum, m_rows->Size()->As(Float));
			
			total_sum := 0.0;
			each(i : m_rows) {
				term := m[0,i] - m_avg;
				total_sum += term * term;
			};

			return Float->Sqrt(SafeDiv(total_sum, (m_rows->As(Float) - 1.)));
		}

		#~
		Get the column from a matrix
		@param c column index
		@param matrix matrix
		@return column from matrix
		~#
		function : native : GetColumn(c : Int, matrix : Float[,]) ~ Float[] {
			dims := matrix->Size();
			rows := dims[0];
			cols := dims[1];

			if(c < cols) {
				col := Float->New[rows];

				each(i : rows) {
					col[i] := matrix[i, c];
				};

				return col;
			};
			
			return Nil;
		}

		#~
		Sum of the given column
		@param c column index
		@param matrix matrix
		@return sum of the column
		~#
		function : native : SumColumn(c : Int, matrix : Float[,]) ~ Float {
			dims := matrix->Size();
			rows := dims[0];
			cols := dims[1];

			if(c < cols) {
				sum := 0;

				each(i : rows) {
					sum += matrix[i, c];
				};

				return sum;
			};
			
			return 0.0;
		}

		#~
		Average of the given column
		@param c column index
		@param matrix matrix
		@return average of the column
		~#
		function : native : AverageColumn(c : Int, matrix : Float[,]) ~ Float {
			dims := matrix->Size();
			rows := dims[0];
			cols := dims[1];

			if(c < cols) {
				sum := 0;
				
				each(i : rows) {
					sum += matrix[i, c];
				};

				return SafeDiv(sum, rows->As(Float));
			};
			
			return 0.0;
		}

		function : StdDevColumn(col : Int, m : Float[,]) ~ Float {
			m_dim := m->Size();
			m_rows := m_dim[0];

			total_sum := 0.0;
			each(i : m_rows) {
				total_sum += m[i,0];
			};
			m_avg := SafeDiv(total_sum, m_rows->Size()->As(Float));

			total_sum := 0.0;
			each(i : m_rows) {
				term := m[i,0] - m_avg;
				total_sum += term * term;
			};

			return Float->Sqrt(SafeDiv(total_sum, (m_rows->As(Float) - 1.)));
		}

		#~
		Adds a constant to a matrix
		@param c constant
		@param m matrix
		@return updated matrix
		~#
		function : native : Add(c : Float, m : Float[,]) ~ Float[,] {
			if(m <> Nil) {
				array_args := Base->New[3];
				array_args[0] := FloatMatrixRef->New();
				array_args[1] := FloatRef->New(c);
				array_args[2] := FloatMatrixRef->New(m);
				Proxy->GetDllProxy()->CallFunction("ml_matrix_add_scalar_matrix", array_args);
				
				holder := array_args[0]->As(FloatMatrixRef);
				return holder->Get();
			};
			
			return Nil;
		}

		#~
		Adds a constant to a matrix
		@param m matrix
		@param c constant
		@return updated matrix
		~#
		function : native : Add(m : Float[,], c : Float) ~ Float[,] {
			if(m <> Nil) {
				array_args := Base->New[3];
				array_args[0] := FloatMatrixRef->New();
				array_args[1] := FloatMatrixRef->New(m);				
				array_args[2] := FloatRef->New(c);				
				Proxy->GetDllProxy()->CallFunction("ml_matrix_add_matrix_scalar", array_args);
				
				holder := array_args[0]->As(FloatMatrixRef);
				return holder->Get();
			};
			
			return Nil;
		}
		
		#~
		Adds two matrices
		@param m1 left matrix
		@param m2 right matrix
		@return updated matrix
		~#
		function : native : Add(m1 : Float[,], m2 : Float[,]) ~ Float[,] {
			if(m1 <> Nil | m2 <> Nil) {
				array_args := Base->New[3];
				array_args[0] := FloatMatrixRef->New();
				array_args[1] := FloatMatrixRef->New(m1);
				array_args[2] := FloatMatrixRef->New(m2);
				Proxy->GetDllProxy()->CallFunction("ml_matrix_add_matrix_matrix", array_args);
				
				holder := array_args[0]->As(FloatMatrixRef);
				return holder->Get();
			};
			
			return Nil;
		}

		#~
		Subtracts a constant from a matrix
		@param c constant
		@param m matrix
		@return updated matrix
		~#
		function : native : Subtract(c : Float, m : Float[,]) ~ Float[,] {
			if(m <> Nil) {
				array_args := Base->New[3];
				array_args[0] := FloatMatrixRef->New();
				array_args[1] := FloatRef->New(c);
				array_args[2] := FloatMatrixRef->New(m);
				Proxy->GetDllProxy()->CallFunction("ml_matrix_sub_scalar_matrix", array_args);
				
				holder := array_args[0]->As(FloatMatrixRef);
				return holder->Get();
			};
			
			return Nil;
		}
		
		#~
		Adds a constant to a matrix
		@param m matrix
		@param c constant
		@return updated matrix
		~#
		function : native : Subtract(m : Float[,], c : Float) ~ Float[,] {
			if(m <> Nil) {
				array_args := Base->New[3];
				array_args[0] := FloatMatrixRef->New();
				array_args[1] := FloatMatrixRef->New(m);				
				array_args[2] := FloatRef->New(c);				
				Proxy->GetDllProxy()->CallFunction("ml_matrix_sub_matrix_scalar", array_args);
				
				holder := array_args[0]->As(FloatMatrixRef);
				return holder->Get();
			};
			
			return Nil;
		}

		#~
		Subtracts two matrices
		@param m1 left matrix
		@param m2 right matrix
		@return updated matrix
		~#
		function : native : Subtract(m1 : Float[,], m2 : Float[,]) ~ Float[,] {
			if(m1 <> Nil | m2 <> Nil) {
				array_args := Base->New[3];
				array_args[0] := FloatMatrixRef->New();
				array_args[1] := FloatMatrixRef->New(m1);
				array_args[2] := FloatMatrixRef->New(m2);
				Proxy->GetDllProxy()->CallFunction("ml_matrix_sub_matrix_matrix", array_args);
				
				holder := array_args[0]->As(FloatMatrixRef);
				return holder->Get();
			};
			
			return Nil;
		}

		#~
		Multiplies a constant by a matrix
		@param c constant
		@param m matrix
		@return updated matrix
		~#
		function : native : Multiple(c : Float, m : Float[,]) ~ Float[,] {
			if(m <> Nil) {
				array_args := Base->New[3];
				array_args[0] := FloatMatrixRef->New();
				array_args[1] := FloatRef->New(c);
				array_args[2] := FloatMatrixRef->New(m);
				Proxy->GetDllProxy()->CallFunction("ml_matrix_mul_scalar_matrix", array_args);
				
				holder := array_args[0]->As(FloatMatrixRef);
				return holder->Get();
			};
			
			return Nil;
		}

		#~
		Multiplies a constant by a matrix
		@param m matrix
		@param c constant
		@return updated matrix
		~#
		function : native : Multiple(m : Float[,], c : Float) ~ Float[,] {
			if(m <> Nil) {
				array_args := Base->New[3];
				array_args[0] := FloatMatrixRef->New();
				array_args[1] := FloatMatrixRef->New(m);				
				array_args[2] := FloatRef->New(c);				
				Proxy->GetDllProxy()->CallFunction("ml_matrix_mul_matrix_scalar", array_args);
				
				holder := array_args[0]->As(FloatMatrixRef);
				return holder->Get();
			};
			
			return Nil;
		}

		#~
		Multiplies two matrices using the Hadamard rule
		@param m1 left matrix
		@param m2 right matrix
		@return updated matrix
		~#
		function : native : HadamardProduct(m1 : Float[,], m2 : Float[,]) ~ Float[,] {
			m1_dims := m1->Size();
			m1_rows := m1_dims[0];
			m1_cols := m1_dims[1];

			m2_dims := m2->Size();
			m2_rows := m2_dims[0];
			m2_cols := m2_dims[1];

			if(m1_rows <> m2_rows | m1_cols <> m2_cols) {
				return Nil;
			};

			c := Float->New[m1_rows, m2_cols];
			for(i := 0; i < m1_rows; i += 1;) {
				for(j := 0; j < m2_cols; j += 1;) {
					c[i,j] := m1[i,j] * m2[i,j];
				};
			};

			return c;
		}

		#~
		Calculates the dot product.
		@param m1 left matrix
		@param m2 right matrix
		@return updated matrix
		~#
		function : native : DotProduct(m1 : Float[,], m2 : Float[,]) ~ Float[,] {
			if(m1 <> Nil | m2 <> Nil) {
				array_args := Base->New[3];
				array_args[0] := FloatMatrixRef->New();
				array_args[1] := FloatMatrixRef->New(m1);
				array_args[2] := FloatMatrixRef->New(m2);
				Proxy->GetDllProxy()->CallFunction("ml_matrix_dot_matrix_matrix", array_args);
				
				holder := array_args[0]->As(FloatMatrixRef);
				return holder->Get();
			};
			
			return Nil;
		}
		
		#~
		Divides a constant by a matrix
		@param c constant
		@param m matrix
		@return updated matrix
		~#
		function : native : Divide(c : Float, m : Float[,]) ~ Float[,] {
			if(m <> Nil) {
				array_args := Base->New[3];
				array_args[0] := FloatMatrixRef->New();
				array_args[1] := FloatRef->New(c);
				array_args[2] := FloatMatrixRef->New(m);
				Proxy->GetDllProxy()->CallFunction("ml_matrix_div_scalar_matrix", array_args);
				
				holder := array_args[0]->As(FloatMatrixRef);
				return holder->Get();
			};
			
			return Nil;
		}

		#~
		Divides a constant by a matrix
		@param m matrix
		@param c constant
		@return updated matrix
		~#
		function : native : Divide(m : Float[,], c : Float) ~ Float[,] {
			if(m <> Nil) {
				array_args := Base->New[3];
				array_args[0] := FloatMatrixRef->New();
				array_args[1] := FloatMatrixRef->New(m);				
				array_args[2] := FloatRef->New(c);				
				Proxy->GetDllProxy()->CallFunction("ml_matrix_div_matrix_scalar", array_args);
				
				holder := array_args[0]->As(FloatMatrixRef);
				return holder->Get();
			};
			
			return Nil;
		}

		#~
		Divides two matrices using the Hadamard rule
		@param m1 left matrix
		@param m2 right matrix
		@return updated matrix
		~#
		function : native : HadamardDivide(m1 : Float[,], m2 : Float[,]) ~ Float[,] {
			m1_dims := m1->Size();
			m1_rows := m1_dims[0];
			m1_cols := m1_dims[1];

			m2_dims := m2->Size();
			m2_rows := m2_dims[0];
			m2_cols := m2_dims[1];

			if(m1_rows <> m2_rows | m1_cols <> m2_cols) {
				return Nil;
			};

			c := Float->New[m1_rows, m2_cols];
			for(i := 0; i < m1_rows; i += 1;) {
				for(j := 0; j < m2_cols; j += 1;) {
					c[i,j] := SafeDiv(m1[i,j], m2[i,j]);
				};
			};

			return c;
		}

		#~
		Transpose of matrix
		@param a matrix
		@return transposed matrix
		~#
		function : native : Transpose(a : Float[,]) ~ Float[,] {
			if(a <> Nil) {
				array_args := Base->New[2];
				array_args[0] := FloatMatrixRef->New();
				array_args[1] := FloatMatrixRef->New(a);
				Proxy->GetDllProxy()->CallFunction("ml_matrix_transpose", array_args);
				
				holder := array_args[0]->As(FloatMatrixRef);
				return holder->Get();
			};
			
			return Nil;
		}

		#~
		Inverse of matrix
		@param a matrix
		@return inverted matrix
		~#
		function : native : Inverse(a : Float[,]) ~ Float[,] {
			if(a <> Nil) {
				array_args := Base->New[2];
				array_args[0] := FloatMatrixRef->New();
				array_args[1] := FloatMatrixRef->New(a);
				Proxy->GetDllProxy()->CallFunction("ml_matrix_inverse", array_args);
				
				holder := array_args[0]->As(FloatMatrixRef);
				return holder->Get();
			};
			
			return Nil;
		}
		
		#~
		Sigmoid 'S' function
		@param x input value
		@return Sigmoid value
		~#
		function : native : Sigmoid(x : Float) ~ Float {
			return 1.0 / (1.0 + Float->Pow(Float->E(), -1.0 * x));
		}

		#~
		Applies the Sigmoid function to all elements
		@param b matrix
		@return updated matrix
		~#
		function : native : Sigmoid(b : Float[,]) ~ Float[,] {
			b_dims := b->Size();
			b_rows := b_dims[0];
			b_cols := b_dims[1];

			c := Float->New[b_rows, b_cols];
			for(i := 0; i < b_rows; i += 1;) {
				for(j := 0; j < b_cols; j += 1;) {
					c[i,j] := Sigmoid(b[i,j]);
				};
			};

			return c;
		}
		
		#~
		Calculates the Dot Product applying while applying the Sigmoid function to all elements
		@param a matrix
		@param b matrix
		@return updated matrix
		~#
		function : native : DotSigmoid(a : Float[,], b : Float[,]) ~ Float[,] {
			a_dims := a->Size();
			a_rows := a_dims[0];
			a_cols := a_dims[1];

			b_dims := b->Size();
			b_rows := b_dims[0];
			b_cols := b_dims[1];
			
			if(a_cols <> b_rows & a_rows <> b_cols) {
				return Nil;
			};

			c := Float->New[a_rows, b_cols];
			for(a_col := 0; a_col < a_rows; a_col += 1;) {
				for(right_col := 0; right_col < b_cols; right_col += 1;) {
					cx := 0.0;
					for(x_col := 0; x_col < b_rows; x_col += 1;) {
						cx += a[a_col, x_col] * b[x_col, right_col];
					};
					c[a_col, right_col] := Sigmoid(cx);
				};
			};

			return c;
		}

		#~
		Generates a random 2D array of values from 0.0 to 1.0
		@param rows rows
		@param cols columns
		@return updated matrix
		~#
		function : Random(rows : Int, cols : Int) ~ Float[,] {
			m := Float->New[rows, cols];

			for(i := 0; i < rows; i += 1;) {
				for(j := 0; j < cols; j += 1;) {
					m[i,j] := Float->Random();
				};
			};
			
			return m;
		}
		
		#~
		Generates a random normal distribution of values
		@param mean center of values
		@param variance variance in values
		@param rows rows
		@param cols columns
		@return updated matrix
		~#
		function : RandomNormal(mean : Float, variance : Float, rows : Int, cols : Int) ~ Float[,] {
			m := Float->New[rows, cols];

			for(i := 0; i < rows; i += 1;) {
				for(j := 0; j < cols; j += 1;) {
					m[i,j] := RandomNormal(mean, variance);
				};
			};

			return m;
		}

		#~
		Generates a random normal value
		@param mean center of values
		@param variance variance in values
		@return updated matrix
		~#
		function : RandomNormal(mean : Float, variance : Float) ~ Float {
			return  (-2.0 * variance * Float->Random()->Log())->Sqrt() * (2.0 * Float->Pi() * Float->Random())->Cos() + mean;
		}

		#~
		Splits a matrix
		@param b matrix
		@param offset offset index
		@param count number of rows to split
		@param is_row true for row split, false for column
		@return copied matrix
		~#
		function : native : Split(b : Float[,], offset : Int, count : Int, is_row : Bool) ~ Float[,] {
			b_dims := b->Size();
			b_rows := b_dims[0];
			b_cols := b_dims[1];
			
			c : Float[,];
			if(is_row) {
				if(count + offset <= 0 | count + offset > b_rows) {
					return Nil;
				};

				c := Float->New[count, b_cols];
				count := count + offset;
				for(row := offset; row < count; row += 1;) {
					for(col := 0; col < b_cols; col += 1;) {
						c[row - offset, col] := b[row, col];
					};
				};
			}
			else {
				if(count + offset <= 0 | count + offset > b_cols) {
					return Nil;
				};

				c := Float->New[b_rows, count];
				count := count + offset;
				for(row := 0; row < b_rows; row += 1;) {
					for(col := offset; col < count; col += 1;) {
						c[row, col - offset] := b[row, col];
					};
				};
			};

			return c;
		}
		
		#~
		Concatenates two matrix
		@param a left matrix
		@param b right matrix
		@param is_row true concatenate by rows, false for columns
		@return concatenated matrix
		~#
		function : Concatenate(a : Float[,], b : Float[,], is_row : Bool) ~ Float[,] {
			a_dims := a->Size();
			a_rows := a_dims[0];
			a_cols := a_dims[1];

			b_dims := b->Size();
			b_rows := b_dims[0];
			b_cols := b_dims[1];

			c : Float[,];
			if(is_row) {
				if(a_cols <> b_cols) {
					return Nil;
				};

				c_rows := a_rows + b_rows;
				c := Float->New[c_rows, a_cols];

				for(row := 0; row < a_rows; row += 1;) {
					for(col := 0; col < a_cols; col += 1;) {
						c[row, col] := a[row, col];
					};
				};

				for(row := 0; row < b_rows; row += 1;) {
					for(col := 0; col < b_cols; col += 1;) {
						c[row + a_rows, col] := b[row, col];
					};
				};
			}
			else {
				if(a_rows <> b_rows) {
					return Nil;
				};

				c_cols := a_cols + b_cols;
				c := Float->New[a_rows, c_cols];

				for(row := 0; row < a_rows; row += 1;) {
					for(col := 0; col < a_cols; col += 1;) {
						c[row, col] := a[row, col];
					};
				};

				for(row := 0; row < b_rows; row += 1;) {
					for(col := 0; col < b_cols; col += 1;) {
						c[row, col + a_cols] := b[row, col];
					};
				};
			};

			return c;
		}
	}

	#~
	Solves a system of linear equations
```
m1 := [
  [1., 1., 2., 3.]
  [1., 4., 5., 6.]
  [1., 7., 8., 9.]];

m2 := [
  [6.]
  [16.]
  [23.]];

solver := System.ML.LinearSolver->New(m1, m2)->Calculate(1);
solver->GetRSquared()->PrintLine();
```
	~#
	class LinearSolver {
		@m1 : Float[,];
		@m2 : Float[,];

		#~
		Constructor
		@param m1 first matrix
		@param m2 second matrix
		~#
		New(m1 : Float[,], m2 : Float[,]) {
			@m1 := m1;
			@m2 := m2;
		}

		#~
		Calculates the equation coefficients
		@param offset offset column for r-squared
		@return equation coefficients and r-squared
		~#
		method : public : Calculate(offset : Int) ~ LinearResult {
			coeff := System.ML.Matrix2D->Solve(@m1, @m2);
			r_sqrd := GetRSquared(coeff, offset);
			return LinearResult->New(coeff, r_sqrd);
		}

		method : GetRSquared(c : Float[], offset : Int) ~ Float {
			avg := System.ML.Matrix2D->AverageColumn(0, @m2);

			m1_dims := @m2->Size();
			m2_rows := m1_dims[0];

			dom := 0.;
			each(i : m2_rows) {
				term := @m2[i,0] - avg;
				dom += term * term;
			};

			m1_dims := @m1->Size();
			m1_cols := m1_dims[1];

			num := 0.;
			each(i : m2_rows) {
				sub_total := 0.;

				for(j := offset; j < m1_cols; j += 1;) {
					sub_total += c[j] * @m1[i,j];
				};

				term := avg - sub_total;
				num += term * term;
			};
# "{$num} / {$dom}"->PrintLine();				
			
			return num/dom;
		}
	}

	#~
	Result of liner equations
	~#
	class LinearResult {
		@coeffs : Float[];
		@r_sqrd : Float;

		#~
		Constructor
		@param coeffs coefficient matrix
		@param r_sqrd r-squared value
		~#
		New(coeffs : Float[], r_sqrd : Float) {
			@coeffs := coeffs;
			@r_sqrd := r_sqrd;
		}

		#~
		Gets the equation coefficients 
		@return equation coefficients
		~#
		method : public : GetCoefficients() ~ Float[] {
			return @coeffs;
		}

		#~
		Gets r-squared
		@return r-squared
		~#
		method : public : GetRSquared() ~ Float {
			return @r_sqrd;
		}

		#~
		Formats the result into a string
		@return string representation 
		~#
		method : public : ToString() ~ String {
			buffer := "";

			count := 0;
			coeff_num := @coeffs->Size();
			buffer += "r_sqrt={$@r_sqrd}, # of coeffs={$coeff_num}\n";
			each(coeff := @coeffs) {
				if(count = 0) {
					buffer += "  slope={$coeff}\n";
				}
				else {
					buffer += "  x{$count}={$coeff}\n";
				};
				count += 1;
			};

			return buffer;
		}
	}

	#~
	Boolean matrix reference
	~#
	class BoolMatrixRef {
		@value : Bool[,];

		#~
		Default constructor
		~#
		New() {
			Parent();
		}

		#~
		Copy constructor
		@param value boolean value
		~#
		New(value : Bool[,]) {
			Parent();
			@value := value;
		}

		#~
		Returns the number of rows in the matrix
		@return number of rows in the matrix
		~#
		method : public : Rows() ~ Int {
			return @value->Rows();
		}

		#~
		Returns the number of columns in the matrix
		@return number of columns in the matrix
		~#
		method : public : Columns() ~ Int {
			return @value->Columns();
		}

		#~
		Get boolean value
		@return boolean value
		~#
		method : public : Get() ~ Bool[,] {
			return @value;
		}

		#~
		Formats the matrix into a string
		@return string representation
		~#
		method : public : ToString() ~ String {
			return @value->ToString();
		}
		
		#~
		Builds random bootstrapped dataset
		@return bootstrapped dataset
		~#
		method : native : public : Bootstrap() ~ BoolMatrixRef {		
			dims := @value->Size();
			rows := dims[0];
			cols := dims[1];
			
			random_rows := Int->New[rows];
			each(i : rows) {
				random_rows[i] := (rows - 1)->Random();
			};
			
			bag_matrix := Bool->New[rows, cols];
			each(i : rows) {
				random_row := random_rows[i];
				each(j : cols) {
					bag_matrix[i, j] := @value[random_row, j];
				};
			};

			return BoolMatrixRef->New(bag_matrix);
		}

		#~
		Splits a 2D boolean matrix
		@param training_offset index of first column with target data. The first element is the train dateset, while the second is the test data
		@return split matrix of training and data sets
		~#
		method : public : Split(training_offset : Float) ~ BoolMatrixRef[] {
			dims := @value->Size();
			rows := dims[0];
			cols := dims[1];

			training_rows := (rows->As(Float) * training_offset)->As(Int);
			training_matrix := Bool->New[training_rows, cols];
			dims := training_matrix->Size();
			train_rows := dims[0];

			each(i : train_rows) {
				each(j : cols) {
					training_matrix[i, j] := @value[i, j];
				};
			};

			data_rows := rows - training_rows;
			data_matrix := Bool->New[data_rows, cols];
			dims := data_matrix->Size();
			data_rows := dims[0];

			each(i : data_rows) {
				each(j : cols) {
					data_matrix[i, j] := @value[training_rows, j];
				};
				training_rows += 1;
			};

			outputs := BoolMatrixRef->New[2];
			outputs[0] := BoolMatrixRef->New(training_matrix);
			outputs[1] := BoolMatrixRef->New(data_matrix);

			return outputs;
		}
	}

	#~
	Float matrix reference with convenience methods
	~#
	class FloatMatrixRef {
		@value : Float[,];

		#~
		Default constructor
		~#
		New() {
			Parent();
		}

		#~
		Copy constructor
		@param value boolean value
		~#
		New(value : Float[,]) {
			Parent();
			@value := value;
		}

		#~
		Get float value
		@return float value
		~#
		method : public : Get() ~ Float[,] {
			return @value;
		}

		#~
		Set boolean value
		@param value boolean value		
		~#
		method : public : Set(value : Float[,]) ~ Nil {
			@value := value;
		}

		#~
		Formats the matrix into a string
		@return string representation
		~#
		method : public : ToString() ~ String {
			return @value->ToString();
		}

		#~
		Parsers a boolean value
		@return boolean value
		~#
		method : public : ToBool() ~ Bool {
			return ToInt() <> 0;
		}

		#~
		Parsers an integer value
		@return integer value
		~#
		method : public : ToInt() ~ Int {
			return Float->Round(ToFloat());
		}

		#~
		Parsers a decimal value
		@return decimal value
		~#
		method : public : ToFloat() ~ Float {
			dim := @value->Size();
			if(dim->Size() = 2 & dim[0] = 1 & dim[1] = 1) {
				return @value[0,0];
			};

			return 0.0;
		}
	}

	#~
	Simple neural network. Input values should be scaled to between 0.0 to 1.0. 
	The tuned network should return outputs between 0.0 to 1.0.

	```
network : NeuralNetwork;
filename := "data/model.dat";
inputs_targets := MatrixReader->LoadSplitMatrices(args[0], 1, 0.8); # 20% test data

# load model
if(args->Size() = 2) {
   network := NeuralNetwork->Load(filename);
   "Loaded model..."->PrintLine();

   "Testing model..."->PrintLine();
   tests := inputs_targets[2];
   answers := inputs_targets[3];

   failures := 0;
   each(i : answers) {
      answer := answers->Get(i)->ToBool();
      predict := network->Query(FloatMatrixRef->New(tests->Get(i)->Get()));
      if(predict <> answer) {
         failures += 1;
      };
   };

   correct := 100.0 * (1.0 - failures->As(Float) / tests->Size()->As(Float));
   System.IO.Console->Print("Tests: ")->Print(tests->Size())->Print(", correct: ")->SetFloatPrecision(5)->Print(correct)->PrintLine("%");
}
# train and store model
else if(args->Size() = 1) {
   "Training model..."->PrintLine();
   network := NeuralNetwork->Train(2, inputs_targets[0], 8, 1, inputs_targets[1], 0.01725, 256);
   if(inputs_targets <> Nil) {
      network->Store(filename);
      "Stored model..."->PrintLine();
   };
}
	```
	~#
	class NeuralNetwork {
		@input_nodes : Float;
		@hidden_nodes : Float;
		@output_nodes : Float;
		@learning_rate : Float;
		@weight_inputs_hidden : Float[,];
		@weight_outputs_hidden : Float[,];
		@threshold : Float;
		@attempts : Int;

		#~
		Trains the network
		@param input_nodes number of input nodes
		@param inputs : training inputs
		@param hidden_factor size of hidden layer, factor of input (i.e. input_nodes * hidden_factor)
		@param output_nodes training outputs
		@param targets training targets
		@param learning_rate learning rate
		@param iterations number of training iterations
		~#
		function : Train(input_nodes : Int, inputs : Vector<FloatMatrixRef>, hidden_factor : Int, output_nodes : Int, targets : Vector<FloatMatrixRef>, learning_rate : Float, iterations : Int) ~ NeuralNetwork {
			network := NeuralNetwork->New(input_nodes, hidden_factor * input_nodes, output_nodes, learning_rate);
			network->Train(inputs, targets, learning_rate, iterations);
			return network;		
		}
		
		New : private (input_nodes : Float, hidden_nodes : Float, output_nodes : Float, learning_rate : Float) {
			@input_nodes := input_nodes;
			@hidden_nodes := hidden_nodes;
			@output_nodes := output_nodes;
			@learning_rate := learning_rate;
			
			@threshold := 0.80;
			@attempts := 10;

			@weight_inputs_hidden := Matrix2D->RandomNormal(0.0, Float->Pow(@input_nodes, -1.0), @hidden_nodes, @input_nodes);
			@weight_outputs_hidden := Matrix2D->RandomNormal(0.0, Float->Pow(@input_nodes, -1.0), @output_nodes, @hidden_nodes);
		}

		New : private (weight_inputs_hidden : Float[,], weight_outputs_hidden : Float[,]) {
			@weight_inputs_hidden := weight_inputs_hidden;
			@weight_outputs_hidden := weight_outputs_hidden;

			@threshold := 0.80;
			@attempts := 10;
		}

		#~
		Sets the activation threshold. Activation if output > threshold or < 1.0 - threshold
		@param threshold activation threshold default is 0.85
		@param attempts number of activation attempts
		~#
		method : public : SetActivation(threshold : Float, attempts : Int) ~ Nil {
			@threshold := threshold;
			@attempts := attempts;
		}

		#~
		Query the network
		@param inputs query inputs
		@return true if activated, false otherwise
		~#
		method : public : Query(inputs : FloatMatrixRef) ~ Bool {
			# try and fail is unsuccessful
			each(i : @attempts) {
				result := Confidence(inputs);
				if(result > @threshold) {
					return true;
				};		
			};

			return false;
		}

		#~
		Query the network's confidence for the give inputs
		@param inputs query inputs
		@return confidence percentage
		~#
		method : public : Confidence(inputs : FloatMatrixRef) ~ Float {
			outputs := Query(inputs->Get());
			if(outputs <> Nil) {
				dims := outputs->Size();
				if(dims->Size() = 2 & dims[0] = 1 & dims[1] = 1) {
					return outputs[0,0];
				};
			};

			return 0.0
		}

		#~
		Loads network inputs and outputs
		@param filename file to store to
		@return true if successful, false otherwise
		~#
		function : Load(filename : String) ~ NeuralNetwork {
			data := System.IO.Filesystem.FileReader->ReadBinaryFile(filename);
			if(data <> Nil) {
				# read inputs weight
				deserializer := System.IO.Deserializer->New(data);
				height := deserializer->ReadInt();
				width := deserializer->ReadInt();

				weight_inputs_hidden := Float->New[height, width];
				each(i : height) {
					each(j : width) {
						weight_inputs_hidden[i,j] := deserializer->ReadFloat();
					};
				};
				height := deserializer->ReadInt();
				width := deserializer->ReadInt();

				weight_outputs_hidden := Float->New[height, width];
				each(i : height) {
					each(j : width) {
						weight_outputs_hidden[i,j] := deserializer->ReadFloat();
					};
				};

				return NeuralNetwork->New(weight_inputs_hidden, weight_outputs_hidden);
			}

			return Nil;
		}

		#~
		Saves final network inputs and outputs
		@param filename file to store to
		@return true if successful, false otherwise
		~#
		method : public : Store(filename : String) ~ Bool {
			input_dims := @weight_inputs_hidden->Size();
			if((input_dims->Size() = 2 & input_dims[0] > 0 & input_dims[1] > 0) = false) {
				return false;
			}

			# write inputs weight
			height := input_dims[0];
			width := input_dims[1];

			serializer := System.IO.Serializer->New();

			serializer->Write(height);
			serializer->Write(width);

			each(i : height) {
				each(j : width) {
					serializer->Write(@weight_inputs_hidden[i,j])
				};
			};
			# write outputs weight
			output_dims := @weight_outputs_hidden->Size();
			if((output_dims->Size() = 2 & output_dims[0] > 0 & output_dims[1] > 0) = false) {
				return false;
			}

			# write outputs weight
			height := output_dims[0];
			width := output_dims[1];

			serializer->Write(height);
			serializer->Write(width);

			each(i : height) {
				each(j : width) {
					serializer->Write(@weight_outputs_hidden[i,j])
				};
			};
			
			return System.IO.Filesystem.FileWriter->WriteFile(filename, serializer->Serialize());
		}

		method : Query(inputs : Float[,]) ~ Float[,] {
			# calculate signals into hidden layer
			hidden_outputs := Matrix2D->DotSigmoid(@weight_inputs_hidden, inputs);
			# calculate the signals emerging from final output layer
			return Matrix2D->DotSigmoid(@weight_outputs_hidden, hidden_outputs);
		}

		method : Train(inputs : Vector<FloatMatrixRef>, targets : Vector<FloatMatrixRef>, rate : Float, iterations : Int) ~ Nil {
			if(inputs->Size() = targets->Size()) {
				each(i : iterations) {
					each(j : inputs) {
						stream_in := inputs->Get(j)->Get();
						target := targets->Get(j)->Get();

						# calculate signals into hidden layer
						hidden_outputs := Matrix2D->DotSigmoid(@weight_inputs_hidden, stream_in);
						# calculate signals into final output layer
						final_outputs  := Matrix2D->DotSigmoid(@weight_outputs_hidden, hidden_outputs);
						# output layer error is the (target - actual)
						output_errors := Matrix2D->Subtract(target, final_outputs);
						# hidden layer error is the output_errors, split by weights, recombined at hidden nodes
						hidden_errors := Matrix2D->DotProduct(Matrix2D->Transpose(@weight_outputs_hidden), output_errors);
						# update the weights for the links between the stream_in and hidden layers
						@weight_inputs_hidden := Matrix2D->Add(@weight_inputs_hidden, Adjust(rate, hidden_errors, hidden_outputs, stream_in));
						# update the weights for the links between the hidden and output layers
						@weight_outputs_hidden := Matrix2D->Add(@weight_outputs_hidden, Adjust(rate, output_errors, final_outputs, hidden_outputs));
					};
				};
			};
		}

		method : Adjust(rate : Float, errors : Float[,], outputs : Float[,], inputs : Float[,]) ~ Float[,] {
			return Matrix2D->Multiple(rate, Matrix2D->DotProduct(Matrix2D->HadamardProduct(errors, Matrix2D->HadamardProduct(outputs, Matrix2D->Subtract(1.0, outputs))), Matrix2D->Transpose(inputs)));
		}
	}

	#~
	Utilities for reading data from CSV data sources 
	~#
	class MatrixReader {
		#~
		Load input and output data into matrices
		@param filename file to process
		@param target_offset index of first column with target data
		@return input and output matrix data
		~#
		function : public : LoadMatrices(filename : String, target_offset : Int) ~ Vector[]<FloatMatrixRef> {
			table := CsvTable->New(System.IO.Filesystem.FileReader->ReadFile(filename));
			if(table->IsParsed()) {
				inputs := Vector->New()<FloatMatrixRef>;
				targets := Vector->New()<FloatMatrixRef>;

				each(row := table) {
					input_length := row->Size() - target_offset;
					target_length := row->Size() - input_length;
					if(input_length < 0) {
						return Nil;
					};

					input_array := Float->New[input_length, 1];
					target_array := Float->New[target_length, 1];

					each(i : input_length) {
						input_array[i, 0] := row->Get(i)->ToFloat();
					};

					target_index := 0;
					for(i := input_length; i < row->Size(); i += 1;) {
						target_array[target_index, 0] := row->Get(i)->ToFloat();
					};

					inputs->AddBack(FloatMatrixRef->New(input_array));
					targets->AddBack(FloatMatrixRef->New(target_array));
				};

				input_targets := Vector->New[2]<FloatMatrixRef>;
				input_targets[0] := inputs;
				input_targets[1] := targets;

				return input_targets;
			};

			return Nil;
		}

		#~
		Load input and output data into split matrices for training and testing
		@param filename file to process
		@param target_offset index of first column with output data
		@param training_perc percentage of data used for training
		@param line_ending CSV line ending (i.e. Unix, Windows, etc.), default CRLF per the spec 
		@return split matrices for training and testing, first two matrices are training, latter two test data
		~#
		function : public : LoadSplitMatrices(filename : String, target_offset : Int, training_perc : Float, line_ending : String := "\r\n") ~ Vector[]<FloatMatrixRef> {
			table := CsvTable->New(System.IO.Filesystem.FileReader->ReadFile(filename), line_ending);
			if(table->IsParsed()) {
				train_count := (table->Size()->As(Float) * training_perc)->As(Int);
				if(train_count < 1) {
					return Nil;
				};

				training_inputs := Vector->New()<FloatMatrixRef>;
				training_targets := Vector->New()<FloatMatrixRef>;

				test_inputs := Vector->New()<FloatMatrixRef>;
				test_targets := Vector->New()<FloatMatrixRef>;

				count := 0;
				each(row := table) {
					input_length := row->Size() - target_offset;
					target_length := row->Size() - input_length;
					if(input_length < 0) {
						return Nil;
					};

					input_array := Float->New[input_length, 1];
					target_array := Float->New[target_length, 1];

					each(i : input_length) {
						input_array[i, 0] := row->Get(i)->ToFloat();
					};

					target_count := 0;
					for(i := input_length; i < row->Size(); i += 1;) {
						target_array[target_count, 0] := row->Get(i)->ToFloat();
					};

					if(count < train_count) {
						training_inputs->AddBack(FloatMatrixRef->New(input_array));
						training_targets->AddBack(FloatMatrixRef->New(target_array));
					}
					else {
						test_inputs->AddBack(FloatMatrixRef->New(input_array));
						test_targets->AddBack(FloatMatrixRef->New(target_array));
					};

					count += 1;
				};

				input_training_targets := Vector->New[4]<FloatMatrixRef>;
				input_training_targets[0] := training_inputs;
				input_training_targets[1] := training_targets;
				input_training_targets[2] := test_inputs;
				input_training_targets[3] := test_targets;

				return input_training_targets;
			};

			return Nil;
		}
	}

	#~
	Random forest algorithm
```
forest := RandomForest->New(8);
forest->Train(0.3, data);
result := forest->Query(data);

possible := Bool->Rows(result)->As(Float);
matched := DecisionTree->Matches(result->Columns() - 1, result)->As(Float);
matched_perc := (matched / possible * 100.0)->As(Int);
"matched {$matched_perc}%"->PrintLine();
```
	~#
	class RandomForest {
		@decisions : Vector<Split>;
		@num_trees : Int;

		#~
		Constructor
		@param num_trees number of trees to generate
		~#
		New(num_trees : Int) {
			@num_trees := num_trees;
		}

		New : private (num_trees : Int, decisions : Vector<Split>) {
			@decisions := decisions;
			@num_trees := num_trees;
		}

		#~
		Calculates a list of decision splits
		@param split_perc percentage of data to use for training
		@param input training matrix
		~#
		method : public : native : Train(split_perc : Float, input : BoolMatrixRef) ~ Nil {
			Train(split_perc, input->Get());
		}

		#~
		Calculates a list of decision splits
		@param split_perc percentage of data to use for training
		@param input training matrix
		~#
		method : public : native : Train(split_perc : Float, input : Bool[,]) ~ Nil {
			data := BoolMatrixRef->New(input);
			best_match := 0.0;

			each(i : @num_trees) {				
				split_data := data->Split(split_perc);
				training_data := split_data[0];
				test_data := split_data[1];

				decisions := DecisionTree->Train(training_data->Get());
				result := DecisionTree->Query(decisions, test_data->Get());

				possible := result->Rows()->As(Float);
				acheived := DecisionTree->Matches(2, result)->As(Float);

				outcome := acheived / possible;
				if(outcome > best_match) {
					best_match := outcome;
					@decisions := decisions; 
				};
				data := data->Bootstrap();
			};
		}

		#~
		Splits a matrix based on a list of decisions
		@param input matrix to be split
		@return split matrix
		~#
		method : public : native : Query(input : BoolMatrixRef) ~ Bool[,] {
			return Query(input->Get());
		}

		#~
		Splits a matrix based on a list of decisions
		@param input matrix to be split
		@return split matrix
		~#
		method : public : native : Query(input : Bool[,]) ~ Bool[,] {
			if(@decisions <> Nil) {
				return DecisionTree->Query(@decisions, input);
			};

			return Nil;
		}

		#~
		Loads a saved random forest
		@param filename file to store to
		@return random forest
		~#
		function : Load(filename : String) ~ RandomForest {
			data := System.IO.Filesystem.FileReader->ReadBinaryFile(filename);
			if(data <> Nil) {
				deserializer := System.IO.Deserializer->New(data);
				
				num_trees := deserializer->ReadInt();
				
				decisions := Vector->New()<Split>;
				num_decisions := deserializer->ReadInt();
				each(i : num_decisions) {
					decisions->AddBack(deserializer->ReadObject()->As(Split));
				};

				return RandomForest->New(num_trees, decisions);
			}

			return Nil;
		}

		#~
		Saves a random forest
		@param filename file to save to
		@return true if successful, false otherwise
		~#
		method : public : Store(filename : String) ~ Bool {
			if(@decisions <> Nil) {
				serializer := System.IO.Serializer->New();

				serializer->Write(@num_trees);
				
				serializer->Write(@decisions->Size());
				each(decision : @decisions) {
					serializer->Write(decision);
				};

				return System.IO.Filesystem.FileWriter->WriteFile(filename, serializer->Serialize());
			};

			return false;
		}
	}

	#~
	Binary decision tree algorithm
	
```
data := BoolMatrixRef->New([
  [true, false, true]
  [true, false, true]
  [true, true, true]
  [true, true, true]
  [true, true, true]
  [true, true, true]
  [true, true, true]
  [true, true, true]
  [false, true, true]
  [false, true, true]
  [true, true, false]
  [true, true, false]
  [false, true, false]
  [false, true, false]
  [false, true, false]
  [false, true, false]
  [false, false, false]
  [false, false, false]
  [false, false, false]
  [false, false, false]
]);
split_data := data->Split(0.3);
training_data := split_data[0];
test_data := split_data[1];

decisions := DecisionTree->Split(training_data->Get());
result := DecisionTree->Decide(decisions, test_data->Get());

possible := result->Rows()->As(Float);
acheived := DecisionTree->Matches(2, result)->As(Float);
(acheived / possible)->PrintLine();
```
	~#
	class DecisionTree {
		#~
		Splits a matrix based on a list of decisions
		@param decisions list of decisions
		@param input matrix to be split
		@return split matrix
		~#
		function : native : Query(decisions : Vector<Split>, input : Bool[,]) ~ Bool[,] {
			each(decision := decisions) {
				out := Split(decision->GetIndex(), input);
				if(out = Nil) {
					return input;
				};
				input := out;
			}

			return input;
		}

		#~
		Calculates a list of decision splits
		@param input training matrix
		@return list of decision tree splits
		~#
		function : native : Train(input : Bool[,]) ~ Vector<Split> {					
			decisions := Vector->New()<Split>;
			dims := input->Size();
			
			cols := dims[1] - 1;
			if(cols > 0) {
				done := false;
				while(<>done) {
					best_wgi := 1000000.0;
					best_index := -1;

					each(i : cols) {
						wgi := WeightedGini(i, cols, input);
						if(wgi <> 0.0 & wgi < best_wgi) {
							best_wgi := wgi;
							best_index := i;
						}
					}

					if(best_index > - 1) {
						input := Split(best_index, input);
						decisions->AddBack(Split->New(best_index, best_wgi));

					}
					else {
						done := true;
					};
				};
			};

			return decisions;
		}

		#~
		Splits a matrix along the given column
		@param index index used to split
		@param input matrix to split
		@return split matrix
		~#
		function : native : Split(index : Int, input : Bool[,]) ~ Bool[,] {
			split_len := Matches(index, input);
			if(split_len > 0) {
				dims := input->Size();
				rows := dims[0];
				cols := dims[1];

				out := Bool->New[split_len, cols];
				count := 0;
				if(index > -1 & index < rows) {
					each(row : rows) {
						if(input[row, index]) {
							each(k : cols) {
								out[count, k] := input[row, k];
							};
							count += 1;
						};
					};
				};

				return out;
			};

			return Nil;
		}

		#~
		Calculates the Gini index
		@param acheived number acheived
		@param goal achievement target
		@return Gini index
		~#
		function : native : Gini(acheived : Float, goal : Float) ~ Float {
			reached := acheived / goal;
			not_reached := (goal - acheived) / goal;
			return 1 - (reached*reached + not_reached*not_reached);
		}

		function : native : WeightedGini(test : Int, target : Int, input : Bool[,]) ~ Float {
			wgi := 0.0;

			dims := input->Size();
			size := dims[0]->As(Float);

			# left
			goal := Matches(test, input);
			if(goal > 0.0) {
				wgi += goal / size * Gini(Acheived(test, target, input), goal);
			}
			else {
				return 0.0;
			};

			
			# right
			goal := Mismatches(test, input);
			if(goal > 0.0) {
				wgi += goal / size * Gini(Unacheived(test, target, input), goal);
			}
			else {
				return 0.0;
			};

			return wgi;
		}

		#~
		Count matches in a column
		@param index column index
		@param matrix matrix matrix to inspect
		@return number of matches
		~#
		function : Matches(index : Int, matrix : Bool[,]) ~ Int {
			dims := matrix->Size();
			rows := dims[0];

			count := 0;
			if(index > -1 & index < rows) {
				each(row : rows) {
					if(matrix[row, index]) {
						count += 1;
					};
				};
			};

			return count;
		}

		#~
		Count mismatches in a column
		@param index column index
		@param matrix matrix matrix to inspect
		@return number of mismatches
		~#
		function : Mismatches(index : Int, matrix : Bool[,]) ~ Int {
			dims := matrix->Size();
			rows := dims[0];

			count := 0;
			if(index > -1 & index < rows) {
				each(row : rows) {
					if(matrix[row, index] = false) {
						count += 1;
					};
				};
			};

			return count;
		}

		function : native : Acheived(test_index : Int, goal_index : Int, matrix : Bool[,]) ~ Float {
			dims := matrix->Size();
			rows := dims[0];

			count := 0;
			if(test_index > -1 & test_index < rows & goal_index > -1 & goal_index < rows) {
				each(row : rows) {
					if(matrix[row, test_index] & matrix[row, goal_index]) {
						count += 1;
					};
				};
			};

			return count;
		}

		function : native : Unacheived(test_index : Int, goal_index : Int, matrix : Bool[,]) ~ Float {
			dims := matrix->Size();
			rows := dims[0];

			count := 0;
			if(test_index > -1 & test_index < rows & goal_index > -1 & goal_index < rows) {
				each(row : rows) {
					if(matrix[row, test_index] = false & matrix[row, goal_index]) {
						count += 1;
					};
				};
			};

			return count;
		}

		#~
		Loads a boolean input matrix from a CSV file of 1s and 0s
		@param filename CSV file to load
		@return boolean matrix
		~#
		function : LoadCsv(filename : String) ~ Bool[,] {
			table := CsvTable->New(System.IO.Filesystem.FileReader->ReadFile(filename));
			if(table->IsParsed()) {
				row_size := table->Size();
				if(row_size->Size() > 1) {
					column := table->Get(1);
					column_size := column->Size();

					matrix := Bool->New[row_size - 1, column_size];
					for(i := 1; i < row_size; i += 1;) {
						each(j : column_size) {
							value := table->Get(i)->Get(j)->ToLower();
							if(value->Equals(["0", "0.0", "false", "o", "f"])) {
								matrix[i - 1, j] := false;
							}
							else {
								matrix[i - 1, j] := true;	
							};
						};
					};

					return matrix;
				};
			};

			return Nil;
		}
	}

	class Split {
		@index : Int;
		@weighted_gini : Float;
		
		New(index : Int, weighted_gini : Float) {
			@index := index;
			@weighted_gini := weighted_gini;
		}

		method : public : GetWeightedGini() ~ Float {
			return @weighted_gini;
		}

		method : public : GetIndex() ~ Int {
			return @index;
		}

		method : public : ToString() ~ String {
			return "index={$@index},weighted_gini={$@weighted_gini}";
		}
	}
	
	#~
	Naive Bayes entry of term with counts
	~#
	class BayesEntry {
		@name : String;
		@count : Int;
		@bayes : Float;

		#~
		Constructor
		@param name entry name
		@param count count of occurrences 
		~#
		New(name : String, count : Int) {
			@name := name;
			@count := count;
		}

		#~
		Get the entry name
		@return entry name
		~#
		method : public : GetName() ~ String {
			return @name;
		}

		#~
		Get the entry count
		@return entry count
		~#
		method : public : GetCount() ~ Int {
			return @count;
		}

		#~
		Set the entry count
		@param count entry count
		~#
		method : public : SetCount(count : Int) ~ Nil {
			@count := count;
		}
	}

	#~
	Naive Bayes group of entries
	~#
	class BayesGroup {
		@entries : Map<String, BayesEntry>;
		@prob : Float;

		#~
		Sets the initial probability
		@param prob initial probability
		~#
		New(prob : Float) {
			@prob := prob;
			@entries := Map->New()<String, BayesEntry>;
		}

		#~
		Adds an entry
		@param entry entry to add
		@return true if added, false otherwise
		~#
		method : public : AddEntry(entry : BayesEntry) ~ Bool {
			if(@entries->Has(entry->GetName())) {
				return false;
			};

			@entries->Insert(entry->GetName(), entry);
			return true;
		}

		#~
		Gets entries
		@return entries
		~#
		method : public : GetEntries() ~ Map<String, BayesEntry> {
			return @entries;
		}

		#~
		Gets the initial probability
		@return probability
		~#
		method : public : GetProbability() ~ Float {
			return @prob;
		}
	}

	#~
	Naive Bayes ML algorithm

```
normal := BayesGroup->New(8.0 / 12.0);
normal->AddEntry(BayesEntry->New("dear", 8));		
normal->AddEntry(BayesEntry->New("friend", 5));
normal->AddEntry(BayesEntry->New("lunch", 3));
normal->AddEntry(BayesEntry->New("money", 1));

spam := BayesGroup->New(4.0 / 12.0);
spam->AddEntry(BayesEntry->New("dear", 2));
spam->AddEntry(BayesEntry->New("friend", 1));
spam->AddEntry(BayesEntry->New("lunch", 0));
spam->AddEntry(BayesEntry->New("money", 4));

bayes := NaiveBayes->New(normal, spam);
finding := bayes->Query(["lunch", "money", "money", "money", "money"]);

if(finding = 0) {
  "normal"->PrintLine();
}
else if(finding = 1) {
  "spam"->PrintLine();	
}
else {
  "invalid"->PrintLine();	
}	
	```
	~#
	class NaiveBayes {
		@left : BayesGroup;
		@right : BayesGroup;

		#~
		Constructor
		@param left left group
		@param right right group
		~#
		New(left : BayesGroup, right : BayesGroup) {
			@left := left;
			@right := right;
		}

		#~
		Query to Naive Bayes
		@param terms list of term to calculate
		@return 0 if left, 1 if right, -1 otherwise
		~#
		method : public : Query(terms : String[]) ~ Int {
			left := Query(terms, @left);
			right := Query(terms, @right);

# "left={$left}, right={$right}"->PrintLine();

			if(left = 0.0 | right = 0.0) {
				return -1;
			};

			if(left > right) {
				return 0;
			};

			return 1;
		}

		method : Query(terms : String[], group : BayesGroup) ~ Float {
			entries := group->GetEntries();
			prob := group->GetProbability();

			sum := 0.0;
			values := entries->GetValues()<BayesEntry>;
			each(value := values) {
				sum += value->GetCount();
			};

			index := 0;
			results := Map->New()<String, FloatRef>;
			each(value := values) {
				if(value->GetCount() = 0) {
					value->SetCount(1);
					sum += values->Size();
				};
				count := value->GetCount()
				name := value->GetName();
				result := count / sum;
				results->Insert(name, result);

# "{$name}: ({$count}/{$sum})={$result} * {$prob}"->PrintLine();
				
				index += 1;
			};

			result :=  0.0;
			each(term := terms) {
				find := results->Find(term);
				if(find <> Nil) {
					if(result = 0.0) {
						result := find->Get();
					}
					else {
						result *= find->Get();
					};
				};
			};

			return prob * result;
		}		
	}

	#~
	K-Nearest Neighbors algorithm

```
matrix := [
  [51.0,  167.0]
  [58.0, 169.0]
  [62.0, 182.0]
  [69.0, 176.0]
  [64.0, 173.0]
  [65.0, 172.0]
  [56.0, 174.0]
  [57.0, 173.0]
  [55.0, 170.0]];

labels := [
  "underweight", 
  "normal", 
  "normal", 
  "normal", 
  "normal", 
  "underweight", 
  "normal", 
  "normal", 
  "normal"];

knn := KNearestNeighbors->New(matrix, labels);
nearest := knn->Query(3, [57.0, 170.0]);
each(neighbor := nearest) {
  neighbor->ToString()->PrintLine();
};
```
~#
	class KNearestNeighbors {
		@matrix : Float[,];
		@labels : String[];

		#~
		Constructor.
		@param matrix matrix input matrix
		@param labels categories labels
		~#
		New(matrix : Float[,], labels : String[]) {
			@matrix := matrix;
			@labels := labels;
		}

		#~
		Query the matrix for classification
		@param k number of nearest neighbors 
		@param query input query
		@return k nearest neighbors 
		~#
		method : public : Query(k : Int, query : Float[]) ~ KNeighbor[] {
			return Query(query, k);		
		}

		method : native : Query(query : Float[], k : Int) ~ KNeighbor[] {
			dims := @matrix->Size();
			rows := dims[0];
			cols := dims[1];

			distances := Collection.CompareVector->New()<KNeighbor>;
			row := Float->New[cols];	
			each(i : rows) {
				each(j : cols) {
					row[j] := @matrix[i,j];
				};
				dist := EuclideanDistance(row, query);
				distances->AddBack(KNeighbor->New(dist, i, @labels[i]));
			};

			distances->Sort();			
			results := KNeighbor->New[k];
			i := distances->Size() - 1;
			while(k > 0) {
				results[--k] := distances->Get(i--);
			};

			return results;
		}

		method : native : EuclideanDistance(a : Float[], b : Float[]) ~ Float {
			if(a->Size() <> b->Size()) {
				return 0.0;
			};

			total := 0.0;
			
			each(i : a) {
				diff := b[i] - a[i];
				total += diff * diff;
			};

			return total->Sqrt();
		}
	}

	#~
	K-Neighbor result
	~#
	class KNeighbor implements Compare {
		@dist : Float;
		@row : Int;
		@cat : String;

		#~
		Constructor.
		@param dist distance value
		@param row row index
		@param cat category label
		~#
		New(dist : Float, row : Int, cat : String) {
			@dist := dist;
			@row := row;
			@cat := cat;
		}

		#~
		Compares neighbors 
		@param rhs neighbor to compare
		@return 0 if equal, -1 if types differ, 1 if equal
		~#
		method : public : Compare(rhs:System.Compare) ~ Int {
			if(@self->GetClassID() <> rhs->GetClassID()) {
				return -1;
			};
			right : KNeighbor := rhs->As(KNeighbor);
			bar := right->GetDistance();
			# foo := Float->Compare(bar, @dist);

			if(bar < @dist) {
				return -1;
			}
			else if(bar > @dist) {
				return 1;
			};

			return 0;
		}

		#~
		Returns a unique hash ID for a boolean
		@return hash ID
		~#
		method : public : HashID() ~ Int {
			return @dist * 4000000;
		}

		#~
		Get the distance
		@return distance
		~#
		method : public : GetDistance() ~ Float {
			return @dist;
		}

		#~
		Get the row index
		@return row index
		~#
		method : public : GetRow() ~ Int {
			return @row;
		}

		#~
		Get the category label
		@return category label
		~#
		method : public : GetCategory() ~ String {
			return @cat;
		}

		#~
		Returns a string representation of the neighbor
		@return string representation of the neighbor
		~#
		method : public : ToString() ~ String {
			return "{$@row}: distance={$@dist}, category={$@cat}";
		}
	}

#~
	K-Means clustering algorithm
	
	```
records->AddBack(FloatArrayRef->New([9.677901811, 3.044481052]));
records->AddBack(FloatArrayRef->New([2.103293937, 2.446154204]));
records->AddBack(FloatArrayRef->New([9.340432657, 2.896683906]));
records->AddBack(FloatArrayRef->New([7.674354483, 4.765027229]));
records->AddBack(FloatArrayRef->New([8.656404515, 0.481807722]));
# ...

labels := ["group-a","group-b", "group-c"];
groups := KMeans->Group(labels, records, 2, 0.0, 10.0);
groups->GetGroupNames()->ToString()->PrintLine();

groups->GetDunnIndex()->PrintLine();

each(group in groups) {
  group->GetName()->PrintLine();
  group->GetArrayValue(0)->PrintLine();
}
	```
~#
	class KMeans {
		@debug : static : Bool;

		#~
		K-Means group clustering
		@param group_labels group labels used to tag groups also specify K
		@param records input records
		@param record_length length of records, all records lengths be the same
		@param min_value smallest record value
		@param max_value largest record value
		@return labeled grouping
		~#
		function : native : Group(group_labels : String[], records : Vector<FloatArrayRef>, record_length : Int, min_value : Float, max_value : Float) ~ KMeansGrouping {
			# https://www.ibm.com/support/pages/how-does-k-mean-cluster-node-select-initial-records-clustering
			centroids := InitalCentroids(group_labels, records, record_length, min_value, max_value);
			updated_centroids := FloatArrayRef->New[group_labels->Size()];
			
			groups := Hash->New()<String, Vector<FloatArrayRef>>;
			each(centroid_label in group_labels) {
				groups->Insert(centroid_label, Vector->New()<FloatArrayRef>);
			};

			iter := 0;
			has_changed := true;
			while(has_changed) {
				if(@debug) {
					"=== {$iter} ==="->PrintLine();
					iter += 1;
				}

				each(datum in records) {
					shortest_index := -1;
					shortest_distance := Float->Inf();
					
					each(i : centroids) {
						centroid := centroids[i];

						distance := Distance(datum, centroid);
						if(distance <= shortest_distance) {
							shortest_distance := distance;
							shortest_index := i;
						}
					};

					nearest_centroid_label := group_labels[shortest_index];
					group := groups->Find(nearest_centroid_label)<FloatArrayRef>;
					group->AddBack(datum);
				};

				group_key_values := groups->GetKeyValues()<Pair<String, Vector<FloatArrayRef>>>;
				each(i : group_key_values) {
					group_key_value := group_key_values->Get(i);

					group_label := group_key_value->GetFirst();
					group := group_key_value->GetSecond();

					if(@debug) {
						group_size := group->Size();
						"label='{$group_label}', size={$group_size}: {$group}"->PrintLine();
					};

					update := Average(group, record_length);
					if(update <> Nil) {
						updated_centroids[i] := update;
					};
				};

				# update of centroids and rebuilding of buckets
				has_changed := HasChanged(centroids, updated_centroids);
				if(has_changed) {
					centroids := updated_centroids;
					updated_centroids := FloatArrayRef->New[group_labels->Size()];

					each(centroid_label in group_labels) {
						if(groups->Remove(centroid_label)) {
							groups->Insert(centroid_label, Vector->New()<FloatArrayRef>);
						};
					};
				};
			};

			return KMeansGrouping->New(groups);
		}

		function : native : InitalCentroids(group_labels : String[], records : Vector<FloatArrayRef>, record_length : Int, min_value : Float, max_value : Float) ~ FloatArrayRef[] {
			centroids := FloatArrayRef->New[group_labels->Size()];

			each(i : centroids) {
				random_values := Float->New[record_length];
				each(j : random_values) {
					random_values[j] := Float->Random(min_value + 0.001, max_value - 0.001);
				};
				centroids[i] := FloatArrayRef->New(random_values);
			};

			return centroids;
		}

		function : native : HasChanged(old_centroids : FloatArrayRef[], new_centroids : FloatArrayRef[]) ~ Bool {
			if(old_centroids = Nil | new_centroids = Nil) {
				return false;
			};

			has_changed := false;
			each(i : old_centroids) {
				temp := old_centroids[i];
				if(temp = Nil) {
					return false;
				};
				old_centroid_values := temp->Get();

				temp := new_centroids[i];
				if(temp = Nil) {
					return false;
				};
				new_centroid_values := temp->Get();
				
				each(j : old_centroid_values) {
					old_centroid_value := old_centroid_values[j];
					new_centroid_value := new_centroid_values[j];

					has_changed := Float->Abs(old_centroid_value - new_centroid_value) < 0.001;
					if(<>has_changed) {
						return true;
					}
				};
			};

			return false;
		}

		function : native : Average(group : Vector<FloatArrayRef>, record_length : Int) ~FloatArrayRef {
			if(group->IsEmpty()) {
				return Nil;
			};

			average_values := Float->New[record_length];
			each(i : average_values) {
				sum := 0.0;
				each(array in group) {
					array_values := array->Get();
					sum += array_values[i];
				};
				average := sum / group->Size()->As(Float);
				average_values[i] := average;
			}

			return FloatArrayRef->New(average_values);
		}

		function : native : Distance(left : FloatArrayRef, right : FloatArrayRef) ~ Float {
			if(left = Nil | right = Nil) {
				return 0.0;
			};

			left_values := left->Get(); right_values := right->Get();
			if(left_values->Size() <> right_values->Size()) {
				return 0.0;
			};

			distance := 0.0;
	        each(i : left_values) {
	            distance += Float->Pow(left_values[i] - right_values[i], 2.0);
	        };

	        return distance->Sqrt();
		}
	}

	#~
	K-Means grouping result
	~#
	class KMeansGrouping {
		@groups : Hash<String, KMeansGroup>;
		@group_names : String[];
		@dunn_index : Float;

		@debug : static : Bool;

		New(groups : Hash<String, Vector<FloatArrayRef>>) {
			group_key_values := groups->GetKeyValues()<Pair<String, Vector<FloatArrayRef>>>;
			@groups := Hash->New()<String, KMeansGroup>;
			@group_names := String->New[group_key_values->Size()];			
			@dunn_index := -1.0;
			
			each(i : group_key_values) {
				group_key_value := group_key_values->Get(i);

				group := group_key_value->GetSecond();
				group_name := group_key_value->GetFirst();
				@group_names[i] := group_name->Copy();
				@groups->Insert(group_name, KMeansGroup->New(group_name, group));
			};
		}

		#~
		Get the number of groups
		@return number of groups
		~#
		method : public : Size() ~ Int {
			return @groups->Size();
		}

		#~
		Get a group by index
		@param i index
		@return group
		~#
		method : public : Get(i : Int) ~ KMeansGroup {
			if(i > -1 & i < @group_names->Size()) {
				return @groups->Find(@group_names[i])
			};

			return Nil;
		}

		#~
		Get an array of group names
		@return array of group names
		~#
		method : public : GetGroupNames() ~ String[] {
			return @group_names;
		}

		#~
		Get a group by name
		@param name group name
		@return group
		~#
		method : public : GetGroup(name : String) ~ KMeansGroup {
			return @groups->Find(name);
		}

		#~
		Calculates the Dunn index
		@param groups K-Mean grouping
		@return Dunn index, higher values indicate more distinct clusters
		~#
		method : public : GetDunnIndex() ~ Float {
			if(@dunn_index < 0.0) {
				group_key_values := @groups->GetKeyValues()<Pair<String, KMeansGroup>>;

				max_intra_distance := 0.0;
				each(group_key_value in group_key_values) {
					group := group_key_value->GetSecond()->GetValues();
					group_name := group_key_value->GetFirst();
					
					if(@debug) {
						group_size := group->Size();
						"group: name='{$group_name}', size={$group_size}\n---"->PrintLine();
					};

					each(left_array in group) {			
						each(right_array in group) {
							if(left_array <> right_array) {
								distance := KMeans->Distance(left_array, right_array);
								if(distance > max_intra_distance) {
									max_intra_distance := distance;
								}
							};
						};
					};
				};

				if(@debug) {
					"max_intra_distance={$max_intra_distance}\n---"->PrintLine();
				};

				min_inter_distance := Float->Inf();
				each(left_key_value in group_key_values) {
					left_group := left_key_value->GetSecond()->GetValues();
					left_group_name := left_key_value->GetFirst();

					each(right_key_value in group_key_values) {
						right_group := right_key_value->GetSecond()->GetValues();
						right_group_name := right_key_value->GetFirst();
						if(<>left_group_name->Equals(right_group_name)) {
							each(left_array in left_group) {
								each(right_array in right_group) {
									distance := KMeans->Distance(left_array, right_array);
									if(distance < min_inter_distance) {
										min_inter_distance := distance;
									};
								};
							};
						};
					};
				};

				if(@debug) {
					"min_inter_distance={$min_inter_distance}\n---"->PrintLine();
				};

				@dunn_index := min_inter_distance / max_intra_distance;
			};

			return @dunn_index;
		}
		
		#~
		String representation of the object
		@return groups representation of the object
		~#
		method : public : ToString() ~ String {
			buffer := "";

			buffer->Append('[');
			group_key_values := @groups->GetKeyValues()<Pair<String, KMeansGroup>>;			
			each(i : group_key_values) {
				group_key_value := group_key_values->Get(i);
				group := group_key_value->GetSecond();
				group_name := group_key_value->GetFirst();

				buffer->Append("{\"name\": \"");
				buffer->Append(group_name);
				buffer->Append("\",\"values\":[");
				buffer->Append(group->ToString());
				buffer->Append("]}");

				if(i + 1 < group_key_values->Size()) {
					buffer->Append(',');
				};
			};
			buffer->Append(']');

			return buffer;
		}
	}

	#~
	KMeans group
	~#
	class KMeansGroup {
		@name : String;
		@arrays : Vector<FloatArrayRef>;

		New(name : String, arrays : Vector<FloatArrayRef>) {
			@name := name;
			@arrays := arrays;
		}

		#~
		Get the name of the group
		@return name of the group
		~#
		method : public : GetName() ~ String {
			return @name;
		}

		#~
		Get group values
		@return group values
		~#
		method : public : GetValues() ~ Vector<FloatArrayRef> {
			return @arrays;
		}

		#~
		Get group values as an array
		@param i index
		@return group values as an array
		~#
		method : public : GetArrayValue(i : Int) ~ Float[] {
			if(i > -1 & i < @arrays->Size()) {
				array := @arrays->Get(i)->Get();
				columns := array->Size();

				matrix := Float->New[columns];
				each(j : array) {
					matrix[j] := array[j];
				};

				return matrix;

			};

			return Nil;
		}

		#~
		Get the size of the group
		@return size of the group
		~#
		method : public : Size() ~ Int {
			return @arrays->Size();
		}

		#~
		Get array by index
		@param i index
		@return array
		~#
		method : public : Get(i : Int) ~ FloatArrayRef {
			if(i > -1 & i < @arrays->Size()) {
				return @arrays->Get(i);
			};

			return Nil;
		}

		#~
		Get group as a value matrix
		@return value matrix
		~#
		method : native : public : GetArrayValues() ~ Float[,] {
			matrix : Float[,];

			if(<>@arrays->IsEmpty()) {
				rows := @arrays->Size();
				array := @arrays->Get(0)->Get();
				columns := array->Size();

				matrix := Float->New[rows, columns];
				each(i : @arrays) {
					array := @arrays->Get(i)->Get();
					each(j : array) {
						matrix[i, j] := array[j];
					}
				};
			};

			return matrix;
		}

		#~
		String representation of the object
		@return groups representation of the object
		~#
		method : public : ToString() ~ String {
			buffer := "";

			if(<>@arrays->IsEmpty()) {
				each(i : @arrays) {
					array := @arrays->Get(i)->Get();
					buffer->Append(array->ToString());
					if(i + 1 < @arrays->Size()) {
						buffer->Append(',');
					};
				};
			};

			return buffer;
		}
	}
}
